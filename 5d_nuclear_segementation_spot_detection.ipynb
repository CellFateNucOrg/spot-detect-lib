{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecdc50a0",
   "metadata": {},
   "source": [
    "# Nuclear segmentation with emerin ring and spot detection\n",
    "\n",
    "Scripts to detect nuclei from 5d images (t,c,z,y,x) where channel 0 is green spots and channel 1 is red emerin rings.\n",
    "Mostly based on scripts from Lucien Hinderling, with some modifications and cleanup by Jennifer Semple.\n",
    "\n",
    "Nuclear segmentation carried out with Cellpose.\n",
    "Spot detection carried out with pytrack.\n",
    "\n",
    "**Inputs**:\n",
    "\n",
    "raw_input_path and denoised_input_path for directories containing raw and denoised images and output_path where results will be put. raw_input_path is used to create a dataframe with paths to images and the following \n",
    "columns:\n",
    "\n",
    "*filename\tdate\texperiment\tstrain\tprotein\tid  raw_filepath    denoised_filepath*\n",
    "\n",
    "example line:\n",
    "\n",
    "*20240915_1268_E_bean_15um\t20240915\t3d\t1268\tDPY27\tDPY27_3d_20240915_1268_E_bean_15um\t/mnt/external.data/MeisterLab/Dario/Imaging/DP...\t/mnt/external.data/MeisterLab/Dario/Imaging/DP...*\n",
    "\n",
    "the id column is used to name images in the output_path directories\n",
    "\n",
    "**Outputs**:\n",
    "\n",
    "segmentation masks (.tif files) in output_path/segmentation/\n",
    "\n",
    "distance masks (.tif files) in output_path/edt/\n",
    "\n",
    "nuclear measurements (.csv files) in output_path/nuclei/\n",
    "\n",
    "intensity measurements for nuclei with arrays of intensity/distance from middle slice of each nuclear mask (.pkl files) in as well as other nuclear measurments and data are in output_path/dist/ \n",
    "\n",
    "qc plots of segmentation on original image (segmentation_XXX.pdf), individual masked nuclei (cropped_nuclei_XXX.pdf) in output_path/qc/\n",
    "\n",
    "spot detection (.csv files, doesn't work very well) in output_path/spots/ with some qc in output_path/qc/spots*.pdf and spotGMM*.pdf\n",
    "\n",
    "### Setting you might need to change\n",
    "\n",
    "raw_input_path - should point to directory where the nd2 images are '/mnt/external.data/MeisterLab/Dario/SDC1/1273/20241108_hs'. \n",
    "Scripts assume the denoised images are one level down in N2V_sdc1_dpy27_mSG_emr1_mCh/denoised folder.\n",
    "Scripts assume that the directory above the raw_input drive contains strain name, and the directory above that contains protein name.\n",
    "\n",
    "output_path - create a directory for the analysis. results will be stored in a protein/strain/date structure same as in the raw_input_path.\n",
    "\n",
    "Make sure file paths end with  '/'\n",
    "\n",
    "If you are not working on the server, but rather locally on a mac with izbkingston mounted as an external drive, you need to change 'server = True' to False (currently this only works for mac externally mounted drives).\n",
    "\n",
    "Set the channels for nuclear stain (nucChannel) and for spots (spotChannel) [currently 0 and 1 respectively] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4864532e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import napari\n",
    "import torch\n",
    "from skimage.measure import regionprops_table, regionprops\n",
    "from skimage.color import label2rgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import trackpy as tp\n",
    "import cellpose\n",
    "from cellpose import models\n",
    "import edt\n",
    "import glob\n",
    "import os\n",
    "import tqdm\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "import gc\n",
    "import seaborn as sns\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from bioio import BioImage\n",
    "import bioio_nd2\n",
    "import bioio_tifffile\n",
    "from bioio.writers import OmeTiffWriter\n",
    "import scipy.stats as stats\n",
    "from scipy import optimize\n",
    "from scipy.ndimage import map_coordinates #new\n",
    "import bioio\n",
    "\n",
    "\n",
    "\n",
    "#anisotropy = (3,1,1) # Relative scale of (Z,X,Y) axes now calculated inside scripts\n",
    "\n",
    "nucChannel = 0 # red emerin rings\n",
    "spotChannel = 1 # green spots\n",
    "server = True # is the script running on the server or mounted on mac\n",
    "\n",
    "def macMount(path): # tansforms server path to path for izbkingston mounted on mac\n",
    "    newpath = path.replace('/mnt/','/Volumes/')\n",
    "    return newpath\n",
    "\n",
    "\n",
    "\n",
    "# in lucien's original scripts:\n",
    "# channel 0 is green spots\n",
    "# channel 1 is red emerin\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d2eb4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# on server\n",
    "\n",
    "raw_input_path = '/mnt/external.data/MeisterLab/Dario/SDC1/1273/20240813_e/'\n",
    "denoised_input_path = raw_input_path+'N2V_sdc1_dpy27_mSG_emr1_mCh/denoised/'\n",
    "\n",
    "# extract identifying directories from raw_input_path\n",
    "protein_strain_date = '/'.join(os.path.normpath(raw_input_path).split(os.sep)[-3:])\n",
    "output_path = '/mnt/external.data/MeisterLab/mvolosko/image_project/sdc1/'+protein_strain_date+'/'\n",
    "\n",
    "\n",
    "if(not server):\n",
    "    raw_input_path = macMount(raw_input_path)\n",
    "    output_path = macMount(output_path)\n",
    "\n",
    "\n",
    "#new\n",
    "if not os.path.exists(output_path+\"/qc_plots\"):\n",
    "    os.makedirs(output_path+\"/qc_plots\")\n",
    "\n",
    "if not os.path.exists(output_path+\"/qc\"):\n",
    "    os.makedirs(output_path+\"/qc\")\n",
    "\n",
    "if not os.path.exists(output_path+\"/segmentation\"):\n",
    "    os.makedirs(output_path+\"/segmentation\")\n",
    "\n",
    "if not os.path.exists(output_path+\"/edt\"):\n",
    "    os.makedirs(output_path+\"/edt\")\n",
    "\n",
    "if not os.path.exists(output_path+\"/spots\"):\n",
    "    os.makedirs(output_path+\"/spots\")\n",
    "\n",
    "if not os.path.exists(output_path+\"/nuclei\"):\n",
    "    os.makedirs(output_path+\"/nuclei\")\n",
    "    \n",
    "if not os.path.exists(output_path+\"/dist\"):\n",
    "    os.makedirs(output_path+\"/dist\")\n",
    "\n",
    "\n",
    "raw_file_name_pattern = \"/*.nd2\"\n",
    "denoised_file_name_pattern = \"/*_n2v.tif\"\n",
    "raw_filepaths = sorted(glob.glob(raw_input_path + raw_file_name_pattern,recursive=True))\n",
    "raw_filepaths = [filepath for filepath in raw_filepaths if '_bad.nd2' not in filepath]\n",
    "\n",
    "print(f\"Found {len(raw_filepaths)} *.nd2 files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e87afd6",
   "metadata": {},
   "source": [
    "Generate data frame of file paths with metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fe90e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(server): #only save if running on server\n",
    "    df = pd.DataFrame()\n",
    "    df['filename'] = [os.path.basename(filepath)[:-4] for filepath in raw_filepaths]\n",
    "    tmpdate = [os.path.normpath(filepath).split(os.sep)[-2] for filepath in raw_filepaths]\n",
    "    df['date'] = pd.Series([exp.split('_')[0] for exp in tmpdate])\n",
    "    df['experiment'] = pd.Series([exp.split('_')[1] for exp in tmpdate])\n",
    "    df['strain'] = [os.path.normpath(filepath).split(os.sep)[-3] for filepath in raw_filepaths]\n",
    "    df['protein'] = [os.path.normpath(filepath).split(os.sep)[-4] for filepath in raw_filepaths]\n",
    "    df['id'] = df['protein'] + '_' + df['experiment'] + '_' + df['filename'] \n",
    "    df['raw_filepath'] = raw_filepaths\n",
    "    df['denoised_filepath'] = [denoised_input_path+filename+'_n2v.tif' for filename in df['filename']]\n",
    "    df.to_csv(output_path+'fileList.csv',index=False)\n",
    "else:\n",
    "    df=pd.read_csv(output_path+'fileList.csv')\n",
    "    for i in range(len(df)):\n",
    "        df.at[i,'raw_filepath'] = macMount(df.at[i,'raw_filepath'])\n",
    "        df.at[i,'denoised_filepath'] = macMount(df.at[i,'denoised_filepath'])\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27817eeb",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667d650d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.device(0)\n",
    "model_path='/mnt/external.data/MeisterLab/lhinder/segmentation_3d_anja/code/worms_1000epochs_v0'\n",
    "if(not server):\n",
    "    model_path = macMount(model_path)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available\")\n",
    "    model = models.CellposeModel(pretrained_model=model_path, gpu=True, device =torch.device('cuda:0'))\n",
    "else:\n",
    "    print(\"Only CPU is available\")\n",
    "    model = models.CellposeModel(pretrained_model=model_path, gpu=False)\n",
    "\n",
    "\n",
    "# no gpu, from local machine with izbkingston mounted \n",
    "#model = models.CellposeModel(pretrained_model='/Volumes/external.data/MeisterLab/lhinder/segmentation_3d_anja/code/worms_1000epochs_v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53b2e30-a266-49e0-85b5-b8e53d1147e7",
   "metadata": {},
   "source": [
    "## ND2 to tiff transforamtion raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1d6c4b",
   "metadata": {},
   "source": [
    "## Functions for nuclear segmentation and qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d68a0b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Disable do_3D, there is a bug. 2D and stitching with overlap works much better.\n",
    "# Takes around 7min for the whole image on the macbook\n",
    "def segment_nuclei(img, model):\n",
    "    ''' use pytorch cellpose model to segment nuclei'''\n",
    "    masks,flows,styles = model.eval(img,do_3D=False,stitch_threshold=0.3,cellprob_threshold =0,diameter =36)\n",
    "    return masks,flows,styles\n",
    "\n",
    "\n",
    "def calc_distance_mask(masks,anisotropy):\n",
    "    '''Calculate the distance map from the nuclei-edge towards the center of nucleus'''\n",
    "    masks_edt = edt.edt(masks,anisotropy = anisotropy)\n",
    "    return masks_edt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_qc_nuclei_crop(df, index, df_region_props, img, t=0, display = False, seed=1):\n",
    "    '''Plot a cropped region of a random sample of 10 nuclei from each image'''\n",
    "    nb_nuc = 10\n",
    "    np.random.seed(seed)\n",
    "    indices_to_sample = np.random.choice(range(len(df_region_props)),size = nb_nuc,replace = False)\n",
    "    # sort indeces in descending order of area\n",
    "\n",
    "    widths=[df_region_props['image'][i].shape[1] for i in indices_to_sample]\n",
    "\n",
    "    fig, axs = plt.subplots(nrows = 2, ncols = nb_nuc, figsize = (15,5),dpi = 250, \n",
    "                            sharex=False, sharey=False, width_ratios=widths)\n",
    "    fig.suptitle(f'Cropped nuclei {df.id.iloc[index]}', fontsize=16)\n",
    "\n",
    "    for i,sample in enumerate(indices_to_sample):\n",
    "        intensity_image = df_region_props['intensity_image'][sample][:,:,:,spotChannel] #show first spot channel\n",
    "        image = df_region_props['image'][sample]\n",
    "        mx = np.ma.masked_array(intensity_image,mask = ~image)\n",
    "        z_height = image.shape[0] \n",
    "        axs[0,i].imshow(mx[int(z_height/2)])\n",
    "        axs[0,i].spines['top'].set_visible(False)\n",
    "        axs[0,i].spines['right'].set_visible(False)\n",
    "        axs[0,i].spines['bottom'].set_visible(False)\n",
    "        axs[0,i].spines['left'].set_visible(False)\n",
    "        axs[0,i].get_xaxis().set_ticks([])\n",
    "        axs[0,i].get_yaxis().set_ticks([])\n",
    "\n",
    "    for i,sample in enumerate(indices_to_sample):\n",
    "        intensity_image = df_region_props['intensity_image'][sample][:,:,:,nucChannel] #show second nuclear channel\n",
    "        image = df_region_props['image'][sample]\n",
    "        mx = np.ma.masked_array(intensity_image,mask = ~image)\n",
    "        z_height = image.shape[0]\n",
    "        axs[1,i].imshow(mx[int(z_height/2)])\n",
    "        axs[1,i].spines['top'].set_visible(False)\n",
    "        axs[1,i].spines['right'].set_visible(False)\n",
    "        axs[1,i].spines['bottom'].set_visible(False)\n",
    "        axs[1,i].spines['left'].set_visible(False)\n",
    "        axs[1,i].get_xaxis().set_ticks([])\n",
    "        axs[1,i].get_yaxis().set_ticks([])\n",
    "\n",
    "        if i == nb_nuc-1:\n",
    "            scalebar = ScaleBar(0.065, \"um\", length_fraction=1, box_alpha=0.7,color='black',location='lower right',height_fraction = 0.05,border_pad =-1)\n",
    "            axs[1,i].add_artist(scalebar)\n",
    "\n",
    "    #plt.tight_layout()\n",
    "    fig.savefig(output_path + 'qc/cropped_nuclei_'+df.id.iloc[index]+'_t'+'{:02d}'.format(t)+'.pdf')\n",
    "    if display == False:\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_single_nucleus_crop(df, index, df_region_props, nuc_index, img):\n",
    "    '''Plot a cropped region of a particular nucleus'''\n",
    "\n",
    "    fig, axs = plt.subplots(nrows = 1, ncols = 2, figsize = (3,1.5),dpi = 250, sharey=True)\n",
    "    fig.suptitle(f'{df.id.iloc[index]}', fontsize=6)\n",
    "\n",
    "    intensity_image = df_region_props['intensity_image'][nuc_index][:,:,:,spotChannel] #show first spot channel\n",
    "    image = df_region_props['image'][nuc_index]\n",
    "    mx = np.ma.masked_array(intensity_image, mask = ~image)\n",
    "    z_height = image.shape[0] \n",
    "    axs[0].imshow(mx[int(z_height/2)])\n",
    "    axs[0].spines['top'].set_visible(False)\n",
    "    axs[0].spines['right'].set_visible(False)\n",
    "    axs[0].spines['bottom'].set_visible(False)\n",
    "    axs[0].spines['left'].set_visible(False)\n",
    "    axs[0].get_xaxis().set_ticks([])\n",
    "    axs[0].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "    intensity_image = df_region_props['intensity_image'][nuc_index][:,:,:,nucChannel] #show second nuclear channel\n",
    "    image = df_region_props['image'][nuc_index]\n",
    "    mx = np.ma.masked_array(intensity_image, mask = ~image)\n",
    "    z_height = image.shape[0]\n",
    "    axs[1].imshow(mx[int(z_height/2)])\n",
    "    axs[1].spines['top'].set_visible(False)\n",
    "    axs[1].spines['right'].set_visible(False)\n",
    "    axs[1].spines['bottom'].set_visible(False)\n",
    "    axs[1].spines['left'].set_visible(False)\n",
    "    axs[1].get_xaxis().set_ticks([])\n",
    "    axs[1].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "    scalebar = ScaleBar(0.065, \"um\", length_fraction=1, box_alpha=0.7,color='black',location='lower right',height_fraction = 0.05,border_pad =-1)\n",
    "    axs[1].add_artist(scalebar)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_qc_segmentation_xyz(img, masks, index, df, t=0, display_plot=False, plotContours=False):\n",
    "    '''Plot a 2x3 grid of xy, xz, yz slices of the image and the corresponding segmentation'''\n",
    "    nucChannel = 0\n",
    "    num_z=img.shape[1]\n",
    "    num_y=img.shape[2]\n",
    "    num_x=img.shape[3]\n",
    "    nlabel=100\n",
    "\n",
    "    fig = plt.figure(layout='constrained',dpi=450,figsize = (10,10))\n",
    "    fig.suptitle(f'Segmentation for {df.id.iloc[index]}', fontsize=10)\n",
    "    subfigs = fig.subfigures(2, 1, wspace=0.1)\n",
    "\n",
    "    axsTop = subfigs[0].subplots(2, 3,sharex=True, sharey=True)\n",
    "    #xy\n",
    "    axsTop[0,0].imshow(label2rgb(masks[int(num_z*0.3),:,:],bg_label=0,bg_color=(255, 255, 255),colors=np.random.random((nlabel, 3))))\n",
    "    axsTop[1,0].set_title('z='+str(int(num_z*0.3)), fontsize=8)\n",
    "    axsTop[0,1].imshow(label2rgb(masks[int(num_z*0.5),:,:],bg_label=0,bg_color=(255, 255, 255),colors=np.random.random((nlabel, 3))))\n",
    "    axsTop[1,1].set_title('z='+str(int(num_z*0.5)), fontsize=8)\n",
    "    axsTop[0,2].imshow(label2rgb(masks[int(num_z*0.7),:,:],bg_label=0,bg_color=(255, 255, 255),colors=np.random.random((nlabel, 3))))\n",
    "    axsTop[1,2].set_title('z='+str(int(num_z*0.7)), fontsize=8)\n",
    "\n",
    "    axsTop[1,0].imshow(img[nucChannel,int(num_z*0.3),:,:],cmap = 'gray_r')\n",
    "    axsTop[1,1].imshow(img[nucChannel,int(num_z*0.5),:,:],cmap = 'gray_r')\n",
    "    axsTop[1,2].imshow(img[nucChannel,int(num_z*0.7),:,:],cmap = 'gray_r')\n",
    "\n",
    "    if plotContours:\n",
    "        axsTop[1,0].contour(masks[int(num_z*0.3),:,:], [0.5], linewidths=0.5, colors='r')\n",
    "        axsTop[1,1].contour(masks[int(num_z*0.5),:,:], [0.5], linewidths=0.5, colors='r')\n",
    "        axsTop[1,2].contour(masks[int(num_z*0.7),:,:], [0.5], linewidths=0.5, colors='r')\n",
    "\n",
    "\n",
    "\n",
    "    for axss in axsTop:\n",
    "        for ax in axss:\n",
    "            #ax.set_xlim(0,num_x)\n",
    "            #ax.set_ylim(0,num_y)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "\n",
    "    axsBottom = subfigs[1].subplots(4, 3,sharex=True,sharey=True)\n",
    "    #xz\n",
    "    axsBottom[0,0].imshow(label2rgb(masks[:,int(num_y*0.3),:],bg_label=0,bg_color=(255, 255, 255),colors=np.random.random((nlabel, 3))))\n",
    "    axsBottom[1,0].set_title('y='+str(int(num_y*0.3)), fontsize=8)\n",
    "    axsBottom[0,1].imshow(label2rgb(masks[:,int(num_y*0.5),:],bg_label=0,bg_color=(255, 255, 255),colors=np.random.random((nlabel, 3))))\n",
    "    axsBottom[1,1].set_title('y='+str(int(num_y*0.5)), fontsize=8)\n",
    "    axsBottom[0,2].imshow(label2rgb(masks[:,int(num_y*0.7),:],bg_label=0,bg_color=(255, 255, 255),colors=np.random.random((nlabel, 3))))\n",
    "    axsBottom[1,2].set_title('y='+str(int(num_y*0.7)), fontsize=8)\n",
    "\n",
    "    axsBottom[1,0].imshow(img[nucChannel,:,int(num_y*0.3),:],cmap = 'gray_r')\n",
    "    axsBottom[1,1].imshow(img[nucChannel,:,int(num_y*0.5),:],cmap = 'gray_r')\n",
    "    axsBottom[1,2].imshow(img[nucChannel,:,int(num_y*0.7),:],cmap = 'gray_r')\n",
    "\n",
    "    if plotContours:\n",
    "        axsBottom[1,0].contour(masks[:,int(num_y*0.3),:], [0.5], linewidths=0.5, colors='r')\n",
    "        axsBottom[1,1].contour(masks[:,int(num_y*0.5),:], [0.5], linewidths=0.5, colors='r')\n",
    "        axsBottom[1,2].contour(masks[:,int(num_y*0.7),:], [0.5], linewidths=0.5, colors='r')\n",
    "\n",
    "\n",
    "    #yz\n",
    "    axsBottom[2,0].imshow(label2rgb(masks[:,:,int(num_x*0.3)],bg_label=0,bg_color=(255, 255, 255),colors=np.random.random((nlabel, 3))))\n",
    "    axsBottom[3,0].set_title('x='+str(int(num_x*0.3)), fontsize=8)\n",
    "    axsBottom[2,1].imshow(label2rgb(masks[:,:,int(num_x*0.5)],bg_label=0,bg_color=(255, 255, 255),colors=np.random.random((nlabel, 3))))\n",
    "    axsBottom[3,1].set_title('x='+str(int(num_x*0.5)), fontsize=8)\n",
    "    axsBottom[2,2].imshow(label2rgb(masks[:,:,int(num_x*0.7)],bg_label=0,bg_color=(255, 255, 255),colors=np.random.random((nlabel, 3))))\n",
    "    axsBottom[3,2].set_title('x='+str(int(num_x*0.7)), fontsize=8)\n",
    "\n",
    "    axsBottom[3,0].imshow(img[nucChannel,:,:,int(num_x*0.3)],cmap = 'gray_r')\n",
    "    axsBottom[3,1].imshow(img[nucChannel,:,:,int(num_x*0.5)],cmap = 'gray_r')\n",
    "    axsBottom[3,2].imshow(img[nucChannel,:,:,int(num_x*0.7)],cmap = 'gray_r')\n",
    "\n",
    "    if plotContours:\n",
    "        axsBottom[3,0].contour(masks[:,:,int(num_x*0.3)], [0.5], linewidths=0.5, colors='r')\n",
    "        axsBottom[3,1].contour(masks[:,:,int(num_x*0.5)], [0.5], linewidths=0.5, colors='r')\n",
    "        axsBottom[3,2].contour(masks[:,:,int(num_x*0.7)], [0.5], linewidths=0.5, colors='r')\n",
    "\n",
    "    for axss in axsBottom:\n",
    "        for ax in axss:\n",
    "            #ax.set_ylim(0,num_z)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if display_plot:\n",
    "        plt.show()\n",
    "    else:\n",
    "        fig.savefig(output_path + 'qc/segmentation_'+df.id.iloc[index]+'_t'+'{:02d}'.format(t)+'.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2061263f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the segmentation script on all images (reserve more than 24GB!)\n",
    "#this produces segmentation, segmentation_qc and edt files\n",
    "def run_nuclear_segmentation(indices, df, rerun=False):\n",
    "    '''Run the segmentation on all images in the dataframe'''\n",
    "    for index in tqdm.tqdm(indices):\n",
    "        if rerun or not os.path.exists(output_path+'edt/'+df.id.iloc[index]+'_t0.tif'):\n",
    "            # get anisotropy from raw image metadata\n",
    "            img_5d = BioImage(df.raw_filepath.iloc[index], reader=bioio_nd2.Reader)\n",
    "            ZvX = np.round(img_5d.physical_pixel_sizes.Z/img_5d.physical_pixel_sizes.X,0)\n",
    "            anisotropy = (ZvX,1,1)\n",
    "            # Load the denoised data\n",
    "            img_5d = BioImage(df.denoised_filepath.iloc[index], reader=bioio_tifffile.Reader)\n",
    "            for t in range(img_5d.dims.T):\n",
    "                img = img_5d.get_image_data(\"CZYX\", T=t)\n",
    "\n",
    "                # Segment nuclei \n",
    "                masks,flows,styles = segment_nuclei(img[nucChannel,:,:,:],model) # Run the segmentation\n",
    "                plot_qc_segmentation_xyz(img,masks,index, df, t, display_plot = False)                         # Create qc plot\n",
    "                OmeTiffWriter.save(masks, output_path+'segmentation/'+df.id.iloc[index]+'_t'+'{:02d}'.format(t)+'.tif')\n",
    "\n",
    "                del flows\n",
    "                del styles\n",
    "                gc.collect()\n",
    "                \n",
    "                # Calculate edt \n",
    "                masks_edt = calc_distance_mask(masks,anisotropy)\n",
    "                OmeTiffWriter.save(masks_edt, output_path+'edt/'+df.id.iloc[index]+'_t'+'{:02d}'.format(t)+'.tif')\n",
    "\n",
    "                del masks\n",
    "                del masks_edt\n",
    "                gc.collect()\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f83e25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read images\n",
    "## crop the nuclei slices\n",
    "## calculate EDT transform\n",
    "## for each nuclei loop over all distances (1:40) and take mean\n",
    "## array of distance/intensity measurements are taken only for middle slice of mask (?)\n",
    "\n",
    "## nucleus_id | nucleus volume | [1:20] mean intensities | group | ...\n",
    "\n",
    "\n",
    "def run_dist_analysis(indices,df):\n",
    "    '''Run the distance analysis on all images in the dataframe'''\n",
    "    for index in tqdm.tqdm(indices):\n",
    "        \n",
    "        df_nuclei = pd.DataFrame()\n",
    "        print(df.iloc[index].raw_filepath)\n",
    "\n",
    "        img_5d = BioImage(df.raw_filepath.iloc[index], reader=bioio_nd2.Reader)\n",
    "        # calculate anisotropy from raw image metadata\n",
    "        ZvX = np.round(img_5d.physical_pixel_sizes.Z/img_5d.physical_pixel_sizes.X,0)\n",
    "\n",
    "        for t in range(img_5d.dims.T):\n",
    "            img = img_5d.get_image_data(\"ZYXC\", T=t)\n",
    "\n",
    "            masks = BioImage(output_path+'segmentation/'+df.id.iloc[index]+'_t'+'{:02d}'.format(t)+'.tif', reader=bioio_tifffile.Reader)\n",
    "            masks = masks.get_image_data(\"ZYX\", T=0, C=0)\n",
    "            \n",
    "            df_region_props = regionprops_table(masks,img, properties = ['label', 'area','centroid','MajorAxisLength','solidity','image','intensity_image'])\n",
    "            df_region_props = pd.DataFrame(df_region_props)\n",
    "\n",
    "            if len(df_region_props)>=10:\n",
    "                plot_qc_nuclei_crop(df, index, df_region_props, img, t=t, display = False) \n",
    "\n",
    "            for i in range(len(df_region_props)):\n",
    "                df_nuclei_temp = pd.DataFrame()\n",
    "\n",
    "                intensity_image_spots = df_region_props['intensity_image'][i][:,:,:,spotChannel] #show spot channel\n",
    "                intensity_image_nuclei = df_region_props['intensity_image'][i][:,:,:,nucChannel] #show nuclear ring channel\n",
    "\n",
    "                image = df_region_props['image'][i]  # binary 3d mask\n",
    "\n",
    "                # Extract the intensity per distance\n",
    "                mx_spots = np.ma.masked_array(intensity_image_spots, mask = ~image) # 3d masked spot channel\n",
    "                mx_nuclei = np.ma.masked_array(intensity_image_nuclei,mask = ~image) # 3d masked nuclear ring channel\n",
    "                mx_mask = np.ma.masked_array(image,mask = ~image)  # 3d masked binary mask\n",
    "\n",
    "                z_height = image.shape[0]\n",
    "\n",
    "                slice_spots = mx_spots[int(z_height/2)]\n",
    "                slice_nuclei = mx_nuclei[int(z_height/2)]\n",
    "                slice_mask = mx_mask[int(z_height/2)]\n",
    "\n",
    "                slice_mask_edt = edt.edt(slice_mask)\n",
    "                slice_mask_edt = np.ma.masked_array(slice_mask_edt, mask = ~(slice_mask_edt>0)) \n",
    "\n",
    "                results = regionprops_table(slice_mask_edt.astype('int'),slice_nuclei,properties=['label','intensity_mean'])\n",
    "                intensity_dist_nuclei = results['intensity_mean']\n",
    "\n",
    "                results = regionprops_table(slice_mask_edt.astype('int'),slice_spots,properties=['label','intensity_mean'])\n",
    "                intensity_dist_spots = results['intensity_mean']\n",
    "\n",
    "                dist = results['label']\n",
    "\n",
    "                df_nuclei_temp['label']  = [df_region_props.label.iloc[i]]\n",
    "                df_nuclei_temp['bb_dimZ']  = [mx_spots.shape[0]]\n",
    "                df_nuclei_temp['bb_dimY']  = [mx_spots.shape[1]]\n",
    "                df_nuclei_temp['bb_dimX']  = [mx_spots.shape[2]]\n",
    "                df_nuclei_temp['centroid_z'] = df_region_props['centroid-0'][i]\n",
    "                df_nuclei_temp['centroid_y'] = df_region_props['centroid-1'][i]\n",
    "                df_nuclei_temp['centroid_x'] = df_region_props['centroid-2'][i]\n",
    "                df_nuclei_temp['major_axis_length'] = df_region_props['MajorAxisLength'][i]\n",
    "                df_nuclei_temp['solidity'] = df_region_props['solidity'][i]\n",
    "                df_nuclei_temp['mean'] = [np.ma.mean(mx_spots)]\n",
    "                df_nuclei_temp['median'] = [np.ma.median(mx_spots)]\n",
    "                df_nuclei_temp['std']=  [np.ma.std(mx_spots)]\n",
    "                df_nuclei_temp['sum']= [np.ma.sum(mx_spots)]\n",
    "                df_nuclei_temp['variance']= [np.ma.var(mx_spots)]\n",
    "                df_nuclei_temp['max'] = [np.ma.max(mx_spots)]\n",
    "                df_nuclei_temp['min'] = [np.ma.min(mx_spots)]\n",
    "                df_nuclei_temp['volume'] = [np.sum(np.invert(mx_spots.mask))]\n",
    "                df_nuclei_temp['id'] = [df.id.iloc[index]]\n",
    "                df_nuclei_temp['timepoint'] = [t]\n",
    "                df_nuclei_temp['intensity_dist_nuclei'] = [intensity_dist_nuclei]  # this is the emerin ring channel intensity on central slice\n",
    "                df_nuclei_temp['intensity_dist_spots'] = [intensity_dist_spots] # this is the spot channel but not actual detected spots\n",
    "                df_nuclei_temp['intensity_dist'] = [dist]  # this is the distance from the edge of the nucleus\n",
    "                df_nuclei_temp['zproj_spots'] = [np.max(intensity_image_spots[:,:,:], axis = 0)]\n",
    "                df_nuclei_temp['zproj_nuclei'] = [np.max(intensity_image_nuclei[:,:,:], axis = 0)]\n",
    "                df_nuclei_temp['anisotropy'] = [ZvX]\n",
    "\n",
    "                df_nuclei = pd.concat([df_nuclei,df_nuclei_temp])\n",
    "\n",
    "        # save as pickle because has array stored in Dataframe\n",
    "        df_nuclei.to_pickle(output_path+'dist/'+df.id.iloc[index]+'.pkl') # Back up the DF for this FOV\n",
    "\n",
    "        # save with metadata as csv for simple viewing \n",
    "        df_nuclei_for_csv = pd.merge(df_nuclei,df,on='id',how='left')\n",
    "        df_nuclei_for_csv.drop( columns = [ 'intensity_dist_nuclei','intensity_dist_spots','intensity_dist' ], axis=1, inplace=True)\n",
    "        df_nuclei_for_csv.to_csv(output_path+'nuclei/'+df.id.iloc[index]+'.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5596bfee",
   "metadata": {},
   "source": [
    "## Functions for spot detection and qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b7b6731-732e-453e-b8a4-7b1e1fb43ede",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from skimage import filters, restoration\n",
    "from skimage.measure import regionprops_table\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "def preprocess_image(img, spot_channel=1, nucleus_channel=0):\n",
    "    \"\"\"Process 4D (ZYX) images with multiple channels\"\"\"\n",
    "    # Extract channels\n",
    "    spot_img = img[spot_channel]  # Green channel (spots)\n",
    "    nuc_img = img[nucleus_channel]  # Red channel (nuclei)\n",
    "    \n",
    "    # Enhanced spot channel processing\n",
    "    spot_processed = restoration.denoise_tv_chambolle(spot_img, weight=0.1)\n",
    "    spot_processed = exposure.equalize_adapthist(spot_processed, kernel_size=15)\n",
    "    \n",
    "    # Nucleus-based masking\n",
    "    nuc_mask = filters.apply_hysteresis_threshold(nuc_img, low=0.1, high=0.3)\n",
    "    spot_processed[nuc_mask == 0] = 0  # Remove background\n",
    "    \n",
    "    return spot_processed, nuc_mask\n",
    "    \n",
    "def find_spots(img, spot_channel=1, diameter=(3,5,5), separation=(1,3,3)):\n",
    "    \"\"\"3D spot detection with channel alignment\"\"\"\n",
    "    spot_img, nuc_mask = preprocess_image(img, spot_channel)\n",
    "    \n",
    "    features = tp.locate(\n",
    "        spot_img,\n",
    "        diameter=diameter,\n",
    "        separation=separation,\n",
    "        minmass=20,\n",
    "        engine='numba',\n",
    "        processes=4,  # Parallel processing\n",
    "        characterize=True,\n",
    "        threshold=0.3\n",
    "    )\n",
    "    \n",
    "    # Add 3D position validation\n",
    "    features = features[features['mass'] > features['mass'].quantile(0.25)]\n",
    "    return features, spot_img, nuc_mask\n",
    "\n",
    "def extract_spot_features(features, masks, masks_edt):\n",
    "    '''For each spot get the label of the corresponding nucleus and distance to its envelope.'''\n",
    "    \n",
    "    #new\n",
    "    # Ensure the mask is not inverted\n",
    "    if np.max(masks) == 0:  # If the mask is inverted (all nuclei are 0)\n",
    "        masks = np.where(masks > 0, 0, 1)  # Invert the mask\n",
    "\n",
    "        # 3D distance transform\n",
    "    masks_edt = distance_transform_edt(masks)\n",
    "    \n",
    "    features['nuclear_volume'] = np.sum(masks)\n",
    "    features['nuclear_surface'] = np.sum(masks_edt == 1)\n",
    "    \n",
    "    # Add 3D spatial features\n",
    "    features['z_ratio'] = features['z'] / masks.shape[0]\n",
    "    features['radial_position'] = np.sqrt(\n",
    "        (features['x'] - masks.shape[2]/2)**2 +\n",
    "        (features['y'] - masks.shape[1]/2)**2\n",
    "    )\n",
    "    \n",
    "    return features\n",
    "\n",
    "#new changed signal_strength to 1.0\n",
    "def filter_spots(features, measure='signal', filter_dist=True):\n",
    "    \"\"\"Advanced filtering using outlier detection\"\"\"\n",
    "    # Initial filtering\n",
    "    base_mask = (features[measure] > 0.001)\n",
    "    if filter_dist:\n",
    "        base_mask &= (features['dist'] > 0)\n",
    "    \n",
    "    # Train anomaly detector on good features\n",
    "    clf = IsolationForest(contamination=0.1)\n",
    "    X = features[['mass', 'size_z', 'eccentricity', 'signal_to_noise']]\n",
    "    clf.fit(X)\n",
    "    \n",
    "    # Combine filters\n",
    "    final_mask = base_mask & (clf.predict(X) == 1)\n",
    "    \n",
    "    return features[final_mask]\n",
    "    \n",
    "#new\n",
    "def calculate_spots_per_nucleus(df_features):\n",
    "    '''Calculate the number of spots per nucleus and their corresponding volumes.'''\n",
    "    grouped = df_features.groupby('label').agg(\n",
    "        num_spots=('label', 'count'),\n",
    "        nucleus_volume=('nucleus_volume', 'first')  # Volume is the same for all spots in a nucleus\n",
    "    ).reset_index()\n",
    "    return grouped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6189a165-6317-4bf2-a44e-a25bc56a80f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training pipeline \n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "\n",
    "class SpotClassifier:\n",
    "    def __init__(self):\n",
    "        self.model = XGBClassifier(\n",
    "            n_estimators=200,\n",
    "            max_depth=5,\n",
    "            learning_rate=0.01,\n",
    "            subsample=0.8\n",
    "        )\n",
    "    \n",
    "    def train(self, all_features):\n",
    "        # Create training data\n",
    "        X = all_features[[\n",
    "            'mass', 'size_z', 'eccentricity', \n",
    "            'nuclear_volume', 'radial_position'\n",
    "        ]]\n",
    "        y = all_features['valid'] \n",
    "        \n",
    "        # Train/validation split\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X, y, test_size=0.2, stratify=y\n",
    "        )\n",
    "        \n",
    "        # Train with early stopping\n",
    "        self.model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            early_stopping_rounds=20,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        # Save model\n",
    "        joblib.dump(self.model, output_path+'spot_classifier.pkl')\n",
    "    \n",
    "    def predict(self, features):\n",
    "        return self.model.predict_proba(features)[:,1]\n",
    "\n",
    "\n",
    "def process_image_stack(img_4d, classifier, spot_channel=1):\n",
    "    \"\"\"Full processing pipeline for one image stack\"\"\"\n",
    "    # Detect spots\n",
    "    features, spot_img, nuc_mask = find_spots(img_4d, spot_channel)\n",
    "    \n",
    "    # Extract features\n",
    "    features = extract_spot_features(features, nuc_mask, spot_img)\n",
    "    \n",
    "    # Classify spots\n",
    "    features['probability'] = classifier.predict(features)\n",
    "    \n",
    "    # Filter based on probability\n",
    "    valid_spots = features[features['probability'] > 0.7]\n",
    "    \n",
    "    return valid_spots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13bb28a-2df8-4835-ba81-591d6b6a0df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pims\n",
    "# # Get list of .nd2 files in the folder\n",
    "# nd2_files = sorted([f for f in os.listdir(raw_input_path) if f.endswith(\".nd2\")])\n",
    "\n",
    "# # Load all .nd2 images\n",
    "# all_images = [pims.open(os.path.join(raw_input_path, nd2_file)) for nd2_file in nd2_files]\n",
    "\n",
    "# # Access individual frames if needed\n",
    "# first_image = all_images[0][0]  # First frame of the first image\n",
    "classifier = SpotClassifier()\n",
    "classifier.train(full_dataset)\n",
    "# Create labeled dataset (label 100-200 spots per image)\n",
    "labeled_features = []\n",
    "for img in all_images:\n",
    "    features = process_image_stack(img)\n",
    "    features = manually_label(features)  # Add 'valid' column\n",
    "    labeled_features.append(features)\n",
    "\n",
    "full_dataset = pd.concat(labeled_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f546a5be-5c00-4cdd-83ec-8133d19cf190",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_qc_spot_detection(index, df, df_features, img, t=0, display_plot = False,\n",
    "                            measure = 'signal', thresholds = [1 ,2.5, 5, 10], filter_dist=True):\n",
    "    '''Plot the spot detection for a given image using several thresholds for the signal strength (shown on Z projections)'''\n",
    "    z_projection = np.max(img[:,:,:], axis = 0)\n",
    "    #masks_z_projection = np.max(masks[:,:,:], axis = 0)\n",
    "    features_filt_01 = filter_spots(df_features, measure = measure, signal_strength = thresholds[0])\n",
    "    features_filt_02 = filter_spots(df_features, measure = measure, signal_strength = thresholds[1])\n",
    "    features_filt_03 = filter_spots(df_features, measure = measure, signal_strength =  thresholds[2])\n",
    "    features_filt_04 = filter_spots(df_features, measure = measure, signal_strength = thresholds[3])\n",
    "\n",
    "\n",
    "    fig, axs = plt.subplots(2,2,figsize = (6,7),dpi= 450)\n",
    "\n",
    "    for axss in axs:\n",
    "        for ax in axss:\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "\n",
    "\n",
    "    axs[0,0].imshow(z_projection, cmap = 'gray_r')\n",
    "    axs[0,0].scatter(features_filt_01[['x']],features_filt_01[['y']], s = 0.3, linewidths=0.1, alpha = 1, edgecolors = 'red', facecolors='none')\n",
    "    #axs[0,0].contour(masks_z_projection, [0.5], linewidths=0.5, colors='green')\n",
    "    axs[0,0].set_title(f'{measure}>{thresholds[0]} (n={len(features_filt_01)})', fontsize=8,y=-0.01)\n",
    "\n",
    "    axs[0,1].imshow(z_projection, cmap = 'gray_r')\n",
    "    axs[0,1].scatter(features_filt_02[['x']],features_filt_02[['y']], s = 0.3, linewidths=0.1, alpha = 1, edgecolors = 'red', facecolors='none')\n",
    "    #axs[0,1].contour(masks_z_projection, [0.5], linewidths=0.5, colors='green')\n",
    "    axs[0,1].set_title(f'{measure}>{thresholds[1]} (n={len(features_filt_02)})', fontsize=8,y=-0.01)\n",
    "\n",
    "    axs[1,0].imshow(z_projection, cmap = 'gray_r')\n",
    "    axs[1,0].scatter(features_filt_03[['x']],features_filt_03[['y']], s = 0.3, linewidths=0.11, alpha = 1, edgecolors = 'red', facecolors='none')\n",
    "    #axs[1,0].contour(masks_z_projection, [0.5], linewidths=0.5, colors='green')\n",
    "    axs[1,0].set_title(f'{measure}>{thresholds[2]} (n={len(features_filt_03)})', fontsize=8,y=-0.01)\n",
    "\n",
    "    axs[1,1].imshow(z_projection, cmap = 'gray_r')\n",
    "    axs[1,1].scatter(features_filt_04[['x']],features_filt_04[['y']], s = 0.3, linewidths=0.1, alpha = 1, edgecolors = 'red', facecolors='none')\n",
    "    #axs[1,1].contour(masks_z_projection, [0.5], linewidths=0.5, colors='green')\n",
    "    axs[1,1].set_title(f'{measure}>{thresholds[3]} (n={len(features_filt_04)})', fontsize=8,y=-0.01)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.suptitle(f'Spot detection for {df.filename.iloc[index]}', fontsize=10)\n",
    "    #xs[0,0].imshow(masks[10,:,:]>0,cmap = 'gray_r')\n",
    "\n",
    "    if display_plot:\n",
    "        plt.show()\n",
    "    else:\n",
    "        fig.savefig(output_path + 'qc/spots_'+df.id.iloc[index]+'_t'+'{:02d}'.format(t)+'.png')\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e58611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_qc_spot_threshold(index, df, df_spots, t=0, display_plot=False, measure='signal', save_path=output_path):\n",
    "    ''' Fits mixed gaussian model to find threshold of spot mass\n",
    "\n",
    "    Parameters:\n",
    "    index (int): Index of image whose spots should be analysed\n",
    "    df (pd.DataFrame): Data frame with list of image ids\n",
    "\n",
    "    Returns:\n",
    "    Saves a spotThreshold__.pdf for each image with a histogram, model fit and \n",
    "    threshold and returns image id, number of spots and the estimated threshold\n",
    "    '''\n",
    "    #df_spots = pd.read_csv(output_path+'spots/'+df.id.iloc[index]+'.csv')\n",
    "    #df_spots = df_spots[df_spots['timepoint']==t]\n",
    "    x = np.array(df_spots[measure]).reshape(-1,1)\n",
    "    gm =GaussianMixture(n_components=2,random_state=0).fit(x)\n",
    "    mu1=gm.means_[0]\n",
    "    mu2=gm.means_[1]\n",
    "    sigma1=np.sqrt(gm.covariances_[0])\n",
    "    sigma2=np.sqrt(gm.covariances_[1])\n",
    "    threshold=np.round(float(mu1+3*sigma1),2)\n",
    "\n",
    "    x_fit = np.linspace(0,max(x),100)\n",
    "    y_fit = gm.score_samples(x_fit)\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    g = sns.histplot(data=df_spots,x=measure,stat='density',label=\"Data\")\n",
    "    plt.plot(x_fit,np.exp(y_fit),color='red',lw=1,ls='-',label=\"Fitted bimodal distribution\")\n",
    "    plt.axvline(mu1,0,1,color='red',lw=0.5,ls=\"--\",label=\"Mean first gaussian\")\n",
    "    plt.axvline(threshold,0,1,color='red',lw=2,ls=\"-\",label=\"Threshold (mean1+3*SD1)\")\n",
    "    plt.axvline(mu2,0,1,color='red',lw=0.5,ls=\":\",label=\"Mean second gaussian\")\n",
    "    plt.annotate('Threshold='+str(threshold),xy=(0.4,0.9),xycoords='axes fraction')\n",
    "    plt.title('Distribution of spot '+measure+' as mixture of two gaussians')\n",
    "    plt.xlabel(measure)\n",
    "    plt.legend()\n",
    "\n",
    "    if display_plot:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(save_path)\n",
    "        #plt.savefig(output_path + 'qc/spotGMM_'+df.id.iloc[index]+'_t'+'{:02d}'.format(t)+'.pdf')\n",
    "        plt.close()\n",
    "    id=df.id.iloc[index]\n",
    "    num_spot=len(df_spots)\n",
    "    #plt.savefig(save_path)  # Use passed path with PNG extension\n",
    "    #plt.close()\n",
    "    return(num_spot, threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b103e2-a6fa-47cb-8323-cc1dcdc4a59a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_spot_analysis(indices, df, useRaw=True, diameter=(7,9,9), separation=(5,7,7), qc_thresholds=[1,2.5,5,10], filter_dist=True):\n",
    "    '''Finds spots and estimates threshold'''\n",
    "    ids = list()\n",
    "    num_spots = list()\n",
    "    thresholds = list()\n",
    "    timepoints = list()\n",
    "    for index in tqdm.tqdm(indices):\n",
    "        # Load the data\n",
    "        # with ND2Reader(df.filepath.iloc[index]) as images:\n",
    "        #     images.bundle_axes = ['z','x','y','c']\n",
    "        #     img = images[0]\n",
    "        df_features = pd.DataFrame()\n",
    "        if useRaw:\n",
    "            img_5d = BioImage(df.raw_filepath.iloc[index], reader=bioio_nd2.Reader)\n",
    "        else:\n",
    "            img_5d = BioImage(df.denoised_filepath.iloc[index], reader=bioio_tifffile.Reader)\n",
    "        \n",
    "        for t in range(img_5d.dims.T):\n",
    "            img = img_5d.get_image_data(\"ZYX\", T=t, C=spotChannel)\n",
    "\n",
    "            # get masks for this timepoint\n",
    "            masks = BioImage(output_path+'segmentation/'+df.id.iloc[index]+'_t'+'{:02d}'.format(t)+'.tif', reader=bioio_tifffile.Reader)\n",
    "            masks = masks.get_image_data(\"ZYX\", T=0, C=0)\n",
    "\n",
    "            masks_edt = BioImage(output_path+'edt/'+df.id.iloc[index]+'_t'+'{:02d}'.format(t)+'.tif', reader=bioio_tifffile.Reader)\n",
    "            masks_edt = masks_edt.get_image_data(\"ZYX\", T=0, C=0)\n",
    "\n",
    "            # Find the spots (location given in image coordinate system )\n",
    "            df_spots = find_spots(img[:,:,:],diameter = diameter,separation = separation)\n",
    "            df_features_temp = extract_spot_features(df_spots, masks, masks_edt)    # For all the spots calculate the features\n",
    "\n",
    "            #new:\n",
    "            df_features_temp = filter_spots(df_features_temp, measure='signal', signal_strength = 0.0001, filter_dist=filter_dist)\n",
    "\n",
    "            #df_features_temp = filter_spots(df_features_temp, measure='signal', signal_strength = 0.0001, filter_dist=filter_dist)\n",
    "\n",
    "            if len(df_features_temp) > 0:\n",
    "                # Calculate spots per nucleus\n",
    "                spots_per_nucleus = calculate_spots_per_nucleus(df_features_temp)\n",
    "                print(spots_per_nucleus)  # Debugging: Print spots per nucleus\n",
    "\n",
    "                # Append to main table\n",
    "                df_features = pd.concat([df_features, df_features_temp])\n",
    "\n",
    "            if len(df_features_temp) == 0:\n",
    "                print('EMPTY DF!!')\n",
    "                print(df.filename.iloc[index])\n",
    "                print('INDEX:' + str(index))\n",
    "            else:\n",
    "                print('found spots:' + str(len(df_features_temp)))\n",
    "\n",
    "\n",
    "            df_features_temp.loc[:,'id'] = df.id.iloc[index]\n",
    "            df_features_temp.loc[:,'timepoint'] = t\n",
    "\n",
    "            #plot spots detected at different thresholds\n",
    "            plot_qc_spot_detection(index, df, df_features_temp, img, t=t, display_plot = False, measure = 'signal', thresholds = qc_thresholds, filter_dist=filter_dist) # Plot and save the QC of the spot detection\n",
    "\n",
    "            # Use mixed Guassian model to separate background from true spots\n",
    "            num_spot, threshold = plot_qc_spot_threshold(index, df, df_features_temp, t=t, display_plot = False, measure = 'signal')\n",
    "            ids.append(df.id.iloc[index])\n",
    "            timepoints.append(t)\n",
    "            num_spots.append(num_spot)\n",
    "            thresholds.append(threshold)\n",
    "\n",
    "            # append to main table\n",
    "            df_features = pd.concat([df_features,df_features_temp])\n",
    "\n",
    "        # output spot table for each raw image\n",
    "        df_features.to_csv(output_path+'spots/'+df.id.iloc[index]+'.csv') # Back up the DF for this FOV\n",
    "\n",
    "    # output table of spot numbers and thresholds for all images\n",
    "    df_thresholds = pd.DataFrame(data = {'id': ids, 'timepoint': timepoints, 'num_spots': num_spots, 'threshold': thresholds })\n",
    "    df_thresholds.to_csv(output_path+'spotGMMthresholds.csv',index=False)\n",
    "    spots_per_nucleus.to_csv(output_path + 'spots_per_nucleus.csv', index=False)\n",
    "    return df_thresholds\n",
    "\n",
    "\n",
    "def replot_spots_with_thresholds(indices, df, useRaw=True, qc_thresholds=[1,2.5,5,10]):\n",
    "    '''Replots the spot qc images without recalculating the spots, so one can try different qc thresholds'''\n",
    "    for index in tqdm.tqdm(indices):\n",
    "        # Load the data\n",
    "        # with ND2Reader(df.filepath.iloc[index]) as images:\n",
    "        #     images.bundle_axes = ['z','x','y','c']\n",
    "        #     img = images[0]\n",
    "        if useRaw:\n",
    "            img_5d = BioImage(df.raw_filepath.iloc[index], reader=bioio_nd2.Reader)\n",
    "        else:\n",
    "            img_5d = BioImage(df.denoised_filepath.iloc[index], reader=bioio_tifffile.Reader)\n",
    "        \n",
    "        df_features =  pd.read_csv(output_path+'spots/'+df.id.iloc[index]+'.csv') # get spots data\n",
    "\n",
    "        for t in range(img_5d.dims.T):\n",
    "            img = img_5d.get_image_data(\"ZYX\", T=t, C=spotChannel)\n",
    "\n",
    "            # Get masks\n",
    "            masks = BioImage(output_path+'segmentation/'+df.id.iloc[index]+'_t'+'{:02d}'.format(t)+'.tif', reader=bioio_tifffile.Reader)\n",
    "            masks = masks.get_image_data(\"ZYX\", T=0, C=0)\n",
    "\n",
    "            df_features_temp = df_features[df_features['timepoint'] == t]\n",
    "            \n",
    "            #plot spots detected at different thresholds\n",
    "            plot_qc_spot_detection(index, df, df_features_temp, img, t=t, display_plot = False, measure = 'signal', thresholds = qc_thresholds) # Plot and save the QC of the spot detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b657443",
   "metadata": {},
   "source": [
    "## Functions to gather results into single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a8332f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_nuclear_segmentation_data(indices, df):\n",
    "    '''Collects nuclear data from Position-specific directories'''\n",
    "    df_nuclei = pd.DataFrame()\n",
    "    \n",
    "    for index in tqdm.tqdm(indices):\n",
    "        position_id = df.id.iloc[index]  # Should be \"Position_X\"\n",
    "        \n",
    "        # Path to CSV in Position-specific directory\n",
    "        csv_path = os.path.join(\n",
    "            output_path, \n",
    "            position_id,  # Position_X folder\n",
    "            'nuclei',     # Subdirectory for nuclear measurements\n",
    "            f\"{position_id}.csv\" \n",
    "        )\n",
    "        \n",
    "        if os.path.exists(csv_path):\n",
    "            df_tmp = pd.read_csv(csv_path)\n",
    "            df_nuclei = pd.concat([df_nuclei, df_tmp])\n",
    "        else:\n",
    "            print(f\"Warning: Missing {csv_path}\")\n",
    "\n",
    "    # Save combined data\n",
    "    output_file = os.path.join(output_path, f'nuclei_analysis.csv')\n",
    "    df_nuclei.to_csv(output_file, index=False)\n",
    "\n",
    "def collect_nuclear_distance_data(indices, df):\n",
    "    '''Collects nuclear intensity and intensity vs distance data for all nuclei in the dataset'''\n",
    "    df_dist = pd.DataFrame()\n",
    "    for index in tqdm.tqdm(indices):\n",
    "        df_tmp = pd.read_pickle(output_path+'dist/'+df.id.iloc[index]+'.pkl')\n",
    "        df_dist = pd.concat([df_dist,df_tmp])\n",
    "    df_dist.to_pickle(output_path+'dist_analysis_.pkl')\n",
    "\n",
    "\n",
    "def collect_spot_data(indices, df):\n",
    "    '''Collects spot data for all images'''\n",
    "    df_spots = pd.DataFrame()\n",
    "    for index in tqdm.tqdm(indices):\n",
    "        df_tmp = pd.read_csv(output_path+'spots/'+df.id.iloc[index]+'.csv')\n",
    "        df_spots = pd.concat([df_spots,df_tmp])\n",
    "    df_spots.to_csv(output_path+'spots_analysis.csv',index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb392f6-453d-4cb6-92a2-ee9031e4158c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this funciton works well\n",
    "# def plot_comparison_qc(index, df, img, masks, df_no_filter, df_with_filter, t=0, thresholds=[1, 3, 6, 10], output_path='qc_plots'):\n",
    "#     \"\"\"\n",
    "#     Plot comparison of spot detection with and without distance filtering, including full nucleus contours.\n",
    "#     \"\"\"\n",
    "#     # Create output directory if it doesn't exist\n",
    "#     os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "#     # Get maximum intensity projection of the image\n",
    "#     z_projection = np.max(img, axis=0)\n",
    "    \n",
    "#     # Create 2D mask projection and find contours\n",
    "#     from skimage import measure\n",
    "#     mask_2d = np.max(masks, axis=0)  # Max projection of 3D masks to 2D\n",
    "#     contours = measure.find_contours(mask_2d, 0.5)  # Find contours at mid-level\n",
    "    \n",
    "#     # Create figure with two subplots\n",
    "#     fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    \n",
    "#     # Common plotting parameters\n",
    "#     contour_kwargs = {'color': 'red', 'linewidth': 0.7, 'alpha': 0.7}\n",
    "#     spot_colors = ['red', 'blue', 'green', 'yellow']\n",
    "    \n",
    "#     # Plot without distance filtering\n",
    "#     ax1.imshow(z_projection, cmap='gray')\n",
    "#     for contour in contours:\n",
    "#         ax1.plot(contour[:, 1], contour[:, 0], **contour_kwargs)  # (x,y) coordinates\n",
    "#     for i, threshold in enumerate(thresholds):\n",
    "#         spots = df_no_filter[df_no_filter['signal'] > threshold]\n",
    "#         ax1.scatter(spots['x'], spots['y'], s=5, c=spot_colors[i],\n",
    "#                    label=f'Threshold {threshold}')\n",
    "#     ax1.set_title(f\"Without Distance Filtering\\nImage {df.id.iloc[index]}\")\n",
    "#     ax1.legend()\n",
    "    \n",
    "#     # Plot with distance filtering\n",
    "#     ax2.imshow(z_projection, cmap='gray')\n",
    "#     for contour in contours:\n",
    "#         ax2.plot(contour[:, 1], contour[:, 0], **contour_kwargs)\n",
    "#     for i, threshold in enumerate(thresholds):\n",
    "#         spots = df_with_filter[df_with_filter['signal'] > threshold]\n",
    "#         ax2.scatter(spots['x'], spots['y'], s=5, c=spot_colors[i],\n",
    "#                    label=f'Threshold {threshold}')\n",
    "#     ax2.set_title(f\"With Distance Filtering\\nImage {df.id.iloc[index]}\")\n",
    "#     ax2.legend()\n",
    "    \n",
    "#     # Save and close\n",
    "#     plt.tight_layout()\n",
    "#     filename = f\"{output_path}/comparison_qc_image_{df.id.iloc[index]}_t{t:02d}.png\"\n",
    "#     plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "#     plt.close()\n",
    "\n",
    "\n",
    "def plot_comparison_qc(index, df, img, masks, df_no_filter, df_with_filter, t=0, \n",
    "                      thresholds=[1, 3, 6, 10], output_path='qc_plots'):\n",
    "    \"\"\"\n",
    "    Plot comparison of spot detection with max projection and single Z-slice views.\n",
    "    Includes both filtered and unfiltered results.\n",
    "    \"\"\"\n",
    "    from skimage import measure\n",
    "    \n",
    "    # Create output directory\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "    # Get middle Z-slice for single slice view\n",
    "    z_slice_idx = img.shape[0] // 2\n",
    "    z_slice_img = img[z_slice_idx]\n",
    "    z_slice_mask = masks[z_slice_idx]\n",
    "    \n",
    "    # Prepare figure with 2 rows (max projection and single Z) and 2 columns (filtered/unfiltered)\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(20, 20))\n",
    "    \n",
    "    # Common parameters\n",
    "    contour_kwargs = {'color': 'red', 'linewidth': 0.8, 'alpha': 0.7}\n",
    "    spot_size = 5\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Max Projection Views\n",
    "    # ========================================================================\n",
    "    max_projection = np.max(img, axis=0)\n",
    "    max_mask = np.max(masks, axis=0)\n",
    "    max_contours = measure.find_contours(max_mask, 0.5)\n",
    "    \n",
    "    # Max Projection - No Filter\n",
    "    axs[0,0].imshow(max_projection, cmap='gray')\n",
    "    for contour in max_contours:\n",
    "        axs[0,0].plot(contour[:, 1], contour[:, 0], **contour_kwargs)\n",
    "    plot_spots(axs[0,0], df_no_filter, thresholds, spot_size)\n",
    "    axs[0,0].set_title(f\"Max Projection - No Filter\\n{df.id.iloc[index]}\")\n",
    "\n",
    "    # Max Projection - With Filter\n",
    "    axs[0,1].imshow(max_projection, cmap='gray')\n",
    "    for contour in max_contours:\n",
    "        axs[0,1].plot(contour[:, 1], contour[:, 0], **contour_kwargs)\n",
    "    plot_spots(axs[0,1], df_with_filter, thresholds, spot_size)\n",
    "    axs[0,1].set_title(f\"Max Projection - With Filter\\n{df.id.iloc[index]}\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Single Z-Slice Views\n",
    "    # ========================================================================\n",
    "    z_contours = measure.find_contours(z_slice_mask, 0.5)\n",
    "    z_min = z_slice_idx - 0.5\n",
    "    z_max = z_slice_idx + 0.5\n",
    "    \n",
    "    # Single Z - No Filter\n",
    "    axs[1,0].imshow(z_slice_img, cmap='gray')\n",
    "    for contour in z_contours:\n",
    "        axs[1,0].plot(contour[:, 1], contour[:, 0], **contour_kwargs)\n",
    "    plot_spots(axs[1,0], \n",
    "              df_no_filter[(df_no_filter['z'] >= z_min) & (df_no_filter['z'] < z_max)],\n",
    "              thresholds, spot_size)\n",
    "    axs[1,0].set_title(f\"Z-Slice {z_slice_idx} - No Filter\\n{df.id.iloc[index]}\")\n",
    "\n",
    "    # Single Z - With Filter\n",
    "    axs[1,1].imshow(z_slice_img, cmap='gray')\n",
    "    for contour in z_contours:\n",
    "        axs[1,1].plot(contour[:, 1], contour[:, 0], **contour_kwargs)\n",
    "    plot_spots(axs[1,1], \n",
    "              df_with_filter[(df_with_filter['z'] >= z_min) & (df_with_filter['z'] < z_max)],\n",
    "              thresholds, spot_size)\n",
    "    axs[1,1].set_title(f\"Z-Slice {z_slice_idx} - With Filter\\n{df.id.iloc[index]}\")\n",
    "    \n",
    "    # Final formatting\n",
    "    for ax in axs.flat:\n",
    "        ax.axis('off')\n",
    "        ax.legend(loc='upper right', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f\"{output_path}/comparison_qc_image_{df.id.iloc[index]}_t{t:02d}.png\"\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_spots(ax, df, thresholds, size):\n",
    "    \"\"\"Helper function to plot spots with different thresholds\"\"\"\n",
    "    colors = ['red', 'blue', 'green', 'yellow']\n",
    "    for i, threshold in enumerate(thresholds):\n",
    "        spots = df[df['signal'] > threshold]\n",
    "        ax.scatter(spots['x'], spots['y'], s=size, c=colors[i],\n",
    "                  label=f'Thr {threshold}', alpha=0.7)\n",
    "\n",
    "        \n",
    "def compare_filter_dist(indices, df, useRaw, diameter, separation, qc_thresholds, \n",
    "                       signal_strength=0.001, base_path=None, output_path=None):\n",
    "    \"\"\"\n",
    "    Compare spot detection results with filter_dist set to True and False.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Set default paths\n",
    "    if base_path is None:\n",
    "        base_path = '/mnt/external.data/MeisterLab/mvolosko/image_project/sdc1v1/SDC1/1273/20240813_3d'\n",
    "    if output_path is None:\n",
    "        output_path = os.path.join(base_path, 'qc_plots')\n",
    "    \n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for filter_dist in [False, True]:\n",
    "        print(f\"\\nRunning spot detection with filter_dist={filter_dist}...\")\n",
    "        \n",
    "        df_features_all = pd.DataFrame()\n",
    "        for index in indices:\n",
    "            img_5d = BioImage(\n",
    "                df.raw_filepath.iloc[index] if useRaw else df.denoised_filepath.iloc[index],\n",
    "                reader=bioio_nd2.Reader if useRaw else bioio_tifffile.Reader\n",
    "            )\n",
    "            \n",
    "            for t in range(img_5d.dims.T):\n",
    "                img = img_5d.get_image_data(\"ZYX\", T=t, C=spotChannel)\n",
    "                \n",
    "                masks_path = os.path.join(base_path, 'segmentation', \n",
    "                                        f'{df.id.iloc[index]}_t{t:02d}.tif')\n",
    "                masks = BioImage(masks_path, reader=bioio_tifffile.Reader)\n",
    "                masks = masks.get_image_data(\"ZYX\", T=0, C=0)\n",
    "                \n",
    "                edt_path = os.path.join(base_path, 'edt', \n",
    "                                      f'{df.id.iloc[index]}_t{t:02d}.tif')\n",
    "                masks_edt = BioImage(edt_path, reader=bioio_tifffile.Reader)\n",
    "                masks_edt = masks_edt.get_image_data(\"ZYX\", T=0, C=0)\n",
    "\n",
    "                df_spots = find_spots(img, diameter=diameter, separation=separation)\n",
    "                df_features_temp = extract_spot_features(df_spots, masks, masks_edt)\n",
    "                df_features_temp = filter_spots(df_features_temp, measure='signal', \n",
    "                                             signal_strength=signal_strength, \n",
    "                                             filter_dist=filter_dist)\n",
    "\n",
    "                # Add metadata using .loc\n",
    "                df_features_temp.loc[:, 'id'] = df.id.iloc[index]\n",
    "                df_features_temp.loc[:, 'timepoint'] = t\n",
    "                df_features_all = pd.concat([df_features_all, df_features_temp])\n",
    "\n",
    "                # Generate QC plot for this timepoint\n",
    "                opposite_filter = not filter_dist\n",
    "                if opposite_filter in results:  # Check if opposite case is available\n",
    "                    df_opposite = results[opposite_filter][\n",
    "                        (results[opposite_filter]['id'] == df.id.iloc[index]) & \n",
    "                        (results[opposite_filter]['timepoint'] == t\n",
    "                    )]\n",
    "                    # Use current df_features_temp and df_opposite for plotting\n",
    "                    plot_comparison_qc(\n",
    "                        index, df, img, masks, \n",
    "                        df_opposite, df_features_temp,  # Opposite vs current\n",
    "                        t=t, thresholds=qc_thresholds,\n",
    "                        output_path=output_path\n",
    "                    )\n",
    "\n",
    "                df_features_all = pd.concat([df_features_all, df_features_temp])\n",
    "\n",
    "        results[filter_dist] = df_features_all\n",
    "        print(df_features_all.head())\n",
    "        print(f\"Total spots detected with filter_dist={filter_dist}: {len(df_features_all)}\")\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89662d67",
   "metadata": {},
   "source": [
    "## Running the analysis for nuclear segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b5278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # run analysis to segment nuclei\n",
    "indices=range(21, 44)\n",
    "#num 20 didn't work\n",
    "\n",
    "run_nuclear_segmentation(indices, df, rerun=True) \n",
    "\n",
    "run_dist_analysis(indices, df)\n",
    "\n",
    "collect_nuclear_segmentation_data(indices, df)\n",
    "collect_nuclear_distance_data(indices, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6740e891",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices=range(21, 44)\n",
    "#run_dist_analysis(indices, df)\n",
    "collect_nuclear_segmentation_data(indices, df)\n",
    "collect_nuclear_distance_data(indices, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439a487a",
   "metadata": {},
   "source": [
    "## Running the analysis for spot detection\n",
    "This is currently not working well so can ignore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "896ed966",
   "metadata": {},
   "outputs": [],
   "source": [
    "#indices=range(11,14)\n",
    "indices = [26]\n",
    "# indices=range(0,len(df))\n",
    "# indices=range(0,4)\n",
    "\n",
    "# Define parameters for spot detection\n",
    "diameter = (7, 9, 9)  # Spot size\n",
    "separation = (3, 5, 5)  # Minimum separation between spots\n",
    "qc_thresholds = [1, 3, 6, 10]  # Quality control thresholds\n",
    "filter_dist = True  # Whether to filter spots based on nuclear location\n",
    "useRaw = False  # Use denoised images\n",
    "\n",
    "#run_spot_analysis(indices, df, useRaw=True, diameter=(7,9,9), separation=(7,9,9), qc_thresholds=[1,3,6,10])\n",
    "\n",
    "#run_spot_analysis(indices, df, useRaw=False, diameter=(7,9,9), separation=(3,5,5) , qc_thresholds=[1,3,6,10], filter_dist=True)\n",
    "\n",
    "run_spot_analysis(\n",
    "    indices=indices,\n",
    "    df=df,\n",
    "    useRaw=useRaw,\n",
    "    diameter=diameter,\n",
    "    separation=separation,\n",
    "    qc_thresholds=qc_thresholds,\n",
    "    filter_dist=filter_dist\n",
    ")\n",
    "collect_spot_data(indices, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b50739b-241b-48b4-ba5c-5c1873ca2d9a",
   "metadata": {},
   "source": [
    "## Run the comparison between nuclear mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bd65d8-5c29-47d2-96e9-52dd48327dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "indices = [26]\n",
    "# diameter = (7, 9, 9)\n",
    "# separation = (3, 5, 5)\n",
    "diameter = (3, 5, 5)\n",
    "separation = (3, 3, 3)\n",
    "qc_thresholds = [1, 3, 6, 10]\n",
    "useRaw = False\n",
    "\n",
    "base_path = '/mnt/external.data/MeisterLab/mvolosko/image_project/sdc1v1/SDC1/1273/20240813_3d'\n",
    "output_path = os.path.join(base_path, 'qc_plots')\n",
    "\n",
    "\n",
    "comparison_results = compare_filter_dist(\n",
    "    indices=indices,\n",
    "    df=df,\n",
    "    useRaw=useRaw,\n",
    "    diameter=diameter,\n",
    "    separation=separation,\n",
    "    qc_thresholds=qc_thresholds,\n",
    "    base_path=base_path,\n",
    "    output_path=output_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09156db-1913-4e9a-b3bd-d0234a9d888b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a single denoised image\n",
    "denoised_filepath = '/mnt/external.data/MeisterLab/Dario/SDC1/1273/20240813_3d/N2V_sdc1_dpy27_mSG_emr1_mCh/denoised/20240813_1273_E_late_15um_02_n2v.tif'\n",
    "\n",
    "# Load the image\n",
    "img_5d = bioio.BioImage(denoised_filepath, reader=bioio_tifffile.Reader)\n",
    "img = img_5d.get_image_data(\"ZYXC\", T=0, C=spotChannel)\n",
    "\n",
    "# Plot the image\n",
    "plt.imshow(img[40], cmap='gray')\n",
    "plt.title('Denoised Image')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lhcellpose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
