{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69f05b17",
   "metadata": {},
   "source": [
    "# Load lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1291d4c6-a237-4d51-ab40-e0a6ab593d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tifffile\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import filters, measure, morphology, feature, segmentation\n",
    "import bioio\n",
    "import bioio_tifffile\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.morphology import white_tophat, ball\n",
    "import ast\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from skimage.measure import marching_cubes\n",
    "from scipy.stats import norm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f95ede4",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c49f341f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_path=\"/mnt/external.data/MeisterLab/Dario/SDC1/1273/20240813_e/N2V_sdc1_dpy27_mSG_emr1_mCh/denoised/20240813_1273_E_late_15um_08_n2v.tif\",\n",
    "image_path=\"/mnt/external.data/MeisterLab/Dario/DPY27/1268/20240808_e/N2V_dpy27_mSG_emr1_mCh/denoised/20240808_1268_E_late_15um_08_n2v.tif\",\n",
    "nuclei_mask_path=\"/mnt/external.data/MeisterLab/mvolosko/image_project/sdc1v1/SDC1/1273/20240813_3d/segmentation/SDC1_3d_20240813_1273_E_late_15um_08_t00.tif\"\n",
    "nuclei_csv_path=\"/mnt/external.data/MeisterLab/mvolosko/image_project/sdc1v1/SDC1/1273/20240813_3d/nuclei/SDC1_3d_20240813_1273_E_late_15um_08.csv\",\n",
    "mask_path=\"/mnt/external.data/MeisterLab/mvolosko/image_project/sdc1v1/SDC1/1273/20240813_3d/segmentation/SDC1_3d_20240813_1273_E_late_15um_08_t00.tif\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "493f5de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Axes: TCZYX\n",
      "Shape: (36, 2, 18, 1282, 1222)\n"
     ]
    }
   ],
   "source": [
    "from aicsimageio import AICSImage\n",
    "from pathlib import Path\n",
    "\n",
    "img_path = Path(\"/mnt/external.data/MeisterLab/Dario/SDC1/1273/20241010_e_tl/N2V_dpy27_mSG_emr1_mCh/denoised/20241010_1273_E_early_3h_5min_5um_03_n2v.tif\")\n",
    "img = AICSImage(str(img_path))\n",
    "\n",
    "# Print axes and shape\n",
    "print(\"Axes:\", img.dims.order)   # e.g., 'TCZYX'\n",
    "print(\"Shape:\", img.shape)       # tuple of dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d14fecd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 1024, 1006)\n"
     ]
    }
   ],
   "source": [
    "import bioio\n",
    "bio = bioio.BioImage(\"/mnt/external.data/MeisterLab/mvolosko/image_project/SDC1/1273/20241108_e_hs/spots/raw_images_timelapse/20241107_1273_E_30minHS_3h_5min_5um_n2v_t00.ome.tif\")\n",
    "img = bio.get_image_data(\"ZYX\", C=0)\n",
    "print(img.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d825feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_5d_tiff_to_timepoints(input_path: Path, output_dir: Path) -> None:\n",
    "    \"\"\"\n",
    "    Splits a 5D (T, C, Z, Y, X) TIFF into one TIFF per timepoint.\n",
    "    Outputs to output_dir/raw_images_timelapse/t{tt}.tif with tt=00,01,...\n",
    "    \"\"\"\n",
    "    input_dir = Path(input_path)\n",
    "    raw_root = Path(output_dir) / \"raw_images_timelapse\"\n",
    "    raw_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    ext = {\".tif\", \".tiff\"}\n",
    "    for img_path in sorted(input_dir.iterdir()):\n",
    "        if img_path.suffix.lower() not in ext or img_path.stem.endswith('_max'):\n",
    "            continue\n",
    "        sample = img_path.stem\n",
    "        out_sub = raw_root / sample\n",
    "        out_sub.mkdir(exist_ok=True)\n",
    "\n",
    "        # lazy open\n",
    "        img = AICSImage(str(img_path))\n",
    "        n_time, n_chan, n_z, n_y, n_x = img.shape  # (T, C, Z, Y, X)\n",
    "\n",
    "        for t in range(n_time):\n",
    "            # grab channels+Z for this timepoint as (C,Z,Y,X)\n",
    "            czyx = img.get_image_data(\"CZYX\", T=t)\n",
    "            # tifffile wants (Z, Y, X, C)\n",
    "            zyx_c = np.moveaxis(czyx, 0, -1)\n",
    "\n",
    "            # write one multi-page TIFF\n",
    "            out_path = out_sub / f\"t{t:02d}.tif\"\n",
    "            tifffile.imwrite(\n",
    "                str(out_path),\n",
    "                zyx_c,\n",
    "                photometric=\"minisblack\",\n",
    "                metadata={\"axes\": \"ZYCX\"},\n",
    "            )\n",
    "\n",
    "        img.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e9e571f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msplit_5d_tiff_to_timepoints\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/mnt/external.data/MeisterLab/Dario/DPY27/1268/20241010_e_tl/N2V_dpy27_mSG_emr1_mCh/denoised/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/mnt/external.data/MeisterLab/mvolosko/image_project/DPY27/1268/20241010_e_tl/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 24\u001b[0m, in \u001b[0;36msplit_5d_tiff_to_timepoints\u001b[0;34m(input_path, output_dir)\u001b[0m\n\u001b[1;32m     20\u001b[0m n_time, n_chan, n_z, n_y, n_x \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mshape  \u001b[38;5;66;03m# (T, C, Z, Y, X)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_time):\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# grab channels+Z for this timepoint as (C,Z,Y,X)\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     czyx \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_image_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCZYX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# tifffile wants (Z, Y, X, C)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     zyx_c \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmoveaxis(czyx, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/lhcellpose/lib/python3.10/site-packages/aicsimageio/aics_image.py:728\u001b[0m, in \u001b[0;36mAICSImage.get_image_data\u001b[0;34m(self, dimension_order_out, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    726\u001b[0m \u001b[38;5;66;03m# Transform and return\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m transforms\u001b[38;5;241m.\u001b[39mreshape_data(\n\u001b[0;32m--> 728\u001b[0m     data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m,\n\u001b[1;32m    729\u001b[0m     given_dims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims\u001b[38;5;241m.\u001b[39morder,\n\u001b[1;32m    730\u001b[0m     return_dims\u001b[38;5;241m=\u001b[39mdimension_order_out,\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    732\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/lhcellpose/lib/python3.10/site-packages/aicsimageio/aics_image.py:542\u001b[0m, in \u001b[0;36mAICSImage.data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdata\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    531\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;124;03m    Recommended to use `dask_data` for large mosaic images.\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxarray_data\u001b[49m\u001b[38;5;241m.\u001b[39mdata\n",
      "File \u001b[0;32m~/miniconda3/envs/lhcellpose/lib/python3.10/site-packages/aicsimageio/aics_image.py:501\u001b[0m, in \u001b[0;36mAICSImage.xarray_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xarray_data \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    494\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_data_array_to_aics_image_standard(\n\u001b[1;32m    495\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreader\u001b[38;5;241m.\u001b[39mxarray_data\n\u001b[1;32m    496\u001b[0m             )\n\u001b[1;32m    497\u001b[0m         )\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xarray_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_data_array_to_aics_image_standard(\n\u001b[0;32m--> 501\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxarray_data\u001b[49m\n\u001b[1;32m    502\u001b[0m     )\n\u001b[1;32m    504\u001b[0m \u001b[38;5;66;03m# Remake the delayed xarray dataarray object using a rechunked dask array\u001b[39;00m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;66;03m# from the just retrieved in-memory xarray dataarray\u001b[39;00m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xarray_dask_data \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mDataArray(\n\u001b[1;32m    507\u001b[0m     da\u001b[38;5;241m.\u001b[39mfrom_array(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xarray_data\u001b[38;5;241m.\u001b[39mdata),\n\u001b[1;32m    508\u001b[0m     dims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xarray_data\u001b[38;5;241m.\u001b[39mdims,\n\u001b[1;32m    509\u001b[0m     coords\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xarray_data\u001b[38;5;241m.\u001b[39mcoords,\n\u001b[1;32m    510\u001b[0m     attrs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xarray_data\u001b[38;5;241m.\u001b[39mattrs,\n\u001b[1;32m    511\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/lhcellpose/lib/python3.10/site-packages/aicsimageio/readers/reader.py:372\u001b[0m, in \u001b[0;36mReader.xarray_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03mReturns\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;124;03m-------\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;124;03mxarray_data: xr.DataArray\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m    The fully read image and metadata as an annotated data array.\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xarray_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 372\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xarray_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_immediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;66;03m# Remake the delayed xarray dataarray object using a rechunked dask array\u001b[39;00m\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# from the just retrieved in-memory xarray dataarray\u001b[39;00m\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xarray_dask_data \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mDataArray(\n\u001b[1;32m    377\u001b[0m         da\u001b[38;5;241m.\u001b[39mfrom_array(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xarray_data\u001b[38;5;241m.\u001b[39mdata),\n\u001b[1;32m    378\u001b[0m         dims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xarray_data\u001b[38;5;241m.\u001b[39mdims,\n\u001b[1;32m    379\u001b[0m         coords\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xarray_data\u001b[38;5;241m.\u001b[39mcoords,\n\u001b[1;32m    380\u001b[0m         attrs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xarray_data\u001b[38;5;241m.\u001b[39mattrs,\n\u001b[1;32m    381\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/lhcellpose/lib/python3.10/site-packages/aicsimageio/readers/ome_tiff_reader.py:372\u001b[0m, in \u001b[0;36mOmeTiffReader._read_immediate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    367\u001b[0m dims \u001b[38;5;241m=\u001b[39m OmeTiffReader\u001b[38;5;241m.\u001b[39m_guess_ome_dim_order(\n\u001b[1;32m    368\u001b[0m     tiff, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ome, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_scene_index\n\u001b[1;32m    369\u001b[0m )\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# Read image into memory\u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m image_data \u001b[38;5;241m=\u001b[39m \u001b[43mtiff\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseries\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_scene_index\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_general_data_array_constructor(\n\u001b[1;32m    375\u001b[0m     image_data,\n\u001b[1;32m    376\u001b[0m     dims,\n\u001b[1;32m    377\u001b[0m     coords,\n\u001b[1;32m    378\u001b[0m     tiff_tags,\n\u001b[1;32m    379\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/lhcellpose/lib/python3.10/site-packages/tifffile/tifffile.py:11103\u001b[0m, in \u001b[0;36mTiffPageSeries.asarray\u001b[0;34m(self, level, **kwargs)\u001b[0m\n\u001b[1;32m  11101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m  11102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlevels[level]\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m> 11103\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m  11104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m  11105\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(result)\n",
      "File \u001b[0;32m~/miniconda3/envs/lhcellpose/lib/python3.10/site-packages/tifffile/tifffile.py:4104\u001b[0m, in \u001b[0;36mTiffFile.asarray\u001b[0;34m(self, key, series, level, squeeze, out, maxworkers)\u001b[0m\n\u001b[1;32m   4102\u001b[0m     result \u001b[38;5;241m=\u001b[39m page0\u001b[38;5;241m.\u001b[39masarray(out\u001b[38;5;241m=\u001b[39mout, maxworkers\u001b[38;5;241m=\u001b[39mmaxworkers)\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4104\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mstack_pages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxworkers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/lhcellpose/lib/python3.10/site-packages/tifffile/tifffile.py:20970\u001b[0m, in \u001b[0;36mstack_pages\u001b[0;34m(pages, maxworkers, out, **kwargs)\u001b[0m\n\u001b[1;32m  20968\u001b[0m     page0\u001b[38;5;241m.\u001b[39mdecode  \u001b[38;5;66;03m# init TiffPage.decode function\u001b[39;00m\n\u001b[1;32m  20969\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor(maxworkers) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m> 20970\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m executor\u001b[38;5;241m.\u001b[39mmap(func, pages, \u001b[38;5;28mrange\u001b[39m(npages)):\n\u001b[1;32m  20971\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m  20973\u001b[0m filecache\u001b[38;5;241m.\u001b[39mclear()\n",
      "File \u001b[0;32m~/miniconda3/envs/lhcellpose/lib/python3.10/concurrent/futures/_base.py:621\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop(), end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m~/miniconda3/envs/lhcellpose/lib/python3.10/concurrent/futures/_base.py:319\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 319\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    321\u001b[0m         fut\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[0;32m~/miniconda3/envs/lhcellpose/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/miniconda3/envs/lhcellpose/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "split_5d_tiff_to_timepoints(input_path='/mnt/external.data/MeisterLab/Dario/DPY27/1268/20241010_e_tl/N2V_dpy27_mSG_emr1_mCh/denoised/', \n",
    "output_dir= \"/mnt/external.data/MeisterLab/mvolosko/image_project/DPY27/1268/20241010_e_tl/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef0437e",
   "metadata": {},
   "source": [
    "# Spot detection + nuclei filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ec31e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_spots_MPHD(image_path, spot_channel=1, \n",
    "                     sigma=1.3, h_percentile=85,  \n",
    "                     min_distance=2,              \n",
    "                     min_volume=10,                \n",
    "                     max_volume=100, \n",
    "                     intensity_percentile=80,     \n",
    "                     peak_percentile=70,\n",
    "                     nuclei_mask_path=None):         \n",
    "    \"\"\"\n",
    "    MPHD spot detection with adaptive h-dome transformation.\n",
    "    Parameters:\n",
    "    - image_path: Path to the 3D TIFF image.\n",
    "    - spot_channel: Channel index for spot detection.\n",
    "    - sigma: Gaussian smoothing parameter.\n",
    "    - h_percentile: Percentile for adaptive h value.\n",
    "    - min_distance: Minimum distance between detected spots.\n",
    "    - min_volume: Minimum volume of detected spots.\n",
    "    - max_volume: Maximum volume of detected spots.\n",
    "    - intensity_percentile: Percentile for intensity filtering.\n",
    "    - peak_percentile: Percentile for peak thresholding.\n",
    "    - nuclei_mask_path: Optional path to nuclei mask for final filtering\n",
    "    \"\"\"\n",
    "    # Load image\n",
    "    img_4d = bioio.BioImage(image_path, reader=bioio_tifffile.Reader)\n",
    "    img_raw = img_4d.get_image_data(\"ZYX\", T=0, C=spot_channel).astype(np.float32)\n",
    "    \n",
    "    # Normalize to [0,1] based on image statistics\n",
    "    img = (img_raw - img_raw.min()) / (img_raw.max() - img_raw.min() + 1e-6)\n",
    "    \n",
    "    # Load nuclei mask if provided\n",
    "    nuclei_mask = None\n",
    "    if nuclei_mask_path is not None:\n",
    "        mask_4d = bioio.BioImage(nuclei_mask_path, reader=bioio_tifffile.Reader)\n",
    "        nuclei_mask = mask_4d.get_image_data(\"ZYX\", T=0, C=0).astype(bool)\n",
    "        if nuclei_mask.shape != img.shape:\n",
    "            raise ValueError(\"Nuclei mask shape does not match image shape.\")\n",
    "\n",
    "    # Gaussian smoothing with 3D kernel\n",
    "    smoothed = filters.gaussian(img, sigma=sigma)\n",
    "    \n",
    "    # Calculate adaptive h value\n",
    "    non_zero = smoothed[smoothed > 0]\n",
    "    if len(non_zero) == 0:\n",
    "        raise ValueError(\"No signal detected after smoothing!\")\n",
    "        \n",
    "    h = np.percentile(non_zero, h_percentile)\n",
    "    \n",
    "    # 3D h-dome transformation\n",
    "    seed = np.clip(smoothed - h, 0, None)\n",
    "    footprint = morphology.ball(1)\n",
    "    reconstructed = morphology.reconstruction(seed, smoothed, method='dilation', footprint=footprint)\n",
    "    hdome = smoothed - reconstructed\n",
    "    \n",
    "    # Adaptive peak threshold\n",
    "    non_zero_hdome = hdome[hdome > 0]\n",
    "    if len(non_zero_hdome) > 0:\n",
    "        peak_thresh = np.percentile(non_zero_hdome, peak_percentile)\n",
    "    else:\n",
    "        raise ValueError(\"H-dome transformation failed - check h value!\")\n",
    "    \n",
    "    # Detect regional maxima\n",
    "    coordinates = feature.peak_local_max(\n",
    "        hdome,\n",
    "        min_distance=min_distance,\n",
    "        threshold_abs=peak_thresh,\n",
    "        exclude_border=False\n",
    "    )\n",
    "\n",
    "    # Create markers\n",
    "    mask = np.zeros_like(hdome, dtype=bool)\n",
    "    mask[tuple(coordinates.T)] = True\n",
    "    markers = measure.label(mask)\n",
    "\n",
    "    # Watershed segmentation\n",
    "    if hdome.max() > 0:\n",
    "        mask_thresh = hdome > filters.threshold_otsu(hdome)\n",
    "    else:\n",
    "        mask_thresh = np.zeros_like(hdome, dtype=bool)\n",
    "    \n",
    "    labels = segmentation.watershed(-hdome, markers, mask=mask_thresh)\n",
    "\n",
    "    # Measure properties\n",
    "    props = measure.regionprops_table(\n",
    "        labels,\n",
    "        intensity_image=img,\n",
    "        properties=('label', 'centroid', 'area', 'max_intensity')\n",
    "    )\n",
    "    \n",
    "    df = pd.DataFrame(props).rename(columns={\n",
    "        'centroid-0': 'centroid_z', 'centroid-1': 'centroid_y', 'centroid-2': 'centroid_x',\n",
    "        'area': 'volume',\n",
    "        'max_intensity': 'intensity'\n",
    "    })\n",
    "    \n",
    "    # Add peak coordinates\n",
    "    peak_df = pd.DataFrame(coordinates, columns=['peak_z', 'peak_y', 'peak_x'])\n",
    "    peak_df['label'] = markers[tuple(coordinates.T)]\n",
    "    df = df.merge(peak_df, on='label', how='left')\n",
    "\n",
    "    # Intensity filtering\n",
    "    if len(img[img > 0]) > 0:\n",
    "        intensity_thresh = np.percentile(img[img > 0], intensity_percentile)\n",
    "        df = df[df['intensity'] > intensity_thresh]\n",
    "    \n",
    "    # Volume filteringindices=range(11, 14)\n",
    "    df = df[df['volume'].between(min_volume, max_volume)]\n",
    "\n",
    "    # Apply nuclei mask filtering * 0.8\n",
    "    if nuclei_mask is not None:\n",
    "        print(\"Applying nuclei mask filtering to final spots\")\n",
    "        # Convert float coordinates to integer indices\n",
    "        z_coords = np.round(df['centroid_z']).astype(int).clip(0, nuclei_mask.shape[0]-1)\n",
    "        y_coords = np.round(df['centroid_y']).astype(int).clip(0, nuclei_mask.shape[1]-1)\n",
    "        x_coords = np.round(df['centroid_x']).astype(int).clip(0, nuclei_mask.shape[2]-1)\n",
    "        \n",
    "        # Check if spots are in masked regions\n",
    "        in_nuclei = nuclei_mask[z_coords, y_coords, x_coords]\n",
    "        df = df[in_nuclei]\n",
    "        print(f\"After nuclei filtering: {len(df)} spots remaining\")\n",
    "\n",
    "    return df, img, hdome, labels\n",
    "\n",
    "def visualize_results(img, df, hdome, labels):\n",
    "    \"\"\"Visualization for MPHD results\"\"\"\n",
    "    max_proj = np.max(img, axis=0)\n",
    "    hdome_proj = np.max(hdome, axis=0)\n",
    "    # mid_z = img.shape[0] // 2\n",
    "    \n",
    "    # # Filter by PEAK Z-coordinate\n",
    "    # df_mid = df[df['peak_z'] == mid_z]\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(max_proj, cmap='gray', vmax=np.percentile(max_proj, 99.5))\n",
    "    plt.scatter(df['peak_x'], df['peak_y'], s=20, facecolors='none', \n",
    "                edgecolors='red', linewidth=0.5)\n",
    "    plt.title(f\"Detected spots: {len(df)}\")\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(hdome_proj, cmap='viridis')\n",
    "    plt.title(\"H-Dome projection\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88591f80",
   "metadata": {},
   "source": [
    "# Count spots per nuclei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4101ed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def load_nuclei_data(nuclei_csv_path):\n",
    "        \"\"\"Load nuclei data with array columns parsing\"\"\"\n",
    "        df = pd.read_csv(nuclei_csv_path)\n",
    "        \n",
    "        def parse_array(arr_str):\n",
    "            try:\n",
    "                cleaned = re.sub(r'[^\\d\\.,\\[\\]]', '', str(arr_str))\n",
    "                cleaned = re.sub(r',+', ',', cleaned)\n",
    "                return np.array(ast.literal_eval(cleaned))\n",
    "            except (ValueError, SyntaxError):\n",
    "                return np.array([])\n",
    "\n",
    "        # Process array columns\n",
    "        array_cols = ['zproj_spots', 'zproj_nuclei', 'intensity_dist', 'intensity_dist_spots']\n",
    "        for col in array_cols:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].apply(parse_array)\n",
    "        \n",
    "        # Removed incorrect bounding box tuple processing\n",
    "        return df\n",
    "\n",
    "    def count_spots_in_nuclei(spots_df, mask_path, nuclei_df):\n",
    "        \"\"\"Enhanced spot counting with physical coordinate conversion\"\"\"\n",
    "        # Load mask with pixel size handling\n",
    "        mask_img = bioio.BioImage(mask_path, reader=bioio_tifffile.Reader)\n",
    "        mask = mask_img.get_image_data(\"ZYX\", T=0, C=0)\n",
    "        \n",
    "        # Handle physical pixel sizes\n",
    "        try:\n",
    "            pixel_sizes = mask_img.physical_pixel_sizes\n",
    "        except AttributeError:\n",
    "            pixel_sizes = (1.0, 1.0, 1.0)\n",
    "        \n",
    "        # Convert coordinates with pixel size adjustment\n",
    "        spots_df = spots_df.copy()\n",
    "        axis_map = {'z': 0, 'y': 1, 'x': 2}\n",
    "        \n",
    "        for axis in ['z', 'y', 'x']:\n",
    "            ps = pixel_sizes[axis_map[axis]]\n",
    "            dim = mask.shape[axis_map[axis]]\n",
    "            ps_val = ps if ps is not None and ps > 0 else 1.0\n",
    "\n",
    "            col_name = f'centroid_{axis}'\n",
    "            if col_name not in spots_df.columns:\n",
    "                raise ValueError(f\"Missing required column: {col_name}\")\n",
    "                \n",
    "            spots_df[f'{axis}_idx'] = (\n",
    "                spots_df[f'centroid_{axis}']\n",
    "                .div(ps_val)\n",
    "                .round()\n",
    "                .astype(int)\n",
    "                .clip(0, dim - 1)\n",
    "            )\n",
    "        \n",
    "        # Get labels for each spot\n",
    "        mask = mask.astype(np.uint32)\n",
    "        spots_df['nucleus_label'] = mask[\n",
    "            spots_df['z_idx'].values,\n",
    "            spots_df['y_idx'].values,\n",
    "            spots_df['x_idx'].values\n",
    "        ]\n",
    "        \n",
    "        # Ensure label column exists before merging\n",
    "        if 'nucleus_label' not in spots_df.columns:\n",
    "            raise RuntimeError(\"Failed to assign nucleus labels to spots\")\n",
    "        \n",
    "        # Count spots per nucleus with proper merging\n",
    "        spot_counts = (\n",
    "            spots_df[spots_df['nucleus_label'] > 0]\n",
    "            .groupby('nucleus_label', observed=True)\n",
    "            .size()\n",
    "            .rename('spot_count')\n",
    "            .astype(np.uint32)\n",
    "        )\n",
    "        \n",
    "        # Merge with nuclei data\n",
    "        nuclei_df = nuclei_df.merge(\n",
    "            spot_counts,\n",
    "            left_on='label',\n",
    "            right_index=True,\n",
    "            how='left'\n",
    "        ).fillna({'spot_count': 0})\n",
    "        \n",
    "        \n",
    "        return spots_df, nuclei_df\n",
    "\n",
    "    def calculate_spatial_metrics(nuclei_df):\n",
    "        \"\"\"Calculate advanced spatial metrics\"\"\"\n",
    "        # 3D density metrics\n",
    "        if 'volume' in nuclei_df.columns:\n",
    "            nuclei_df['spots_per_volume'] = nuclei_df['spot_count'] / (nuclei_df['volume'] + 1e-6)\n",
    "        \n",
    "        # Surface area approximation\n",
    "        if all(col in nuclei_df.columns for col in ['major_axis_length', 'solidity', 'anisotropy']):\n",
    "            a = nuclei_df['major_axis_length']/2\n",
    "            b = a * nuclei_df['solidity']\n",
    "            c = b * nuclei_df['anisotropy']\n",
    "            nuclei_df['surface_area'] = 4 * np.pi * (((a*b)**1.6 + (a*c)**1.6 + (b*c)**1.6)/3)**(1/1.6)\n",
    "        \n",
    "        return nuclei_df\n",
    "\n",
    "    def visualize_distribution(nuclei_df):\n",
    "        \"\"\"Enhanced visualization with multiple plots and normal distribution fit\"\"\"\n",
    "        fig = plt.figure(figsize=(16, 12))\n",
    "        \n",
    "        # Plot 1: Volume vs Spot Count\n",
    "        ax1 = fig.add_subplot(221)\n",
    "        if 'volume' in nuclei_df.columns and 'spot_count' in nuclei_df.columns:\n",
    "            color_data = nuclei_df['anisotropy'] if 'anisotropy' in nuclei_df.columns else 'blue'\n",
    "            cmap = 'viridis' if 'anisotropy' in nuclei_df.columns else None\n",
    "            scatter = ax1.scatter(\n",
    "                nuclei_df['volume'],\n",
    "                nuclei_df['spot_count'],\n",
    "                c=color_data,\n",
    "                cmap=cmap,\n",
    "                alpha=0.6)\n",
    "            ax1.set_xlabel('Nuclear Volume (pixels³)')\n",
    "            ax1.set_ylabel('Spot count')\n",
    "            # if 'anisotropy' in nuclei_df.columns:\n",
    "            #     plt.colorbar(scatter, ax=ax1, label='Anisotropy')\n",
    "\n",
    "        # Plot 2: Spots per Volume with Normal Fit\n",
    "        ax2 = fig.add_subplot(222)\n",
    "        if 'spots_per_volume' in nuclei_df.columns:\n",
    "            spots_per_vol = nuclei_df['spots_per_volume'].dropna()\n",
    "            if not spots_per_vol.empty:\n",
    "                # Histogram with counts\n",
    "                n, bins, patches = ax2.hist(spots_per_vol, bins=30, alpha=0.6, color='green')\n",
    "                \n",
    "                # Calculate normal distribution parameters\n",
    "                mu, sigma = spots_per_vol.mean(), spots_per_vol.std()\n",
    "                x = np.linspace(spots_per_vol.min(), spots_per_vol.max(), 100)\n",
    "                \n",
    "                # Scale normal curve to match histogram\n",
    "                y = norm.pdf(x, mu, sigma) * len(spots_per_vol) * (bins[1] - bins[0])\n",
    "                ax2.plot(x, y, 'r--', linewidth=2)\n",
    "                ax2.set_xlabel('Spots per volume (spots/pixel³)')\n",
    "                ax2.set_ylabel('Count')\n",
    "                ax2.set_title(f'Normal distribution fit\\nμ={mu:.2f}, σ={sigma:.2f}')\n",
    "\n",
    "        # Plot 3: Spot Count Distribution\n",
    "        ax3 = fig.add_subplot(223)\n",
    "        if 'spot_count' in nuclei_df.columns:\n",
    "            counts = nuclei_df['spot_count'].value_counts().sort_index()\n",
    "            counts.plot(kind='bar', ax=ax3, color='teal')\n",
    "            ax3.set_xlabel('Spot count per nucleus')\n",
    "            ax3.set_ylabel('Frequency')\n",
    "            ax3.set_title('Distribution of spot counts')\n",
    "\n",
    "        # Plot 4: Strain Comparison or Density Plot\n",
    "        ax4 = fig.add_subplot(224)\n",
    "        if 'strain' in nuclei_df.columns and 'spots_per_volume' in nuclei_df.columns:\n",
    "            # Boxplot by strain\n",
    "            strains = nuclei_df['strain'].unique()\n",
    "            data = [nuclei_df[nuclei_df['strain'] == s]['spots_per_volume'].dropna() for s in strains]\n",
    "            ax4.boxplot(data, labels=strains, showmeans=True)\n",
    "            ax4.set_ylabel('Spots per Volume (spots/μm³)')\n",
    "            ax4.set_title('Distribution by Strain')\n",
    "        elif 'spots_per_volume' in nuclei_df.columns:\n",
    "            # Density plot if no strain information\n",
    "            spots_per_vol = nuclei_df['spots_per_volume'].dropna()\n",
    "            if not spots_per_vol.empty:\n",
    "                ax4.hist(spots_per_vol, bins=30, density=True, alpha=0.6, color='purple')\n",
    "                ax4.set_xlabel('Spots per volume (spots/pixel³)')\n",
    "                ax4.set_ylabel('Density')\n",
    "                ax4.set_title('Probability density')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def analyze_spots(spots_df, nuclei_csv_path, mask_path):\n",
    "        \"\"\"Integrated analysis pipeline\"\"\"\n",
    "        print(\"Loading nuclei data...\")\n",
    "        nuclei_df = load_nuclei_data(nuclei_csv_path)\n",
    "        \n",
    "        print(\"Mapping spots to nuclei...\")\n",
    "        with tqdm(total=3) as pbar:\n",
    "            spots_mapped, nuclei_counts = count_spots_in_nuclei(spots_df, mask_path, nuclei_df)\n",
    "            pbar.update(1)\n",
    "            \n",
    "            # Calculate aspect ratios for each plane\n",
    "            nuclei_counts['xy_ratio'] = nuclei_counts.apply(\n",
    "                lambda row: min(row['bb_dimX'], row['bb_dimY']) / max(row['bb_dimX'], row['bb_dimY']), axis=1)\n",
    "            nuclei_counts['xz_ratio'] = nuclei_counts.apply(\n",
    "                lambda row: min(row['bb_dimX'], row['bb_dimZ']) / max(row['bb_dimX'], row['bb_dimZ']), axis=1)\n",
    "            nuclei_counts['yz_ratio'] = nuclei_counts.apply(\n",
    "                lambda row: min(row['bb_dimY'], row['bb_dimZ']) / max(row['bb_dimY'], row['bb_dimZ']), axis=1)\n",
    "            \n",
    "            # Filter nuclei based on aspect ratios\n",
    "            filtered_nuclei = nuclei_counts[\n",
    "                (nuclei_counts['xy_ratio'] >= 0.5) &\n",
    "                (nuclei_counts['xz_ratio'] >= 0.2) &\n",
    "                (nuclei_counts['yz_ratio'] >= 0.2)\n",
    "            ].copy()\n",
    "            \n",
    "            nuclei_metrics = calculate_spatial_metrics(filtered_nuclei)\n",
    "            pbar.update(1)\n",
    "            \n",
    "            print(\"Generating visualizations...\")\n",
    "            visualize_distribution(nuclei_metrics)\n",
    "            pbar.update(1)\n",
    "        \n",
    "        return spots_mapped, nuclei_metrics\n",
    "\n",
    "    def explore_z_stack(img, spots_df, nuclei_mask=None):\n",
    "        \"\"\"\n",
    "        Interactive 3D explorer for image z-stack with spots overlay.\n",
    "        :param img: 3D image array (Z, Y, X) to explore.\n",
    "        :param spots_df: DataFrame with at least 'z_idx', 'y_idx', and 'x_idx' columns.\n",
    "        :param nuclei_mask: (Optional) 3D nuclei mask array to overlay boundaries.\n",
    "        \"\"\"\n",
    "        z_max = img.shape[0] - 1\n",
    "\n",
    "        def plot_slice(z_idx):\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            slice_img = img[z_idx]\n",
    "            plt.imshow(slice_img, cmap='gray', vmax=np.percentile(slice_img, 99))\n",
    "            # Overlay spots which have the same z-slice (or close to it)\n",
    "            idx = spots_df['z_idx'] == z_idx\n",
    "            #idx = spots_df['peak_z'] == z_idx\n",
    "            if idx.sum() > 0:\n",
    "                plt.scatter(spots_df.loc[idx, 'x_idx'],\n",
    "                            spots_df.loc[idx, 'y_idx'],\n",
    "                            s=40, facecolors='none', edgecolors='r', linewidth=1.2)\n",
    "            # Optionally overlay nuclei boundaries if provided\n",
    "            if nuclei_mask is not None:\n",
    "                # Get nuclei mask slice; overlay boundaries\n",
    "                from skimage import measure\n",
    "                slice_mask = nuclei_mask[z_idx].astype(np.uint8)\n",
    "                contours = measure.find_contours(slice_mask, 0.5)\n",
    "                for contour in contours:\n",
    "                    plt.plot(contour[:, 1], contour[:, 0], color='lime', linewidth=1)\n",
    "            plt.title(f\"Z slice: {z_idx}   Spots: {idx.sum()}\")\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "        # Create an interactive widget to scroll through the z-stack.\n",
    "        slider = widgets.IntSlider(min=0, max=z_max, step=1, value=z_max // 2, description='Z Slice:')\n",
    "        widgets.interact(plot_slice, z_idx=slider)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de33f609",
   "metadata": {},
   "source": [
    "# RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4798e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #First run your spot detection\n",
    "    df, img, hdome, labels = detect_spots_MPHD(\n",
    "        image_path=image_path[0],\n",
    "        spot_channel=1,\n",
    "        sigma=1.3,               # Start with smaller sigma\n",
    "        h_percentile=55,         # Lower h-percentile\n",
    "        peak_percentile=70,      # Lower peak threshold\n",
    "        min_distance=1,          # Reduced separation\n",
    "        min_volume=5,            # Smaller volume\n",
    "        max_volume=100,\n",
    "        intensity_percentile=80, # More lenient intensity cutoff\n",
    "        nuclei_mask_path=nuclei_mask_path \n",
    "    )\n",
    "    visualize_results(img, df, hdome, labels)\n",
    "\n",
    "    # Use the results to analyze spots in the nuclei\n",
    "    spots_mapped, nuclei_analysis = analyze_spots(\n",
    "        spots_df=df,\n",
    "        nuclei_csv_path=\"/mnt/external.data/MeisterLab/mvolosko/image_project/sdc1v1/SDC1/1273/20240813_3d/nuclei/SDC1_3d_20240813_1273_E_late_15um_08.csv\",\n",
    "        mask_path=nuclei_mask_path \n",
    "    )\n",
    "\n",
    "\n",
    "    # Save the spots with nucleus labels\n",
    "    spots_mapped = spots_mapped.merge(\n",
    "        nuclei_analysis[['label', 'anisotropy', 'experiment', 'strain']],\n",
    "        left_on='nucleus_label',\n",
    "        right_on='label',\n",
    "        how='left'\n",
    "    ).drop(columns=['label_y']).rename(columns={'label_x': 'label'})\n",
    "\n",
    "    # explore_z_stack(img, spots_mapped, nuclei_mask=None)  \n",
    "    \n",
    "    # Save results\n",
    "    spots_mapped.to_csv(\"/mnt/external.data/MeisterLab/mvolosko/image_project/sdc1v1/spots_with_nucleus_labels.csv\", index=False)\n",
    "    nuclei_analysis.to_csv(\"/mnt/external.data/MeisterLab/mvolosko/image_project/sdc1v1/nuclei_with_spot_counts.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27b80a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the results to analyze spots in the nuclei\n",
    "spots_mapped, nuclei_analysis = analyze_spots(\n",
    "    spots_df=df,\n",
    "    nuclei_csv_path=\"/mnt/external.data/MeisterLab/mvolosko/image_project/sdc1v1/SDC1/1273/20240813_3d/nuclei/SDC1_3d_20240813_1273_E_late_15um_08.csv\",\n",
    "    mask_path=nuclei_mask_path \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cad0753",
   "metadata": {},
   "source": [
    "# Analyse batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf50208b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_folder(\n",
    "    input_dir,\n",
    "    output_dir,\n",
    "    nuclei_mask_dir,\n",
    "    nuclei_csv_dir,\n",
    "    nuclei_prefix='SDC1_e_',\n",
    "    mask_time_suffix='_t00',\n",
    "    **detect_kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    Process all images in a folder for spot detection and nuclei analysis.\n",
    "\n",
    "    Parameters:\n",
    "    - input_dir: Directory containing input TIFF images\n",
    "    - output_dir: Directory to save output CSVs\n",
    "    - nuclei_mask_dir: Directory containing nuclei mask TIFFs\n",
    "    - nuclei_csv_dir: Directory containing nuclei CSV files\n",
    "    - nuclei_prefix: Prefix for nuclei-related filenames\n",
    "    - mask_time_suffix: Time suffix for mask filenames (e.g., '_t00')\n",
    "    - **detect_kwargs: Additional keyword arguments passed to detect_spots_MPHD\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Initialize empty summary DataFrame\n",
    "    summary_df = pd.DataFrame(columns=[\n",
    "        'image', 'total_spots', 'nuclei_data_available',\n",
    "        'mean_spots_per_nuclei', 'median_spots_per_nuclei', 'total_nuclei',\n",
    "        'processing_status', 'error_message'\n",
    "    ])\n",
    "\n",
    "    # Save path for summary file\n",
    "    summary_path = os.path.join(output_dir, 'summary.csv')\n",
    "\n",
    "    # Filter out *_max.tif* files and non-TIFF files\n",
    "    image_files = [\n",
    "        f for f in os.listdir(input_dir)\n",
    "        if f.lower().endswith(('.tif', '.tiff'))\n",
    "        and not os.path.splitext(f)[0].endswith('_max')\n",
    "    ]\n",
    "\n",
    "    for image_file in tqdm(image_files, desc=\"Processing images\"):\n",
    "        image_path = os.path.join(input_dir, image_file)\n",
    "        base_name = os.path.splitext(image_file)[0]\n",
    "\n",
    "        # Initialize row data\n",
    "        row_data = {\n",
    "            'image': image_file,\n",
    "            'processing_status': 'started',\n",
    "            'error_message': '',\n",
    "            'total_spots': 0,\n",
    "            'nuclei_data_available': False,\n",
    "            'mean_spots_per_nuclei': None,\n",
    "            'median_spots_per_nuclei': None,\n",
    "            'total_nuclei': None\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            # Construct nuclei filenames based on naming convention\n",
    "            nuclei_base = f\"{nuclei_prefix}{base_name}\"\n",
    "            mask_filename = f\"{nuclei_base}{mask_time_suffix}.tif\"\n",
    "            csv_filename = f\"{nuclei_base}.csv\"\n",
    "\n",
    "            mask_path = os.path.join(nuclei_mask_dir, mask_filename)\n",
    "            csv_path = os.path.join(nuclei_csv_dir, csv_filename)\n",
    "\n",
    "            mask_exists = os.path.exists(mask_path)\n",
    "            csv_exists = os.path.exists(csv_path)\n",
    "\n",
    "            row_data['nuclei_data_available'] = mask_exists and csv_exists\n",
    "\n",
    "            # Detect spots\n",
    "            spots_df, _, _, _ = detect_spots_MPHD(\n",
    "                image_path,\n",
    "                nuclei_mask_path=mask_path if mask_exists else None,\n",
    "                **detect_kwargs\n",
    "            )\n",
    "\n",
    "            row_data['total_spots'] = len(spots_df)\n",
    "\n",
    "            # Save spots data\n",
    "            spots_output = os.path.join(output_dir, f\"{base_name}_spots.csv\")\n",
    "            spots_df.to_csv(spots_output, index=False)\n",
    "\n",
    "            # Analyze nuclei if data exists\n",
    "            if mask_exists and csv_exists:\n",
    "                try:\n",
    "                    nuclei_df = load_nuclei_data(csv_path)\n",
    "                    spots_mapped, nuclei_metrics = analyze_spots(\n",
    "                        spots_df, csv_path, mask_path, plot=False\n",
    "                    )\n",
    "\n",
    "                    metrics_output = os.path.join(output_dir, f\"{base_name}_nuclei_metrics.csv\")\n",
    "                    nuclei_metrics.to_csv(metrics_output, index=False)\n",
    "\n",
    "                    row_data.update({\n",
    "                        'mean_spots_per_nuclei': nuclei_metrics['spot_count'].mean(),\n",
    "                        'median_spots_per_nuclei': nuclei_metrics['spot_count'].median(),\n",
    "                        'total_nuclei': len(nuclei_metrics)\n",
    "                    })\n",
    "\n",
    "                except Exception as e:\n",
    "                    row_data['error_message'] = f\"Nuclei analysis error: {str(e)}\"\n",
    "\n",
    "            row_data['processing_status'] = 'completed'\n",
    "\n",
    "        except Exception as e:\n",
    "            row_data['processing_status'] = 'failed'\n",
    "            row_data['error_message'] = str(e)\n",
    "\n",
    "        # Update summary DataFrame\n",
    "        summary_df = pd.concat([\n",
    "            summary_df,\n",
    "            pd.DataFrame([row_data])\n",
    "        ], ignore_index=True)\n",
    "\n",
    "        # Save updated summary after each image\n",
    "        summary_df.to_csv(summary_path, index=False)\n",
    "\n",
    "    return summary_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def analyze_spots(\n",
    "    spots_csv_path,\n",
    "    nuclei_csv_path,\n",
    "    mask_path,\n",
    "    output_dir=None,\n",
    "    plot=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Analyze spots in nuclei using saved CSV files\n",
    "    \n",
    "    Parameters:\n",
    "    - spots_csv_path: Path to the CSV file containing spot coordinates\n",
    "    - nuclei_csv_path: Path to the CSV file containing nuclei data\n",
    "    - mask_path: Path to the nuclei mask file\n",
    "    - output_dir: Directory to save output files (optional)\n",
    "    - plot: Whether to generate and save plots (default: False)\n",
    "    \n",
    "    Returns:\n",
    "    - Path to the mapped spots CSV file\n",
    "    - Path to the nuclei metrics CSV file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load data from files\n",
    "        spots_df = pd.read_csv(spots_csv_path)\n",
    "        nuclei_df = load_nuclei_data(nuclei_csv_path)\n",
    "        \n",
    "        # Perform analysis\n",
    "        spots_mapped, nuclei_counts = count_spots_in_nuclei(spots_df, mask_path, nuclei_df)\n",
    "        \n",
    "        # Calculate aspect ratios and filter\n",
    "        nuclei_counts['xy_ratio'] = nuclei_counts.apply(\n",
    "            lambda r: min(r['bb_dimX'], r['bb_dimY']) / max(r['bb_dimX'], r['bb_dimY']), axis=1)\n",
    "        nuclei_counts['xz_ratio'] = nuclei_counts.apply(\n",
    "            lambda r: min(r['bb_dimX'], r['bb_dimZ']) / max(r['bb_dimX'], r['bb_dimZ']), axis=1)\n",
    "        nuclei_counts['yz_ratio'] = nuclei_counts.apply(\n",
    "            lambda r: min(r['bb_dimY'], r['bb_dimZ']) / max(r['bb_dimY'], r['bb_dimZ']), axis=1)\n",
    "        \n",
    "        filtered_nuclei = nuclei_counts[\n",
    "            (nuclei_counts['xy_ratio'] >= 0.5) &\n",
    "            (nuclei_counts['xz_ratio'] >= 0.2) &\n",
    "            (nuclei_counts['yz_ratio'] >= 0.2)\n",
    "        ].copy()\n",
    "        \n",
    "        nuclei_metrics = calculate_spatial_metrics(filtered_nuclei)\n",
    "        \n",
    "        # Save results if output directory is provided\n",
    "        if output_dir:\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            \n",
    "            # Generate output filenames\n",
    "            base_name = os.path.splitext(os.path.basename(spots_csv_path))[0]\n",
    "            spots_output = os.path.join(output_dir, f\"{base_name}_mapped_spots.csv\")\n",
    "            metrics_output = os.path.join(output_dir, f\"{base_name}_nuclei_metrics.csv\")\n",
    "            \n",
    "            # Save results\n",
    "            spots_mapped.to_csv(spots_output, index=False)\n",
    "            nuclei_metrics.to_csv(metrics_output, index=False)\n",
    "            \n",
    "            # Generate and save plots if requested\n",
    "            if plot:\n",
    "                plot_output = os.path.join(output_dir, f\"{base_name}_distribution.png\")\n",
    "                visualize_distribution(nuclei_metrics)\n",
    "                plt.savefig(plot_output)\n",
    "                plt.close()\n",
    "            \n",
    "            return spots_output, metrics_output\n",
    "        else:\n",
    "            return spots_mapped, nuclei_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66caf0c7",
   "metadata": {},
   "source": [
    "# RUN all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b047e227",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_folder(\n",
    "    input_dir='/mnt/external.data/MeisterLab/Dario/SDC1/1273/20240813_e/N2V_sdc1_dpy27_mSG_emr1_mCh/denoised/',\n",
    "    output_dir='/mnt/external.data/MeisterLab/mvolosko/image_project/sdc1/SDC1/1273/20240813_e/spots/',\n",
    "    nuclei_mask_dir='/mnt/external.data/MeisterLab/mvolosko/image_project/sdc1v1/SDC1/1273/20240813_3d/segmentation/',\n",
    "    nuclei_csv_dir='/mnt/external.data/MeisterLab/mvolosko/image_project/sdc1v1/SDC1/1273/20240813_3d/nuclei/',\n",
    "    sigma=1,\n",
    "    h_percentile=85\n",
    ")\n",
    "analyze_spots(spots_df, nuclei_csv_path='/mnt/external.data/MeisterLab/mvolosko/image_project/sdc1v1/SDC1/1273/20240813_3d/nuclei/',\n",
    " mask_path='/mnt/external.data/MeisterLab/mvolosko/image_project/sdc1v1/SDC1/1273/20240813_3d/segmentation/', plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d62a3f1",
   "metadata": {},
   "source": [
    "# One use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473569d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect spots and visualize\n",
    "df, img, hdome, labels = detect_spots_MPHD('path/to/single_image.tif')\n",
    "visualize_results(img, df, hdome, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccc225a",
   "metadata": {},
   "source": [
    "# 3 D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c73faedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_nuclei_3d(spots_df, mask, nuclei_df, step_size=2, level=0.5, z_range=None):\n",
    "    \"\"\"\n",
    "    Modified 3D rendering with aspect ratio filtering\n",
    "    \"\"\"\n",
    "    # Filter nuclei based on aspect ratios first\n",
    "    filtered_nuclei = nuclei_df[\n",
    "        (nuclei_df['xy_ratio'] >= 0.5) &\n",
    "        (nuclei_df['xz_ratio'] >= 0.2) &\n",
    "        (nuclei_df['yz_ratio'] >= 0.2)\n",
    "    ]\n",
    "    \n",
    "    mask = mask.astype(np.uint16)\n",
    "    labels_to_plot = filtered_nuclei['label'].tolist()\n",
    "\n",
    "    if z_range is not None:\n",
    "        z_start, z_end = z_range\n",
    "        mask = mask[z_start:z_end]\n",
    "        spots_df = spots_df[(spots_df['z_idx'] >= z_start) & (spots_df['z_idx'] < z_end)].copy()\n",
    "        spots_df['z_idx'] -= z_start\n",
    "\n",
    "    print(f\"Rendering {len(labels_to_plot)} filtered nuclei...\")\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for label in labels_to_plot:\n",
    "        binary_mask = (mask == label).astype(np.uint8)\n",
    "        if np.count_nonzero(binary_mask) == 0:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            verts, faces, normals, values = marching_cubes(\n",
    "                binary_mask, \n",
    "                level=level, \n",
    "                step_size=step_size\n",
    "            )\n",
    "        except RuntimeError:\n",
    "            continue\n",
    "\n",
    "        z, y, x = verts.T\n",
    "        i, j, k = faces.T\n",
    "\n",
    "        # Get matching nucleus data for coloring\n",
    "        nucleus_data = filtered_nuclei[filtered_nuclei['label'] == label].iloc[0]\n",
    "        \n",
    "        fig.add_trace(go.Mesh3d(\n",
    "            x=x, y=y, z=z,\n",
    "            i=i, j=j, k=k,\n",
    "            opacity=0.3,\n",
    "            color='orange',\n",
    "            name=f'Nucleus {label} (Spots: {nucleus_data[\"spot_count\"]})',\n",
    "            text=[\n",
    "                f\"Volume: {nucleus_data['volume']}<br>\"\n",
    "                f\"Spots: {nucleus_data['spot_count']}<br>\"\n",
    "                f\"XY Ratio: {nucleus_data['xy_ratio']:.2f}<br>\"\n",
    "                f\"XZ Ratio: {nucleus_data['xz_ratio']:.2f}\"\n",
    "            ],\n",
    "            hoverinfo='text',\n",
    "            flatshading=True\n",
    "        ))\n",
    "\n",
    "    # Plot spots with same filtering\n",
    "    filtered_spots = spots_df[spots_df['nucleus_label'].isin(labels_to_plot)]\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=filtered_spots['x_idx'],\n",
    "        y=filtered_spots['y_idx'],\n",
    "        z=filtered_spots['z_idx'],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=5,\n",
    "            color=filtered_spots['nucleus_label'],\n",
    "            colorscale='Viridis',\n",
    "            opacity=0.6,\n",
    "            colorbar=dict(title='Nucleus ID')\n",
    "        ),\n",
    "        name='Spots',\n",
    "        hovertext=filtered_spots['label']\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title='3D Filtered Nuclei and Spots',\n",
    "        scene=dict(\n",
    "            xaxis_title='X', \n",
    "            yaxis_title='Y', \n",
    "            zaxis_title='Z',\n",
    "            aspectmode='data'\n",
    "        ),\n",
    "        margin=dict(l=0, r=0, b=0, t=30)\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7a67c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_path=\"/mnt/external.data/MeisterLab/mvolosko/image_project/sdc1v1/SDC1/1273/20240813_3d/segmentation/SDC1_3d_20240813_1273_E_late_15um_08_t00.tif\"\n",
    "nuclei_csv_path=\"/mnt/external.data/MeisterLab/mvolosko/image_project/sdc1v1/SDC1/1273/20240813_3d/nuclei/SDC1_3d_20240813_1273_E_late_15um_08.csv\"\n",
    "mask_img = bioio.BioImage(mask_path, reader=bioio_tifffile.Reader)\n",
    "nuclei_mask = mask_img.get_image_data(\"ZYX\", T=0, C=0)\n",
    "nuclei_df = load_nuclei_data(\"/mnt/external.data/MeisterLab/mvolosko/image_project/sdc1v1/nuclei_with_spot_counts.csv\")\n",
    "\n",
    "render_nuclei_3d(spots_mapped, nuclei_mask, nuclei_analysis, z_range=(15, 40))#.sample(40).tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4860c6",
   "metadata": {},
   "source": [
    "# Previous tries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8af122d",
   "metadata": {},
   "source": [
    "## LoG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a47383",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_spots(image_path, spot_channel=1, \n",
    "                log_sigma=1.8, threshold_abs=0.2,\n",
    "                min_distance=3, min_volume=8, max_volume=50,\n",
    "                intensity_percentile=90):\n",
    "    \"\"\"\n",
    "    Spot detection optimized for black background/white spots\n",
    "    \"\"\"\n",
    "    # Load image directly without background subtraction\n",
    "    img_4d = bioio.BioImage(image_path, reader=bioio_tifffile.Reader)\n",
    "    img = img_4d.get_image_data(\"ZYX\", T=0, C=spot_channel).astype(np.float32)\n",
    "\n",
    "    # Direct LoG processing on raw image\n",
    "    log = filters.gaussian(img, sigma=log_sigma)\n",
    "    log = filters.laplace(log)\n",
    "    log = -log  # Enhance bright spots\n",
    "\n",
    "    # Adaptive threshold calculation\n",
    "    non_zero_log = log[log > 0]\n",
    "    if len(non_zero_log) > 0:\n",
    "        adaptive_thresh = np.percentile(non_zero_log, 99)  # Focus on top 1% intensities\n",
    "    else:\n",
    "        adaptive_thresh = 0.1  # Fallback threshold\n",
    "\n",
    "    # Find regional maxima\n",
    "    coordinates = feature.peak_local_max(\n",
    "        log,\n",
    "        min_distance=min_distance,\n",
    "        threshold_abs=adaptive_thresh,\n",
    "        exclude_border=False\n",
    "    )\n",
    "\n",
    "    # Create markers\n",
    "    mask = np.zeros_like(log, dtype=bool)\n",
    "    mask[tuple(coordinates.T)] = True\n",
    "    markers = measure.label(mask)\n",
    "\n",
    "    # Watershed with dynamic mask\n",
    "    mask_thresh = log > filters.threshold_otsu(log) if log.max() > 0 else np.zeros_like(log, dtype=bool)\n",
    "    labels = segmentation.watershed(-log, markers, mask=mask_thresh)\n",
    "\n",
    "    # Measure properties\n",
    "    props = measure.regionprops_table(\n",
    "        labels,\n",
    "        intensity_image=img,  # Use original image for intensity measurements\n",
    "        properties=('centroid', 'area', 'max_intensity')\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame(props).rename(columns={\n",
    "        'centroid-0': 'z', 'centroid-1': 'y', 'centroid-2': 'x',\n",
    "        'area': 'volume',\n",
    "        'max_intensity': 'intensity'\n",
    "    })\n",
    "    \n",
    "    # Intensity filtering based on original image\n",
    "    intensity_thresh = np.percentile(img[img > 0], intensity_percentile)  # Focus on non-zero pixels\n",
    "    df = df[\n",
    "        (df['volume'].between(min_volume, max_volume)) &\n",
    "        (df['intensity'] > intensity_thresh)\n",
    "    ]\n",
    "\n",
    "    return df, img, log, labels\n",
    "\n",
    "def visualize_results(img, df, log, labels):\n",
    "    \"\"\"Visualization focusing on original image characteristics\"\"\"\n",
    "    max_proj = np.max(img, axis=0)\n",
    "    log_proj = np.max(log, axis=0)\n",
    "\n",
    "      # Find middle Z-slice and its detections\n",
    "    mid_z = img.shape[0] // 2\n",
    "    df_mid = df[df['z'].round().astype(int) == mid_z]  # Match spots to slice\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(max_proj, cmap='gray', vmax=np.percentile(max_proj, 99.5))\n",
    "    plt.scatter(df['x'], df['y'], s=30, facecolors='none', marker='o', \n",
    "                edgecolors='magenta', linewidth=0.8, alpha=0.8)\n",
    "    plt.title(f\"Detected spots: {len(df)}\")\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(log_proj, cmap='viridis')#, vmax=np.percentile(log_proj, 99.5))\n",
    "    plt.contour(log_proj > np.percentile(log, 99.5), colors='white', alpha=0.3)\n",
    "    plt.title(\"Processed LoG Image\")\n",
    "    \n",
    "    # Z-slice validation\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(img[mid_z], cmap='gray')\n",
    "    plt.scatter(df_mid['x'], df_mid['y'], s=60, facecolors='none',\n",
    "                marker='o', edgecolors='red', linewidth=0.8)\n",
    "    plt.title(f\"Z={mid_z} Validation: {len(df_mid)} spots\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    df, img, log, labels = detect_spots(\n",
    "        image_path=\"/mnt/external.data/MeisterLab/Dario/SDC1/1273/20240813_3d/N2V_sdc1_dpy27_mSG_emr1_mCh/denoised/20240813_1273_E_late_15um_08_n2v.tif\",\n",
    "        spot_channel=1,\n",
    "        log_sigma=0.001,             # Adjust based on actual spot size\n",
    "        threshold_abs=0.2,         # Start with 0.1-0.3 range\n",
    "        min_distance=1,            # Physical separation between spots\n",
    "        min_volume=10,             # Minimum voxels per spot\n",
    "        max_volume=50,             # Maximum voxels per spot\n",
    "        intensity_percentile=99.5    # Strong intensity cutoff\n",
    "    )\n",
    "    visualize_results(img, df, log, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a811d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_spots(image_path, spot_channel=1, sigma_xy=1.0, sigma_z=0.5,\n",
    "                 threshold_percentile=99, min_volume=10):\n",
    "    \"\"\"\n",
    "    Detect spots in a 3D z-stack TIFF image.\n",
    "    \"\"\"\n",
    "    # Load image with proper dimension handling\n",
    "    img_4d = bioio.BioImage(image_path, reader=bioio_tifffile.Reader)\n",
    "    img = img_4d.get_image_data(\"ZYX\", T=0, C=spot_channel)  # Direct 3D array\n",
    "\n",
    "    # Preprocessing: 3D Gaussian blur\n",
    "    blurred = filters.gaussian(\n",
    "        img,\n",
    "        sigma=(sigma_z, sigma_xy, sigma_xy),\n",
    "        mode='nearest'\n",
    "    )\n",
    "\n",
    "    # Thresholding\n",
    "    threshold = np.percentile(blurred, threshold_percentile)\n",
    "    binary_mask = blurred > threshold\n",
    "\n",
    "    # Remove small objects\n",
    "    cleaned_mask = morphology.remove_small_objects(binary_mask, min_size=min_volume)\n",
    "\n",
    "    # Label regions and measure properties\n",
    "    label_image = measure.label(cleaned_mask)\n",
    "    props = measure.regionprops_table(\n",
    "        label_image,\n",
    "        intensity_image=blurred,\n",
    "        properties=('centroid', 'area', 'mean_intensity')\n",
    "    )\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(props)\n",
    "    df = df.rename(columns={\n",
    "        'centroid-0': 'z',\n",
    "        'centroid-1': 'y',\n",
    "        'centroid-2': 'x',\n",
    "        'area': 'volume',\n",
    "        'mean_intensity': 'intensity'\n",
    "    })\n",
    "\n",
    "    return df, img\n",
    "\n",
    "def visualize_results(img, df):\n",
    "    \"\"\"Plot maximum projection with detected spots and middle Z-slice.\"\"\"\n",
    "    max_proj = np.max(img, axis=0)\n",
    "    mid_z = img.shape[0] // 2\n",
    "\n",
    "    # Find spots within ±0.5 of middle Z-slice (strict middle plane)\n",
    "    df_mid = df[(df['z'] >= mid_z - 0.5) & (df['z'] < mid_z + 0.5)]\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Max projection\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(max_proj, cmap='gray')\n",
    "    plt.scatter(df['x'], df['y'], s=40, facecolors='none', marker='o', \n",
    "                edgecolors='red', linewidths=0.5)\n",
    "    plt.title(f\"Max Projection: {len(df)} spots\")\n",
    "    \n",
    "    # Middle slice\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(img[mid_z], cmap='gray')\n",
    "    plt.scatter(df_mid['x'], df_mid['y'], s=40, facecolors='none', marker='o', \n",
    "                edgecolors='red', linewidths=0.5)\n",
    "    plt.title(f\"Z={mid_z} Slice: {len(df_mid)} spots\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    df, img = detect_spots(\n",
    "        image_path=\"/mnt/external.data/MeisterLab/Dario/SDC1/1273/20240813_3d/N2V_sdc1_dpy27_mSG_emr1_mCh/denoised/20240813_1273_E_late_15um_08_n2v.tif\",\n",
    "        spot_channel=1,\n",
    "        sigma_xy=0,\n",
    "        sigma_z=0,\n",
    "        threshold_percentile=99,\n",
    "        min_volume=0\n",
    "    )\n",
    "    visualize_results(img, df)\n",
    "    print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743443d6",
   "metadata": {},
   "source": [
    "## Spots with background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e64210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_spots_MPHD(image_path, spot_channel=1, \n",
    "                     sigma=1.8, h_percentile=85,  \n",
    "                     min_distance=2,              \n",
    "                     min_volume=5,                \n",
    "                     max_volume=100, \n",
    "                     intensity_percentile=80,     \n",
    "                     peak_percentile=90):         \n",
    "    \"\"\"\n",
    "    MPHD spot detection with adaptive h-dome transformation.\n",
    "    Parameters:\n",
    "    - image_path: Path to the 3D TIFF image.\n",
    "    - spot_channel: Channel index for spot detection.\n",
    "    - sigma: Gaussian smoothing parameter.\n",
    "    - h_percentile: Percentile for adaptive h value.\n",
    "    - min_distance: Minimum distance between detected spots.\n",
    "    - min_volume: Minimum volume of detected spots.\n",
    "    - max_volume: Maximum volume of detected spots.\n",
    "    - intensity_percentile: Percentile for intensity filtering.\n",
    "    - peak_percentile: Percentile for peak thresholding.\n",
    "    \"\"\"\n",
    "    # Load image with intensity scaling\n",
    "    img_4d = bioio.BioImage(image_path, reader=bioio_tifffile.Reader)\n",
    "    img_raw = img_4d.get_image_data(\"ZYX\", T=0, C=spot_channel).astype(np.float32)\n",
    "    \n",
    "    # Normalize to [0,1] based on image statistics\n",
    "    img = (img_raw - img_raw.min()) / (img_raw.max() - img_raw.min() + 1e-6)\n",
    "    \n",
    "    # Diagnostic output\n",
    "    print(f\"Image intensity stats - Min: {img.min():.3f}, Max: {img.max():.3f}, Mean: {img.mean():.3f}\")\n",
    "    \n",
    "    # Gaussian smoothing with 3D kernel\n",
    "    smoothed = filters.gaussian(img, sigma=sigma)\n",
    "    \n",
    "    # Calculate adaptive h value\n",
    "    non_zero = smoothed[smoothed > 0]\n",
    "    if len(non_zero) == 0:\n",
    "        raise ValueError(\"No signal detected after smoothing!\")\n",
    "        \n",
    "    h = np.percentile(non_zero, h_percentile)\n",
    "    print(f\"Calculated h-value: {h:.3f} (percentile {h_percentile})\")\n",
    "    \n",
    "    # 3D h-dome transformation\n",
    "    seed = np.clip(smoothed - h, 0, None)\n",
    "    footprint = morphology.ball(1)\n",
    "    reconstructed = morphology.reconstruction(seed, smoothed, method='dilation', footprint=footprint)\n",
    "    hdome = smoothed - reconstructed\n",
    "    \n",
    "    # Diagnostic visualization\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(np.max(smoothed, axis=0), cmap='gray')\n",
    "    plt.title(\"Smoothed Image\")\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(np.max(seed, axis=0), cmap='gray')\n",
    "    plt.title(f\"Seed Image (h={h:.3f})\")\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(np.max(hdome, axis=0), cmap='viridis')\n",
    "    plt.title(\"H-Dome Projection\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Adaptive peak threshold\n",
    "    non_zero_hdome = hdome[hdome > 0]\n",
    "    if len(non_zero_hdome) > 0:\n",
    "        peak_thresh = np.percentile(non_zero_hdome, peak_percentile)\n",
    "        print(f\"Peak threshold: {peak_thresh:.3f} (percentile {peak_percentile})\")\n",
    "    else:\n",
    "        raise ValueError(\"H-dome transformation failed - check h value!\")\n",
    "    \n",
    "    # Detect regional maxima with relaxed thresholds\n",
    "    coordinates = feature.peak_local_max(\n",
    "        hdome,\n",
    "        min_distance=min_distance,\n",
    "        threshold_abs=peak_thresh * 0.8,  # 20% margin\n",
    "        exclude_border=False\n",
    "    )\n",
    "    \n",
    "    print(f\"Initial candidates: {len(coordinates)} spots\")\n",
    "    \n",
    "    peak_df = pd.DataFrame(coordinates, columns=['peak_z', 'peak_y', 'peak_x'])\n",
    "    \n",
    "    # Create markers\n",
    "    mask = np.zeros_like(hdome, dtype=bool)\n",
    "    mask[tuple(coordinates.T)] = True\n",
    "    markers = measure.label(mask)\n",
    "\n",
    "    # Watershed segmentation with Otsu masking\n",
    "    if hdome.max() > 0:\n",
    "        mask_thresh = hdome > filters.threshold_otsu(hdome)\n",
    "    else:\n",
    "        mask_thresh = np.zeros_like(hdome, dtype=bool)\n",
    "    \n",
    "    labels = segmentation.watershed(-hdome, markers, mask=mask_thresh)\n",
    "\n",
    "    # Measure properties including original label IDs\n",
    "    props = measure.regionprops_table(\n",
    "        labels,\n",
    "        intensity_image=img,\n",
    "        properties=('label', 'centroid', 'area', 'max_intensity')\n",
    "    )\n",
    "    \n",
    "    df = pd.DataFrame(props).rename(columns={\n",
    "        'centroid-0': 'centroid_z', 'centroid-1': 'y', 'centroid-2': 'x',\n",
    "        'area': 'volume',\n",
    "        'max_intensity': 'intensity'\n",
    "    })\n",
    "    \n",
    "    # Add peak coordinates using label mapping\n",
    "    peak_df['label'] = markers[tuple(coordinates.T)]  # Get label for each peak\n",
    "    df = df.merge(peak_df, on='label', how='left')\n",
    "\n",
    "    # Intensity filtering\n",
    "    if len(img[img > 0]) > 0:\n",
    "        intensity_thresh = np.percentile(img[img > 0], intensity_percentile)\n",
    "        df = df[df['intensity'] > intensity_thresh]\n",
    "    \n",
    "    # Volume filtering\n",
    "    df = df[df['volume'].between(min_volume, max_volume)]\n",
    "\n",
    "    return df, img, hdome, labels\n",
    "\n",
    "\n",
    "def visualize_results(img, df, hdome, labels):\n",
    "    \"\"\"Visualization for MPHD results\"\"\"\n",
    "    max_proj = np.max(img, axis=0)\n",
    "    hdome_proj = np.max(hdome, axis=0)\n",
    "    mid_z = img.shape[0] // 2\n",
    "    \n",
    "    # Filter by PEAK Z-coordinate\n",
    "    df_mid = df[df['peak_z'] == mid_z]\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(max_proj, cmap='gray', vmax=np.percentile(max_proj, 99.5))\n",
    "    plt.scatter(df['peak_x'], df['peak_y'], s=20, facecolors='none', \n",
    "                edgecolors='red', linewidth=0.5)\n",
    "    plt.title(f\"Detected spots: {len(df)}\")\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(hdome_proj, cmap='viridis')\n",
    "    plt.title(\"H-Dome Projection\")\n",
    "    \n",
    "\n",
    "# # Usage with recommended starting parameters\n",
    "# if __name__ == \"__main__\":\n",
    "#     df, img, hdome, labels = detect_spots_MPHD(\n",
    "#         #image_path=\"/mnt/external.data/MeisterLab/Dario/SDC1/1273/20240813_3d/N2V_sdc1_dpy27_mSG_emr1_mCh/denoised/20240813_1273_E_late_15um_08_n2v.tif\",\n",
    "#         image_path=\"/mnt/external.data/MeisterLab/Dario/DPY27/1268/20240808_3d/N2V_dpy27_mSG_emr1_mCh/denoised/20240808_1268_E_late_15um_08_n2v.tif\",\n",
    "#         spot_channel=1,\n",
    "#         sigma=1,               # Start with smaller sigma\n",
    "#         h_percentile=70,         # Lower h-percentile\n",
    "#         peak_percentile=75,      # Lower peak threshold\n",
    "#         min_distance=2,          # Reduced separation\n",
    "#         min_volume=5,            # Smaller volume\n",
    "#         max_volume=150,\n",
    "#         intensity_percentile=80  # More lenient intensity cutoff\n",
    "#     )\n",
    "#     visualize_results(img, df, hdome, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99c585a",
   "metadata": {},
   "source": [
    "# 3 d old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df4a517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3d_spots_and_nuclei(spots_df, nuclei_df, color_by='nucleus_label'):\n",
    "    \"\"\"\n",
    "    Creates an interactive 3D scatter plot of spot and nuclei data.\n",
    "\n",
    "    :param spots_df: DataFrame with 'x_idx', 'y_idx', 'z_idx', and optionally 'nucleus_label'.\n",
    "    :param nuclei_df: DataFrame with 'centroid_x', 'centroid_y', 'centroid_z'.\n",
    "    :param color_by: Column in spots_df to color by (e.g., 'nucleus_label' or 'intensity').\n",
    "    \"\"\"\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Plot spots\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=spots_df['x_idx'],\n",
    "        y=spots_df['y_idx'],\n",
    "        z=spots_df['z_idx'],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=6,\n",
    "            color=spots_df[color_by] if color_by in spots_df.columns else 'red',\n",
    "            colorscale='Viridis',\n",
    "            opacity=0.6,\n",
    "            colorbar=dict(title=color_by)\n",
    "        ),\n",
    "        name='Spots'\n",
    "    ))\n",
    "\n",
    "    # Plot nuclei centroids\n",
    "    if all(f'centroid_{ax}' in nuclei_df.columns for ax in ['x', 'y', 'z']):\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=nuclei_df['centroid_x'],\n",
    "            y=nuclei_df['centroid_y'],\n",
    "            z=nuclei_df['centroid_z'],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=15,\n",
    "                color='orange',\n",
    "                opacity=0.3,\n",
    "                symbol='circle'\n",
    "            ),\n",
    "            name='Nuclei Centers'\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            xaxis_title='X',\n",
    "            yaxis_title='Y',\n",
    "            zaxis_title='Z',\n",
    "            aspectmode='data',\n",
    "        ),\n",
    "        title='3D Visualization of Spots and Nuclei',\n",
    "        height=800\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "#spots_mapped, nuclei_metrics = analyze_spots(spots_df, nuclei_csv_path, mask_path)\n",
    "\n",
    "# Call the 3D plot function\n",
    "plot_3d_spots_and_nuclei(spots_mapped, nuclei_analysis, color_by='nucleus_label')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lhcellpose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
