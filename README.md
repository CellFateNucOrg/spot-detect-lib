
# spot-detect-lib

This repository focuses on spot detection in microscopic images with segmented nuclei.

To get started, clone this Git repository. While scripts are optimized for GPU (nuclei pipeline) and multi-core processing (spot segmentation pipeline) on servers, you can also clone it to a local computer.

```bash
git clone https://github.com/CellFateNucOrg/spot-detect-lib.git
```

On a server, the scripts directly activate the environment throught conteiner, ensuring reproducibility of the system. If no environment is available to youm check out `Sponuc.def`, `sponuc_env.yml` and `requirments.txt` files to get the environments that were used during settings. More details how to set up a container - in the end of this document. 

---

Assumptions: 
1. **Image files**:
   - Nuclei degmentation algorithm can work with .nd2 and .tiff files with channels: ZYXC ot TZYXC. The pipeline will authomatically deal with timelapse images.
   - Spot segmentation pipeline currently is only available for tiff files, ZYXC or TZYXC. In the case of timelapse image TZYXC, the user needs to use a function `split_5d_tiff_to_timepoints` which could be activated in "spot_detectoin/main.py" script (uncomment it).
2. Both pipelines are desinged to work interconnectively. Spot detection algorithms assumes you have the file structure from nuclei detection step. And a tracking algorithm, also benefits from nuclei and spot detection data types.
     
## 1. Segmentation

The segmentation process utilizes CellPose and a pretrained model developed by Perz lab and Meister lab.

**To run a segmentation:**

1.  Open the `nuclei_segmentation.sh` script on your cluster.
2.  **Crucially, change the folder locations** to folders with your image files.

This script supports **.nd2** and **.tif** image files.

The segmentation script involves two main steps: **Segmentation** and **Analysis**. You can customize various settings by using command-line flags as demonstrated below:

```bash
python -m segmentation.cli segment \
    --raw-dir        "${RAW_DIR}" \
    --denoised-dir "${DENOISED_DIR}" \
    --pattern        "*.nd2" \
    --model          "${MODEL_DIR}" \
    --out-root       "${OUT_ROOT}" \
    --gpu \
    --do-qc \
    --blur-sigma "1.5" \
    --diameter "125"
```

### Available Segmentation Flags

Here's a breakdown of the available flags for the segmentation process:

* **`--raw-dir`** (required)
    *  Specifies the folder containing your input image files (**.nd2**, **.czi**, or **.tif**).
* **`--denoised-dir`** (optional)
    *  Specifies the folder containing denoised **.tif** files, if available.
* **`--pattern`** (default: `*.nd2`)
    *  A glob pattern to filter raw images (e.g., `'*.nd2'`, `'*.czi'`, `'*.tif'`).
* **`--model`** (required)
    *  Path to the Cellpose model folder.
* **`--out-root`** (required)
    *  The root directory where all output files will be saved.
* **`--gpu` / `--cpu`** (default: `--gpu`)
    *  Toggles between using **GPU** acceleration or **CPU** for processing.
* **`--do-qc` / `--no-qc`** (default: `--no-qc`)
    *  Enables or disables saving Quality Control (**QC**) images of the segmentation results.
* **`--invert` / `--no-invert`** (default: `--no-invert`)
    *  Controls whether image intensities are inverted before segmentation.
* **`--blur-sigma`** (optional)
    *  Applies an optional Gaussian blur with a specified sigma value before segmentation.
* **`--diameter`** (optional)
    * Change the expected diameter of nuclei. Might be needed for abnormal images, like high resolution. Confocal images usually work well because the model was trained on the similar data. 

---

## 2. Spot Detection

The spot detection algorithm relies on data generated by the nuclei segmentation algorithm. Therefore, you must have `nuclei` and `segmentation` folders present to analyze spots.

**To run a spot segmentation:**

1.  Open the `spot_detection.sh` script on your cluster.
2.  **Crucially, change the folder locations** to folders with your image files.
   
**To change analysis settings:**

* If you want to change the algorithm parameters you need to navigate to `spot_analysis.py` script. There you'd see the parameters needed 
* Navigate to `main.py` to change the analysis pipeline and utilize the split 5D images function, change QC settings.

---

3. **Tracking of particles**
After you make sure your spot segmentations are of a good quality, you can try to track particles in timelapse images. `tracking.ipynb` contains scripts which are currently interactive through a Jupyter Notebook to control the proccess. You need to indicate a location of spot segmentation directory called `spots/spot_segmentation/` for your data, generated by previous step. After, you run the following cells and this will generate a tracking output in the current working directory. 

To vizualize the tracks, the local Jupyter Notebook `tracking_local.py` with Napari available should be executed. There, you should indicate tracking csv file and the spot segmentation masks. Then it will load the data to NApari where you can inspect it. Because the mask data is quite big, the script utilizes lazy loading. This might work slow if you want to scroll through it. In order to efficiently look at the tracking Napari Animation plugin is utilized. This helps to create a movie to observe the tracking of the particles with time.

In the `tracking_local.ipynb`, different plotting examples for tracking statistics are available.

---

## Apptainer on IZB cluster

### Container
The continer for execution of the scripts is located in this folder on IZB cluster `/mnt/external.data/MeisterLab/mvolosko/spot_detection_environment/`

There are few important files to consider.
The first one is `Sponuc.def` - an image with which the container was built locally. 
This image creates a container called `sponuc.sif`, which includes the drivers needed for GPU execution on the cluster. It works with current version of Cuda toolkit 12.9.0. In the future this might need to be updated.
To build a container, you need to install the Apptainer locally and run the following command:
```bash
apptainer build sponuc.sif Sponuc.def
```

After you can transport the container file `sponuc.sif` to the server and use it there.

### Python envorinment
Then the micromamba environment was created in the sponuc-env using `sponuc_env.yml`. 
```bash
apptainer exec --nv sponuc.sif micromamba create -y -p /envs/sponuc -f sponuc_env.yml
```
This environment was installed with minimum requirments, to avoid packages incompatibility. And later the needed packages were installed with requirments.txt via pip.
In order to install new or update packages inside the environment, the following command should be executed in the spot_detection_environment folder:
```bash
#you should update the requirments.txt with packages you want to have
apptainer exec --nv sponuc.sif micromamba run -p ./sponuc-env pip install -r requirements.txt
```

## Future developments
It could be great to unify file handling system for both nuclei and spot detection pipeline. Because I developed the spot pipeline from scratch, I didn't think of utilizing the same system until it was too late.
CLI interface could be developed similarly to nuclei_detection pipeline to take advantage of a more modular workflow and to be able to change the parameters directly in bash script.

