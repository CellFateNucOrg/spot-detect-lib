{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c52f5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "import os\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import skimage.filters as filters\n",
    "import skimage.morphology as morphology\n",
    "import skimage.measure as measure\n",
    "import skimage.segmentation as segmentation\n",
    "import skimage.feature as feature\n",
    "import scipy.ndimage as ndi\n",
    "import bioio\n",
    "import bioio_tifffile\n",
    "import napari\n",
    "from skimage.measure import regionprops\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9631b529",
   "metadata": {},
   "source": [
    "# Load images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "46ada5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded image shape: (26, 1000, 1000)\n",
      "Image data type: float32\n",
      "Image min/max intensity: 99.071044921875/275.77728271484375\n"
     ]
    }
   ],
   "source": [
    "# --- REPLACE THIS SECTION WITH YOUR ACTUAL IMAGE LOADING ---\n",
    "# Example: Load a 3D image from a file (e.g., TIFF stack)\n",
    "# image = io.imread('path/to/your/3d_image.tif')\n",
    "# If your image is (Y, X, Z) or (X, Y, Z), you might need to transpose it:\n",
    "# image = np.transpose(image, (2, 0, 1)) # Example for (Y, X, Z) to (Z, Y, X)\n",
    "#filename = '/home/mira/Documents/MASTER/MASTER THESIS/napari/images/crop_2306/20240821_1273_E_late_15um_02_n2v_cropped.tif'\n",
    "filename = '/home/mira/Documents/MASTER/MASTER THESIS/napari/images/20241107_1268_E_30minHS_3h_5min_5um_n2v_t26.tif'\n",
    "image_path = os.path.basename(filename)\n",
    "\n",
    "img_3D = bioio.BioImage(filename, reader=bioio_tifffile.Reader)\n",
    "image= img_3D.get_image_data(\"ZYX\", C=1).astype(np.float32)\n",
    "    \n",
    "print(f\"Loaded image shape: {image.shape}\")\n",
    "print(f\"Image data type: {image.dtype}\")\n",
    "print(f\"Image min/max intensity: {image.min()}/{image.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b35009",
   "metadata": {},
   "source": [
    "# Pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ffb5387f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Otsu threshold: 116.67263793945312\n"
     ]
    }
   ],
   "source": [
    "# --- Step 3A: Binarization / Initial Segmentation ---\n",
    "# You'll likely need to adjust the thresholding method and parameters.\n",
    "\n",
    "# 1. Global Thresholding (simple, but sensitive to intensity variations)\n",
    "# Adjust `threshold_value` based on your image intensity histogram.\n",
    "threshold_value = filters.threshold_otsu(image) # Otsu's method is a good starting point\n",
    "# threshold_value = 500 # You might manually set a value\n",
    "binary_image_global = image > threshold_value\n",
    "print(f\"Otsu threshold: {threshold_value}\")\n",
    "\n",
    "# 2. Local/Adaptive Thresholding (better for uneven illumination)\n",
    "# `block_size`: Size of neighborhood to calculate local threshold. Must be odd.\n",
    "# `offset`: A constant subtracted from the mean or weighted mean.\n",
    "# Be careful with `block_size` in 3D; larger blocks are slower.\n",
    "# For 3D, you might consider slice-by-slice adaptive thresholding if performance is an issue.\n",
    "block_size_3D = 31 # Example: Must be odd. Adjust based on your object size.\n",
    "offset_value = 0.05 * image.max() # Example offset, adjust as needed\n",
    "\n",
    "# Apply adaptive thresholding. `mean` and `gaussian` are common methods.\n",
    "# For 3D, `adaptive` method from `skimage.filters` can be slow.\n",
    "# If it's too slow, consider applying `threshold_local` slice by slice, then stacking.\n",
    "# try:\n",
    "#     # This can be very slow for large 3D images; consider processing 2D slices if needed.\n",
    "#     binary_image_adaptive = image > filters.threshold_local(\n",
    "#         image, block_size=block_size_3D, method='gaussian', offset=offset_value\n",
    "#     )\n",
    "# except RuntimeError as e:\n",
    "#     print(f\"Warning: 3D adaptive thresholding might be too slow or memory intensive: {e}\")\n",
    "#     print(\"Consider processing slice-by-slice if this is the case.\")\n",
    "#     binary_image_adaptive = np.copy(binary_image_global) # Fallback\n",
    "\n",
    "# Choose which binary image to proceed with for morphology\n",
    "binary_image = binary_image_global # Start with global for simplicity, then try adaptive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "36dde308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 3B: Morphological Operations ---\n",
    "# Experiment with different structuring element shapes and sizes.\n",
    "# Structuring elements can be `disk` (2D), `ball` (3D sphere), or custom arrays.\n",
    "\n",
    "# Define a 3D structuring element (e.g., a ball/sphere)\n",
    "# `radius`: Controls the size of the structuring element. Crucial parameter!\n",
    "selem_radius = 4 # Adjust this radius!\n",
    "selem = morphology.ball(selem_radius)\n",
    "\n",
    "# 1. Opening: Erosion followed by Dilation.\n",
    "#   Purpose: Removes small objects and breaks thin connections between larger objects.\n",
    "#   Useful for separating your weakly connected \"spots\".\n",
    "binary_image_opened = morphology.binary_opening(binary_image, footprint=selem)\n",
    "\n",
    "\n",
    "# 2. Closing: Dilation followed by Erosion.\n",
    "#   Purpose: Fills small holes within objects and connects nearby objects separated by small gaps.\n",
    "#   Useful if your \"connected spots\" have tiny breaks you want to bridge.\n",
    "#   Apply after opening if you want to first separate, then fill within the separated parts.\n",
    "# selem_close_radius = 1 # Often a smaller radius than opening\n",
    "# selem_close = morphology.ball(selem_close_radius)\n",
    "# binary_image_closed = morphology.binary_closing(binary_image_opened, footprint=selem_close)\n",
    "\n",
    "# Choose which morphological output to proceed with\n",
    "# Start with `binary_image_opened`, as your primary goal is to separate.\n",
    "processed_binary_image = binary_image_opened # Or binary_image_closed, or just binary_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a4b14641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 103 initial markers for watershed.\n",
      "Segments before filtering: 103\n",
      "Segments after filtering: 95\n"
     ]
    }
   ],
   "source": [
    "# --- Step 3C: Watershed Segmentation ---\n",
    "# This is crucial for separating truly connected components.\n",
    "\n",
    "# Ensure `processed_binary_image` is boolean (True/False) for distance transform\n",
    "processed_binary_image = processed_binary_image.astype(bool)\n",
    "\n",
    "# 1. Compute Euclidean Distance Transform\n",
    "#   Pixels inside the foreground objects have values representing their distance to the nearest background pixel.\n",
    "#   Peaks in this transform correspond to potential object centers.\n",
    "distance_map = ndi.distance_transform_edt(processed_binary_image)\n",
    "\n",
    "# 2. Find Markers (Regional Maxima) for Watershed\n",
    "#   These are the \"seeds\" from which the watershed algorithm will grow.\n",
    "#   `min_distance`: Minimum distance between peaks. Adjust carefully to avoid too many or too few markers.\n",
    "#   `threshold_abs` or `threshold_rel`: Minimum intensity of peaks.\n",
    "min_peak_distance_3D = 10 # Adjust based on the expected size of your individual spots.\n",
    "# You might also want a minimum intensity for the peaks\n",
    "peak_min_intensity_abs = distance_map.max() * 0.30 # Example: 20% of max distance\n",
    "\n",
    "local_maxi = feature.peak_local_max(\n",
    "    distance_map,\n",
    "    footprint=np.ones((min_peak_distance_3D, min_peak_distance_3D, min_peak_distance_3D)), # Neighborhood for peak finding\n",
    "    labels=processed_binary_image, # Only find peaks within the foreground\n",
    "    threshold_abs=peak_min_intensity_abs\n",
    ")\n",
    "# Create a markers array from the coordinates of the local maxima\n",
    "markers = np.zeros(image.shape, dtype=bool)\n",
    "markers[tuple(local_maxi.T)] = True\n",
    "# Label the markers uniquely for watershed\n",
    "labeled_markers, num_markers = ndi.label(markers)\n",
    "\n",
    "print(f\"Found {num_markers} initial markers for watershed.\")\n",
    "\n",
    "# 3. Apply Watershed\n",
    "#   The watershed algorithm segments the image based on the markers.\n",
    "#   It 'floods' from the markers, and the 'watershed lines' become the boundaries between segments.\n",
    "#   `mask`: Constrains the flooding to only within the `processed_binary_image` area.\n",
    "#   `compactness`: Optional, can make the watershed regions more compact, useful for noisy data.\n",
    "#   `watershed_line`: If True, returns 0 for watershed lines (boundaries).\n",
    "segmented_labels = segmentation.watershed(\n",
    "    -distance_map, # Watershed works on 'basins', so we invert the distance map\n",
    "    labeled_markers,\n",
    "    mask=processed_binary_image,\n",
    "    # compactness=0.1, # Experiment with compactness if you get jagged boundaries\n",
    "    watershed_line=True # Recommended to get clear boundaries\n",
    ")\n",
    "\n",
    "# Post-processing: Remove very small segments (noise)\n",
    "# This is an optional but often useful step\n",
    "min_segment_volume = 50 # Adjust based on the smallest expected volume of an SDC body\n",
    "labels_after_filtering = np.copy(segmented_labels)\n",
    "\n",
    "# Iterate through unique labels (excluding background 0)\n",
    "for label in np.unique(segmented_labels):\n",
    "    if label == 0: # Skip background\n",
    "        continue\n",
    "    mask = (segmented_labels == label)\n",
    "    if np.sum(mask) < min_segment_volume:\n",
    "        labels_after_filtering[mask] = 0 # Assign to background\n",
    "\n",
    "print(f\"Segments before filtering: {len(np.unique(segmented_labels)) - 1}\")\n",
    "print(f\"Segments after filtering: {len(np.unique(labels_after_filtering)) - 1}\")\n",
    "\n",
    "final_segmented_image = labels_after_filtering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898cdd80",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ba845268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 4: Interactive Visualization with Napari ---\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "# Add the original image\n",
    "viewer.add_image(image, name='Original Image', colormap='gray', blending='additive')\n",
    "\n",
    "# Add binary images at different stages for comparison\n",
    "viewer.add_labels(binary_image_global, name='Binary - Global Otsu', opacity=0.3, visible=False)\n",
    "# viewer.add_labels(binary_image_adaptive, name='Binary - Adaptive', opacity=0.3) # Uncomment if you used adaptive\n",
    "\n",
    "viewer.add_labels(binary_image_opened, name=f'Binary - Opened (selem_radius={selem_radius})', opacity=0.4, visible=False)\n",
    "#viewer.add_labels(binary_image_closed, name=f'Binary - Closed (selem_close_radius={selem_close_radius})', opacity=0.4, visible=False)\n",
    "\n",
    "# Add the distance map (useful for understanding watershed markers)\n",
    "viewer.add_image(distance_map, name='Distance Map', colormap='magma', blending='additive', visible=False) # Start hidden\n",
    "\n",
    "# Add the markers\n",
    "viewer.add_points(\n",
    "    local_maxi,\n",
    "    name='Watershed Markers',\n",
    "    size=3, # Adjust point size for visibility\n",
    "    face_color='red',\n",
    "    #edge_color='white',\n",
    "    # ndim=3, # Not necessary if local_maxi is (N, 3)\n",
    "    opacity=0.7,\n",
    "    symbol='o',\n",
    "    visible=False # Start hidden, show when needed\n",
    ")\n",
    "\n",
    "# Add the final segmented labels\n",
    "# Napari will auto-assign random colors to labels, which is great for visualization.\n",
    "viewer.add_labels(final_segmented_image, name='Final Segmented SDC Bodies', opacity=0.6)\n",
    "\n",
    "# To keep the napari viewer open\n",
    "if __name__ == '__main__':\n",
    "    napari.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bf293641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved final segmented labels to: 20241107_1268_E_30minHS_3h_5min_5um_n2v_t26_labels.tif\n",
      "Saved centroids to: 20241107_1268_E_30minHS_3h_5min_5um_n2v_t26_centroids.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Selected 3 points in this slice, use Shift-A to select all points on the layer. (3 selected)\n"
     ]
    }
   ],
   "source": [
    "# --- Step 5: Saving Processed Data for Deep Learning Training ---\n",
    "\n",
    "# Define a path to save your processed data\n",
    "base_name= os.path.splitext(image_path)[0]\n",
    "output_labels_path = os.path.join(os.path.dirname(image_path), f'{base_name}_labels.tif')\n",
    "output_centroids_path = os.path.join(os.path.dirname(image_path), f'{base_name}_centroids.csv')\n",
    "\n",
    "# Save the segmented labels as a 3D TIFF stack\n",
    "# Ensure the data type is appropriate for labels (e.g., uint16, uint32)\n",
    "# If you have many labels (>2^16-1), use uint32\n",
    "io.imsave(output_labels_path, final_segmented_image.astype(np.uint16))\n",
    "print(f\"Saved final segmented labels to: {output_labels_path}\")\n",
    "\n",
    "# Extract centroids for SpotiFlow\n",
    "\n",
    "# Get properties for each labeled region (excluding background label 0)\n",
    "regions = regionprops(final_segmented_image)\n",
    "centroids_list = []\n",
    "for prop in regions:\n",
    "    # Centroid gives (Z, Y, X) coordinates for 3D\n",
    "    centroids_list.append({\n",
    "        'axis-0': prop.centroid[0],\n",
    "        'axis-1': prop.centroid[1],\n",
    "        'axis-2': prop.centroid[2]\n",
    "        #'area_volume': prop.area # For 3D, 'area' is actually volume in pixels\n",
    "    })\n",
    "\n",
    "if centroids_list:\n",
    "    centroids_df = pd.DataFrame(centroids_list)\n",
    "    centroids_df.to_csv(output_centroids_path, index=False)\n",
    "    print(f\"Saved centroids to: {output_centroids_path}\")\n",
    "else:\n",
    "    print(\"No SDC bodies detected to save centroids.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a23f3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Reusable Functions Cell ---\n",
    "# --- Imports ---\n",
    "import os\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import skimage.filters as filters\n",
    "import skimage.morphology as morphology\n",
    "import skimage.measure as measure\n",
    "import skimage.segmentation as segmentation\n",
    "import skimage.feature as feature\n",
    "import scipy.ndimage as ndi\n",
    "import bioio\n",
    "import bioio_tifffile\n",
    "import napari\n",
    "from skimage.measure import regionprops\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "def preprocess_and_segment_image(\n",
    "    image_path: str,\n",
    "    selem_radius: int = 4,\n",
    "    min_peak_distance_3D: int = 10,\n",
    "    peak_min_intensity_factor: float = 0.30,\n",
    "    min_segment_volume: int = 50,\n",
    "    viewer: napari.Viewer = None,\n",
    "    save_outputs: bool = True,\n",
    ") -> tuple:\n",
    "    \n",
    "    print(f\"\\nProcessing image: {os.path.basename(image_path)}\")\n",
    "\n",
    "    # Load image\n",
    "    img_3D = bioio.BioImage(image_path, reader=bioio_tifffile.Reader)\n",
    "    # Try to keep the original data type or convert to uint16/uint8 if sufficient range\n",
    "    # ONLY convert to float32 if pixel values are expected to be float or range > uint16 max.\n",
    "    # For typical microscopy, uint16 is usually fine for raw data.\n",
    "    image = img_3D.get_image_data(\"ZYX\", C=1)\n",
    "\n",
    "    # Normalize to 0-1 range for robust thresholding, but keep as original dtype if possible\n",
    "    # Or, if intensity range is limited (e.g., 0-255), consider converting to uint8\n",
    "    # If your images are always uint16, let's stick to that for memory.\n",
    "    # If you need floating point operations later, convert *only* when necessary.\n",
    "    if image.dtype != np.float32:\n",
    "        # Check max value. If within uint16 range (0-65535), keep uint16.\n",
    "        # If your images have negative values or very large values, float is needed.\n",
    "        if image.max() > np.iinfo(np.uint16).max or image.min() < 0:\n",
    "             # Fallback to float32 only if absolutely necessary\n",
    "            print(\"Warning: Image values outside uint16 range, converting to float32.\")\n",
    "            image = image.astype(np.float32)\n",
    "        else:\n",
    "            image = image.astype(np.uint16) # Use uint16 to save memory\n",
    "\n",
    "    print(f\"Loaded image shape: {image.shape}\")\n",
    "    print(f\"Image data type: {image.dtype}\") # Check if it's now uint16\n",
    "    print(f\"Image min/max intensity: {image.min()}/{image.max()}\")\n",
    "\n",
    "    # Step 3A: Binarization\n",
    "    threshold_value = filters.threshold_otsu(image)\n",
    "    binary_image_global = image > threshold_value\n",
    "    print(f\"Otsu threshold: {threshold_value}\")\n",
    "    binary_image = binary_image_global # This will be bool (1 byte/pixel)\n",
    "\n",
    "    # Step 3B: Morphological operations\n",
    "    selem = morphology.ball(selem_radius)\n",
    "    binary_image_opened = morphology.binary_opening(binary_image, footprint=selem)\n",
    "    processed_binary_image = binary_image_opened # Still bool\n",
    "\n",
    "    # Step 3C: Watershed Segmentation\n",
    "    processed_binary_image = processed_binary_image.astype(bool) # Ensure it's bool for ndi.distance_transform_edt\n",
    "    # ndi.distance_transform_edt typically returns float64. This is a big one.\n",
    "    distance_map = ndi.distance_transform_edt(processed_binary_image)\n",
    "\n",
    "    # Option: Convert distance_map to float32 if float64 is too much\n",
    "    # This will halve its memory usage. Check if accuracy is sufficient.\n",
    "    distance_map = distance_map.astype(np.float32)\n",
    "\n",
    "    peak_min_intensity_abs = distance_map.max() * peak_min_intensity_factor\n",
    "\n",
    "    local_maxi = feature.peak_local_max(\n",
    "        distance_map,\n",
    "        footprint=np.ones((min_peak_distance_3D,) * 3),\n",
    "        labels=processed_binary_image, # Pass original binary image as label mask\n",
    "        threshold_abs=peak_min_intensity_abs\n",
    "    )\n",
    "\n",
    "    markers = np.zeros(image.shape, dtype=bool)\n",
    "    if local_maxi.size > 0:\n",
    "        markers[tuple(local_maxi.T)] = True\n",
    "    labeled_markers, num_markers = ndi.label(markers) # labeled_markers will be int32 or int64\n",
    "\n",
    "    print(f\"Found {num_markers} initial markers for watershed.\")\n",
    "\n",
    "    if num_markers == 0:\n",
    "        print(\"No markers found for watershed. Returning empty results.\")\n",
    "        final_segmented_image = np.zeros_like(image, dtype=np.uint16)\n",
    "        centroids_df = pd.DataFrame(columns=['axis-0', 'axis-1', 'axis-2'])\n",
    "        base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        if viewer:\n",
    "            viewer.add_image(image, name=f'{base_name} - Original Image', colormap='gray', blending='additive')\n",
    "            viewer.add_labels(final_segmented_image, name=f'{base_name} - Final Segmented SDC Bodies (No Markers)', opacity=0.6)\n",
    "        return final_segmented_image, centroids_df, base_name\n",
    "\n",
    "    segmented_labels = segmentation.watershed(\n",
    "        -distance_map,\n",
    "        labeled_markers,\n",
    "        mask=processed_binary_image,\n",
    "        watershed_line=True\n",
    "    )\n",
    "    # Convert segmented_labels to a smaller integer type if possible.\n",
    "    # Max label value will determine required dtype. If you have < 65535 segments, uint16 is fine.\n",
    "    # If segments can exceed this, uint32 is next.\n",
    "    if segmented_labels.max() < np.iinfo(np.uint16).max:\n",
    "        segmented_labels = segmented_labels.astype(np.uint16)\n",
    "    elif segmented_labels.max() < np.iinfo(np.uint32).max:\n",
    "        segmented_labels = segmented_labels.astype(np.uint32)\n",
    "\n",
    "\n",
    "    labels_after_filtering = np.copy(segmented_labels) # This creates a copy, doubles memory for labels temporarily\n",
    "    # Consider directly modifying segmented_labels if you don't need the original pre-filtered version\n",
    "    # Or, filter in-place to avoid copy:\n",
    "    # region_sizes = measure.regionprops(segmented_labels)\n",
    "    # for prop in region_sizes:\n",
    "    #     if prop.area < min_segment_volume:\n",
    "    #         labels_after_filtering[segmented_labels == prop.label] = 0\n",
    "\n",
    "\n",
    "    # More memory-efficient way to filter labels\n",
    "    unique_labels = np.unique(segmented_labels)\n",
    "    # Create a mapping for labels to keep (or set to 0)\n",
    "    label_map = np.zeros(segmented_labels.max() + 1, dtype=segmented_labels.dtype)\n",
    "    valid_labels = []\n",
    "\n",
    "    for label in unique_labels:\n",
    "        if label == 0:\n",
    "            continue # Skip background\n",
    "        mask = (segmented_labels == label)\n",
    "        if np.sum(mask) >= min_segment_volume:\n",
    "            label_map[label] = label # Keep this label\n",
    "            valid_labels.append(label)\n",
    "        # else: label_map[label] remains 0\n",
    "\n",
    "    # Apply the mapping\n",
    "    final_segmented_image = label_map[segmented_labels]\n",
    "\n",
    "    print(f\"Segments before filtering: {len(unique_labels) - 1}\")\n",
    "    print(f\"Segments after filtering: {len(valid_labels)}\") # Adjusted count\n",
    "\n",
    "\n",
    "\n",
    "    #final_segmented_image = labels_after_filtering\n",
    "    \n",
    "    # --- New Section: Post-Watershed Merging for 1-pixel separation ---\n",
    "    # Define a small structuring element for closing.\n",
    "    # A 3x3x3 ball (radius 1) or a small cube is often suitable for bridging 1-pixel gaps.\n",
    "    # Adjust this 'merge_selem_radius' based on how much \"merging\" you want to allow.\n",
    "    # For exactly 1-pixel gaps, a radius of 1 (3x3x3 ball) is appropriate.\n",
    "    merge_selem_radius = 1\n",
    "    merge_selem = morphology.ball(merge_selem_radius)\n",
    "\n",
    "    # Convert the segmented image back to a binary mask for closing\n",
    "    # Any non-zero pixel is considered foreground.\n",
    "    binary_from_labels = final_segmented_image > 0\n",
    "\n",
    "    # Apply morphological closing to bridge small gaps\n",
    "    # This will connect regions that are separated by a small distance.\n",
    "    closed_binary = morphology.binary_closing(binary_from_labels, footprint=merge_selem)\n",
    "\n",
    "    # Re-label the connected components after closing\n",
    "    # This will assign new labels to the merged regions.\n",
    "    merged_labels, num_merged_segments = ndi.label(closed_binary)\n",
    "\n",
    "    # Important: We need to ensure that the merged labels correspond to the original\n",
    "    # object boundaries as much as possible, and that small regions aren't accidentally\n",
    "    # merged into very large ones if they were far apart but the closing connected them.\n",
    "    # A common way to refine this is to transfer the properties of the *old* labels\n",
    "    # to the *new* labels, or to ensure that the new labels are within the original\n",
    "    # processed_binary_image boundaries.\n",
    "\n",
    "    # A more robust approach might be to use the original distance map or markers\n",
    "    # with the merged binary image. However, for a simple \"merge 1-pixel apart\"\n",
    "    # using closing, we can relabel and then apply the min_segment_volume again.\n",
    "\n",
    "    # --- Refinement after closing and relabeling ---\n",
    "    # The `merged_labels` might have new labels that are smaller than the original.\n",
    "    # We should re-filter by volume.\n",
    "    unique_merged_labels = np.unique(merged_labels)\n",
    "    final_final_segmented_image = np.zeros_like(image, dtype=np.uint16)\n",
    "    new_label_counter = 0\n",
    "\n",
    "    print(f\"Segments after initial filtering and before final merge filter: {num_merged_segments}\")\n",
    "\n",
    "    for label in unique_merged_labels:\n",
    "        if label == 0:\n",
    "            continue\n",
    "        mask = (merged_labels == label)\n",
    "        if np.sum(mask) >= min_segment_volume: # Re-apply volume filter\n",
    "            new_label_counter += 1\n",
    "            final_final_segmented_image[mask] = new_label_counter\n",
    "        # else: this merged region is too small, discard it.\n",
    "\n",
    "    print(f\"Segments after post-watershed merge and final filtering: {new_label_counter}\")\n",
    "\n",
    "    final_segmented_image = final_final_segmented_image # Use the newly merged and filtered labels\n",
    "\n",
    "\n",
    "\n",
    "    # Visualization (optional)\n",
    "    base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    if viewer:\n",
    "        viewer.add_image(image, name=f'{base_name} - Original image', colormap='gray', blending='additive')\n",
    "        viewer.add_labels(binary_image_global, name=f'{base_name} - Binary global Otsu', opacity=0.3, visible=False)\n",
    "        viewer.add_labels(binary_image_opened, name=f'{base_name} - Binary opened (selem_radius={selem_radius})', opacity=0.4, visible=False)\n",
    "        viewer.add_image(distance_map, name=f'{base_name} - Distance map', colormap='magma', blending='additive', visible=False)\n",
    "        viewer.add_points(\n",
    "            local_maxi,\n",
    "            name=f'{base_name} - Watershed markers',\n",
    "            size=3,\n",
    "            face_color='red',\n",
    "            opacity=0.7,\n",
    "            symbol='o',\n",
    "            visible=False\n",
    "        )\n",
    "        viewer.add_labels(final_segmented_image, name=f'{base_name} - Final Segmented SDC Bodies', opacity=0.6)\n",
    "\n",
    "    # Saving Processed Data\n",
    "    centroids_list = []\n",
    "    regions = regionprops(final_segmented_image)\n",
    "    for prop in regions:\n",
    "        centroids_list.append({\n",
    "            'axis-0': prop.centroid[0],\n",
    "            'axis-1': prop.centroid[1],\n",
    "            'axis-2': prop.centroid[2]\n",
    "        })\n",
    "\n",
    "    if centroids_list:\n",
    "        centroids_df = pd.DataFrame(centroids_list)\n",
    "    else:\n",
    "        centroids_df = pd.DataFrame(columns=['axis-0', 'axis-1', 'axis-2'])\n",
    "\n",
    "    if save_outputs:\n",
    "        base_output_dir = os.path.dirname(image_path)\n",
    "        output_dir = os.path.join(base_output_dir, 'authomated_annotations')\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        output_labels_path = os.path.join(output_dir, f'{base_name}_labels.tif')\n",
    "        output_centroids_path = os.path.join(output_dir, f'{base_name}.csv')\n",
    "\n",
    "        io.imsave(output_labels_path, final_segmented_image.astype(np.uint16))\n",
    "        print(f\"Saved final segmented labels to: {output_labels_path}\")\n",
    "\n",
    "        if not centroids_df.empty:\n",
    "            centroids_df.to_csv(output_centroids_path, index=False)\n",
    "            print(f\"Saved centroids to: {output_centroids_path}\")\n",
    "        else:\n",
    "            print(\"No SDC bodies detected to save centroids.\")\n",
    "\n",
    "    return final_segmented_image, centroids_df, base_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5db60c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running single image experiment ---\n",
      "\n",
      "Processing image: 1268_fast_imaging_1_SIM^2processing_t14.tif\n",
      "Loaded image shape: (27, 2560, 2560)\n",
      "Image data type: uint16\n",
      "Image min/max intensity: 0/63380\n",
      "Otsu threshold: 4965\n",
      "Found 205 initial markers for watershed.\n",
      "Segments before filtering: 205\n",
      "Segments after filtering: 199\n",
      "Segments after initial filtering and before final merge filter: 138\n",
      "Segments after post-watershed merge and final filtering: 138\n",
      "Saved final segmented labels to: /mnt/external.data/MeisterLab/mvolosko/image_project/SDC1/1268_fast_imaging/spots/raw_images_timelapse/authomated_annotations/1268_fast_imaging_1_SIM^2processing_t14_labels.tif\n",
      "Saved centroids to: /mnt/external.data/MeisterLab/mvolosko/image_project/SDC1/1268_fast_imaging/spots/raw_images_timelapse/authomated_annotations/1268_fast_imaging_1_SIM^2processing_t14.csv\n",
      "Single image processing complete for: 1268_fast_imaging_1_SIM^2processing_t14\n",
      "Number of SDC bodies detected: 138\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Experimenting with single images (using the reusable function) ---\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Initialize Napari viewer once for all visualizations\n",
    "    #viewer = napari.Viewer()\n",
    "\n",
    "    # Define parameters for the single image experiment\n",
    "    single_image_filename = '/mnt/external.data/MeisterLab/mvolosko/image_project/SDC1/1268_fast_imaging/spots/raw_images_timelapse/1268_fast_imaging_1_SIM^2processing_t14.tif'\n",
    "    single_image_params = {\n",
    "        'selem_radius': 4, #was 4\n",
    "        'min_peak_distance_3D': 30,  #was 10 and oversegmented\n",
    "        'peak_min_intensity_factor': 0.20, #was 0.30v\n",
    "        'min_segment_volume': 100 #was 50\n",
    "    }\n",
    "\n",
    "    print(\"\\n--- Running single image experiment ---\")\n",
    "    segmented_single_image, centroids_single_image_df, single_image_base_name = preprocess_and_segment_image(\n",
    "        image_path=single_image_filename,\n",
    "        #viewer=viewer,\n",
    "        save_outputs=True,  # Set to True to save outputs for the single image\n",
    "        **single_image_params\n",
    "        )\n",
    "\n",
    "    print(f\"Single image processing complete for: {single_image_base_name}\")\n",
    "    print(f\"Number of SDC bodies detected: {len(centroids_single_image_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16a6bc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running batch processing for folder ---\n",
      "\n",
      "Processing image: 1268_fast_imaging_3_SIM^2processing_t18.tif\n",
      "Loaded image shape: (27, 2560, 2560)\n",
      "Image data type: uint16\n",
      "Image min/max intensity: 0/42146\n",
      "Otsu threshold: 914\n",
      "Found 2202 initial markers for watershed.\n",
      "Segments before filtering: 2202\n",
      "Segments after filtering: 1986\n",
      "Segments after initial filtering and before final merge filter: 1379\n",
      "Segments after post-watershed merge and final filtering: 1365\n",
      "Saved final segmented labels to: /mnt/external.data/MeisterLab/mvolosko/image_project/SDC1/1268_fast_imaging/spots/raw_images_timelapse/authomated_annotations/1268_fast_imaging_3_SIM^2processing_t18_labels.tif\n",
      "Saved centroids to: /mnt/external.data/MeisterLab/mvolosko/image_project/SDC1/1268_fast_imaging/spots/raw_images_timelapse/authomated_annotations/1268_fast_imaging_3_SIM^2processing_t18.csv\n",
      "\n",
      "Processing image: 1268_fast_imaging_3_SIM^2processing_t16.tif\n",
      "Loaded image shape: (27, 2560, 2560)\n",
      "Image data type: uint16\n",
      "Image min/max intensity: 0/45299\n",
      "Otsu threshold: 922\n",
      "Found 2104 initial markers for watershed.\n",
      "Segments before filtering: 2104\n",
      "Segments after filtering: 1881\n",
      "Segments after initial filtering and before final merge filter: 1280\n",
      "Segments after post-watershed merge and final filtering: 1272\n",
      "Saved final segmented labels to: /mnt/external.data/MeisterLab/mvolosko/image_project/SDC1/1268_fast_imaging/spots/raw_images_timelapse/authomated_annotations/1268_fast_imaging_3_SIM^2processing_t16_labels.tif\n",
      "Saved centroids to: /mnt/external.data/MeisterLab/mvolosko/image_project/SDC1/1268_fast_imaging/spots/raw_images_timelapse/authomated_annotations/1268_fast_imaging_3_SIM^2processing_t16.csv\n",
      "\n",
      "Processing image: 1268_fast_imaging_3_SIM^2processing_t11.tif\n",
      "Loaded image shape: (27, 2560, 2560)\n",
      "Image data type: uint16\n",
      "Image min/max intensity: 0/51811\n",
      "Otsu threshold: 940\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Analyse whole folder images ---\n",
    "if __name__ == '__main__':\n",
    "    # Define the folder containing images\n",
    "    image_folder = '/mnt/external.data/MeisterLab/mvolosko/image_project/SDC1/1268_fast_imaging/spots/raw_images_timelapse/'\n",
    "    # List of image file extensions to process\n",
    "    image_extensions = ('.tif', '.tiff')\n",
    "\n",
    "    print(\"\\n--- Running batch processing for folder ---\")\n",
    "    processed_results = []\n",
    "\n",
    "    for filename in os.listdir(image_folder):\n",
    "        if filename.lower().endswith(image_extensions):\n",
    "            full_image_path = os.path.join(image_folder, filename)\n",
    "            # Process each image using the reusable function\n",
    "            segmented_img, centroids_df, img_base_name = \\\n",
    "                preprocess_and_segment_image(\n",
    "                    image_path=full_image_path,\n",
    "                    save_outputs=True, # Set to True to save outputs for each image in the folder\n",
    "                    selem_radius= 4,\n",
    "                    min_peak_distance_3D= 20,\n",
    "                    peak_min_intensity_factor= 0.20,\n",
    "                    min_segment_volume= 100\n",
    "                )\n",
    "            processed_results.append({\n",
    "                'filename': img_base_name,\n",
    "                'segmented_image': segmented_img,\n",
    "                'centroids': centroids_df,\n",
    "                'num_sdc_bodies': len(centroids_df)\n",
    "            })\n",
    "\n",
    "    print(\"\\n--- Batch processing complete ---\")\n",
    "    for result in processed_results:\n",
    "        print(f\"Image: {result['filename']}, Detected SDC Bodies: {result['num_sdc_bodies']}\")\n",
    "\n",
    "    # # Keep napari viewer open\n",
    "    # napari.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf14ed27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lhcellpose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
