{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166281a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tifffile import imread\n",
    "from skimage.measure import regionprops\n",
    "from collections import defaultdict\n",
    "from scipy.spatial.distance import cdist\n",
    "from typing import List, Dict, Any, Tuple, Optional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc6ea13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"/mnt/external.data/MeisterLab/mvolosko/image_project/SDC1/1268_fast_imaging_01/spots/spot_segmentation/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7739114",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Found 18 timepoints to process.\n",
      "INFO: Pre-processing to determine volume threshold...\n",
      "INFO: Median object volume is 1377.00. Using min volume threshold: 413\n",
      "INFO: Extracted properties for all timepoints.\n",
      "INFO: Processing link between frame 0 and 1...\n",
      "INFO: Processing link between frame 1 and 2...\n",
      "INFO: Processing link between frame 2 and 3...\n",
      "INFO: Processing link between frame 3 and 4...\n",
      "INFO: Processing link between frame 4 and 5...\n",
      "INFO: Processing link between frame 5 and 6...\n",
      "INFO: Processing link between frame 6 and 7...\n",
      "INFO: Processing link between frame 7 and 8...\n",
      "INFO: Processing link between frame 8 and 9...\n",
      "INFO: Processing link between frame 9 and 10...\n",
      "INFO: Processing link between frame 10 and 11...\n",
      "INFO: Processing link between frame 11 and 12...\n",
      "INFO: Processing link between frame 12 and 13...\n",
      "INFO: Processing link between frame 13 and 14...\n",
      "INFO: Processing link between frame 14 and 15...\n",
      "INFO: Processing link between frame 15 and 16...\n",
      "INFO: Processing link between frame 16 and 17...\n",
      "INFO: Built object linkage graph.\n",
      "INFO: Completed robust object tracking with gap closing.\n",
      "INFO: Generated detailed report: analysis_results_robust.csv\n",
      "INFO: Generated Napari-compatible tracks file: napari_tracks_robust.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Pipeline executed successfully! ---\n",
      "Detailed results saved to: analysis_results_robust.csv\n",
      "Napari tracks saved to: napari_tracks_robust.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration & Setup ---\n",
    "\n",
    "# Configure logging for clear script output.\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "logging.getLogger('tifffile').setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "# --- Core Functions ---\n",
    "\n",
    "def get_mask_filepaths(directory: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Gets and sorts all TIFF file paths from a directory.\n",
    "\n",
    "    Args:\n",
    "        directory (str): Path to the directory containing TIFF files.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A sorted list of full file paths to the TIFF masks.\n",
    "    \"\"\"\n",
    "    files = sorted([f for f in os.listdir(directory) if f.endswith(('.tif', '.tiff'))])\n",
    "    if not files:\n",
    "        raise ValueError(f\"No TIFF files found in directory: {directory}\")\n",
    "    return [os.path.join(directory, f) for f in files]\n",
    "\n",
    "\n",
    "def load_mask(file_path: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Loads a single 3D mask from a file path, ensuring it's a 3D integer array.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the TIFF file.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A 3D mask array (z, y, x).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        mask = imread(file_path)\n",
    "        mask_squeezed = np.squeeze(mask).astype(np.int32)\n",
    "        if mask_squeezed.ndim != 3:\n",
    "            raise ValueError(f\"Mask must be 3D, but file {file_path} has shape {mask_squeezed.shape} after squeeze.\")\n",
    "        return mask_squeezed\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to load or process mask {file_path}: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def extract_properties_from_mask(\n",
    "    mask: np.ndarray, \n",
    "    time_index: int, \n",
    "    min_volume_threshold: int = 0\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Extracts region properties for all objects in a mask that meet a minimum volume.\n",
    "\n",
    "    Args:\n",
    "        mask (np.ndarray): A single 3D mask array.\n",
    "        time_index (int): The timepoint (frame number) of the mask.\n",
    "        min_volume_threshold (int): The minimum pixel volume for an object to be included.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[str, Any]]: A list of property dictionaries for each valid object.\n",
    "    \"\"\"\n",
    "    regions = regionprops(mask)\n",
    "    properties = []\n",
    "    for r in regions:\n",
    "        # --- Noise Filtering ---\n",
    "        # Ignore objects smaller than the specified volume threshold.\n",
    "        if r.area >= min_volume_threshold:\n",
    "            properties.append({\n",
    "                'time': time_index,\n",
    "                'label': r.label,\n",
    "                'centroid': r.centroid,\n",
    "                'area': r.area,\n",
    "                'bbox': r.bbox\n",
    "            })\n",
    "    return properties\n",
    "\n",
    "\n",
    "def link_objects_between_frames(\n",
    "    props1: List[Dict[str, Any]],\n",
    "    props2: List[Dict[str, Any]],\n",
    "    mask1: np.ndarray,\n",
    "    mask2: np.ndarray,\n",
    "    overlap_threshold: float = 0.25\n",
    ") -> List[Tuple[Tuple[int, int], Tuple[int, int]]]:\n",
    "    \"\"\"\n",
    "    Calculates links between objects in two consecutive frames based on overlap.\n",
    "\n",
    "    ***ALGORITHM UPDATE***:\n",
    "    This function now uses Intersection over Parent (IoP) instead of IoU.\n",
    "    IoP = intersection / area_of_object_in_frame1. This is more robust for\n",
    "    detecting splits (one large parent overlapping with multiple smaller children).\n",
    "\n",
    "    Args:\n",
    "        props1: Properties for objects in the first frame (t).\n",
    "        props2: Properties for objects in the second frame (t+1).\n",
    "        mask1: The full 3D mask for the first frame.\n",
    "        mask2: The full 3D mask for the second frame.\n",
    "        overlap_threshold: The minimum IoP to establish a link.\n",
    "\n",
    "    Returns:\n",
    "        A list of links, where each link is a tuple of ((t, label1), (t+1, label2)).\n",
    "    \"\"\"\n",
    "    links = []\n",
    "    if not props1 or not props2:\n",
    "        return []\n",
    "        \n",
    "    time1 = props1[0]['time']\n",
    "    time2 = props2[0]['time']\n",
    "\n",
    "    for p1 in props1:\n",
    "        p1_bbox = p1['bbox']\n",
    "        for p2 in props2:\n",
    "            p2_bbox = p2['bbox']\n",
    "            \n",
    "            # Fast bounding box intersection check\n",
    "            inter_min_z = max(p1_bbox[0], p2_bbox[0])\n",
    "            inter_min_y = max(p1_bbox[1], p2_bbox[1])\n",
    "            inter_min_x = max(p1_bbox[2], p2_bbox[2])\n",
    "            inter_max_z = min(p1_bbox[3], p2_bbox[3])\n",
    "            inter_max_y = min(p1_bbox[4], p2_bbox[4])\n",
    "            inter_max_x = min(p1_bbox[5], p2_bbox[5])\n",
    "\n",
    "            if not (inter_max_z > inter_min_z and inter_max_y > inter_min_y and inter_max_x > inter_min_x):\n",
    "                continue\n",
    "            \n",
    "            # Efficient intersection calculation on the small intersection crop\n",
    "            crop1 = mask1[inter_min_z:inter_max_z, inter_min_y:inter_max_y, inter_min_x:inter_max_x]\n",
    "            crop2 = mask2[inter_min_z:inter_max_z, inter_min_y:inter_max_y, inter_min_x:inter_max_x]\n",
    "            intersection = np.sum((crop1 == p1['label']) & (crop2 == p2['label']))\n",
    "\n",
    "            if intersection > 0:\n",
    "                # --- Intersection over Parent (IoP) ---\n",
    "                # If an object in frame t overlaps with an object in t+1 by at least\n",
    "                # 25% (or other specified) of its own (the parent's) volume, we link them.\n",
    "                iop = intersection / p1['area']\n",
    "                if iop >= overlap_threshold:\n",
    "                    key1 = (time1, p1['label'])\n",
    "                    key2 = (time2, p2['label'])\n",
    "                    links.append((key1, key2))\n",
    "    return links\n",
    "\n",
    "\n",
    "def build_link_graph(all_props: List[Dict[int, Dict[str, Any]]], mask_files: List[str], overlap_threshold: float) -> defaultdict:\n",
    "    \"\"\"\n",
    "    Builds a directed graph of object links across all timepoints.\n",
    "    This function processes masks sequentially to keep memory usage low.\n",
    "    \"\"\"\n",
    "    link_graph = defaultdict(lambda: {'parents': [], 'children': []})\n",
    "    \n",
    "    # Load the first mask to initialize\n",
    "    mask_t0 = load_mask(mask_files[0])\n",
    "\n",
    "    for t in range(len(all_props) - 1):\n",
    "        logging.info(f\"Processing link between frame {t} and {t+1}...\")\n",
    "        \n",
    "        # Load the next mask in the sequence\n",
    "        mask_t1 = load_mask(mask_files[t+1])\n",
    "        \n",
    "        # Link objects between the current pair of masks\n",
    "        links = link_objects_between_frames(\n",
    "            list(all_props[t].values()), list(all_props[t+1].values()), mask_t0, mask_t1, overlap_threshold\n",
    "            )\n",
    "        \n",
    "        # Populate the graph with the links found\n",
    "        for key1, key2 in links:\n",
    "            link_graph[key1]['children'].append(key2)\n",
    "            link_graph[key2]['parents'].append(key1)\n",
    "            \n",
    "        # The mask for t+1 becomes the mask for t in the next iteration.\n",
    "        mask_t0 = mask_t1\n",
    "        \n",
    "    return link_graph\n",
    "\n",
    "\n",
    "def track_objects_robust(\n",
    "    all_props: List[Dict[int, Dict[str, Any]]],\n",
    "    link_graph: defaultdict,\n",
    "    max_gap_frames: int = 2,\n",
    "    max_distance: float = 50.0\n",
    ") -> Tuple[Dict, defaultdict, Dict]:\n",
    "    \"\"\"\n",
    "    Tracks objects across time, assigning unique track IDs, identifying events,\n",
    "    and handling gaps in tracking.\n",
    "\n",
    "    Args:\n",
    "        all_props: A list of dictionaries, mapping labels to object properties for all timepoints.\n",
    "        link_graph: The object linkage graph.\n",
    "        max_gap_frames: The maximum number of frames an object can disappear for and still be re-linked.\n",
    "        max_distance: The maximum centroid distance to bridge a gap.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing: track_map, event_map, and lineage.\n",
    "    \"\"\"\n",
    "    track_counter = 1\n",
    "    track_map = {}  # (time, label) -> track_id\n",
    "    event_map = defaultdict(lambda: {'type': '', 'parents': []})\n",
    "    lineage = {}    # track_id: [parent_track_id(s)]\n",
    "    \n",
    "    # --- Gap Closing Logic ---\n",
    "    lost_tracks = {} # track_id -> {'key': (t, label), 'props': props, 'frame_lost': t}\n",
    "\n",
    "    for t, timepoint_props in enumerate(all_props):\n",
    "        # Link new objects to lost tracks from previous frames\n",
    "        unlinked_props = []\n",
    "        \n",
    "        # Find objects in this frame that have no parents\n",
    "        props_with_no_parents = []\n",
    "        for props in timepoint_props.values():\n",
    "            key = (props['time'], props['label'])\n",
    "            if not link_graph[key]['parents']:\n",
    "                props_with_no_parents.append(props)\n",
    "\n",
    "        # Try to bridge gaps for these parentless objects\n",
    "        matched_lost_track_ids = set()\n",
    "        for new_prop in props_with_no_parents:\n",
    "            new_key = (new_prop['time'], new_prop['label'])\n",
    "            best_match = None\n",
    "            min_dist = float('inf')\n",
    "\n",
    "            # Find the closest lost track within the time and distance thresholds\n",
    "            for track_id, lost_info in list(lost_tracks.items()):\n",
    "                if track_id in matched_lost_track_ids: continue\n",
    "                \n",
    "                frame_gap = t - lost_info['frame_lost']\n",
    "                if 1 <= frame_gap <= max_gap_frames:\n",
    "                    dist = np.linalg.norm(np.array(new_prop['centroid']) - np.array(lost_info['props']['centroid']))\n",
    "                    if dist < max_distance and dist < min_dist:\n",
    "                        min_dist = dist\n",
    "                        best_match = track_id\n",
    "            \n",
    "            if best_match is not None:\n",
    "                # Found a match, bridge the gap!\n",
    "                lost_info = lost_tracks[best_match]\n",
    "                parent_key = lost_info['key']\n",
    "                parent_track_id = track_map[parent_key]\n",
    "\n",
    "                # Update maps and lineage\n",
    "                track_map[new_key] = parent_track_id\n",
    "                lineage.setdefault(parent_track_id, []).append(parent_track_id) # Self-parent for bridging\n",
    "                event_map[new_key] = {'type': 'bridged', 'parents': [parent_track_id]}\n",
    "                event_map[parent_key]['type'] = 'bridged_disappearance' # Mark the original disappearance\n",
    "\n",
    "                # Remove from lost tracks so it can't be matched again\n",
    "                del lost_tracks[best_match]\n",
    "                matched_lost_track_ids.add(best_match)\n",
    "            else:\n",
    "                # No match found, it's a truly new object (or we can't bridge it)\n",
    "                unlinked_props.append(new_prop)\n",
    "\n",
    "        # Process all objects in the current timepoint\n",
    "        for obj in timepoint_props.values():\n",
    "            key = (t, obj['label'])\n",
    "            if key in track_map: continue # Already handled by gap closing\n",
    "\n",
    "            parents = link_graph[key]['parents']\n",
    "            parent_track_ids = [track_map.get(p) for p in parents if p in track_map]\n",
    "            \n",
    "            if not parent_track_ids: # Appearance\n",
    "                track_id = track_counter\n",
    "                track_map[key] = track_id\n",
    "                event_map[key] = {'type': 'appearance', 'parents': []}\n",
    "                lineage[track_id] = []\n",
    "                track_counter += 1\n",
    "            elif len(parent_track_ids) == 1: # Continuation\n",
    "                track_id = parent_track_ids[0]\n",
    "                track_map[key] = track_id\n",
    "                lineage.setdefault(track_id, []).extend(parent_track_ids)\n",
    "            else: # Merge\n",
    "                # For merges, we continue the track of the largest parent\n",
    "                parent_areas = [all_props[p[0]][p[1]]['area'] for p in parents]\n",
    "                main_parent_idx = np.argmax(parent_areas)\n",
    "                main_parent_track_id = parent_track_ids[main_parent_idx]\n",
    "\n",
    "                track_id = main_parent_track_id\n",
    "                track_map[key] = track_id\n",
    "                event_map[key] = {'type': 'merge', 'parents': parent_track_ids}\n",
    "                lineage.setdefault(track_id, []).extend(parent_track_ids)\n",
    "\n",
    "        # Final pass for this timepoint to identify splits and true disappearances\n",
    "        # We check the *previous* frame's objects to see if they split or disappeared\n",
    "        if t > 0:\n",
    "            for prev_obj in all_props[t-1].values():\n",
    "                prev_key = (t-1, prev_obj['label'])\n",
    "                if prev_key not in track_map: continue\n",
    "\n",
    "                children = link_graph[prev_key]['children']\n",
    "                \n",
    "                if not children: # Potential disappearance\n",
    "                    if event_map[prev_key]['type'] == '': # Not already marked as part of a bridge\n",
    "                        event_map[prev_key]['type'] = 'disappearance'\n",
    "                        track_id = track_map[prev_key]\n",
    "                        lost_tracks[track_id] = {'key': prev_key, 'props': prev_obj, 'frame_lost': t-1}\n",
    "                elif len(children) > 1: # Split\n",
    "                    event_map[prev_key]['type'] = 'split'\n",
    "\n",
    "    # Clean up any lost tracks at the end of the sequence\n",
    "    for track_id, lost_info in lost_tracks.items():\n",
    "        if event_map[lost_info['key']]['type'] == 'disappearance':\n",
    "             event_map[lost_info['key']]['type'] = 'terminal' # Final disappearance\n",
    "\n",
    "    return track_map, event_map, lineage\n",
    "\n",
    "\n",
    "def generate_outputs(\n",
    "    all_props: List[Dict[int, Dict[str, Any]]], \n",
    "    track_map: Dict, \n",
    "    event_map: defaultdict, \n",
    "    lineage: Dict,\n",
    "    output_csv: str,\n",
    "    tracks_output_csv: str\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Generates a detailed CSV report and a napari-compatible tracks file.\"\"\"\n",
    "    csv_data, tracks_data = [], []\n",
    "    \n",
    "    for t, timepoint_props in enumerate(all_props):\n",
    "        for obj in timepoint_props.values():\n",
    "            key = (t, obj['label'])\n",
    "            track_id = track_map.get(key)\n",
    "            if track_id is None: continue\n",
    "\n",
    "            event_info = event_map.get(key, {'type': '', 'parents': []})\n",
    "            parent_ids_str = ','.join(map(str, sorted(list(set(event_info['parents'])))))\n",
    "            \n",
    "            csv_data.append({\n",
    "                'time': t,\n",
    "                'z': obj['centroid'][0], 'y': obj['centroid'][1], 'x': obj['centroid'][2],\n",
    "                'label': obj['label'], 'track_id': track_id, 'area': obj['area'],\n",
    "                'event_type': event_info['type'], 'parent_track_id': parent_ids_str\n",
    "            })\n",
    "            \n",
    "            tracks_data.append([track_id, t, obj['centroid'][0], obj['centroid'][1], obj['centroid'][2]])\n",
    "    \n",
    "    df = pd.DataFrame(csv_data).sort_values(by=['track_id', 'time']).reset_index(drop=True)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    \n",
    "    tracks_array = np.array(tracks_data, dtype=float)\n",
    "    napari_df = pd.DataFrame(tracks_array, columns=['track_id', 'time', 'z', 'y', 'x'])\n",
    "    napari_df.to_csv(tracks_output_csv, index=False)\n",
    "    \n",
    "    napari_graph = {child_id: parents[0] for child_id, parents in lineage.items() if parents and len(parents) == 1}\n",
    "\n",
    "    return {\n",
    "        'tracks_array': tracks_array,\n",
    "        'graph': napari_graph,\n",
    "        'csv_path': output_csv,\n",
    "        'tracks_csv_path': tracks_output_csv\n",
    "    }\n",
    "\n",
    "\n",
    "# --- Main Pipeline---\n",
    "\n",
    "def segmentation_pipeline_robust(\n",
    "    input_dir: str, \n",
    "    output_csv: str = 'analysis_results.csv',\n",
    "    tracks_output_csv: str = 'napari_tracks.csv',\n",
    "    overlap_threshold: float = 0.1,\n",
    "    min_volume_fraction: float = 0.2,\n",
    "    max_gap_frames: int = 2,\n",
    "    max_distance_for_gap: float = 50.0\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    End-to-end robust segmentation analysis pipeline.\n",
    "\n",
    "    This pipeline includes noise filtering, gap closing, and uses a more robust\n",
    "    linking metric (IoP) to handle splits and merges effectively.\n",
    "\n",
    "    Args:\n",
    "        input_dir: Directory containing 3D mask TIFF files.\n",
    "        output_csv: Path to save the detailed CSV report.\n",
    "        tracks_output_csv: Path to save the Napari-compatible tracks CSV.\n",
    "        overlap_threshold: Minimum IoP (Intersection over Parent) to link objects.\n",
    "        min_volume_fraction: Fraction of the median object volume to use as a noise threshold.\n",
    "        max_gap_frames: Max frames to bridge a track across a gap.\n",
    "        max_distance_for_gap: Max centroid distance to bridge a track.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary of results including the tracks array, graph, and output file paths.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        mask_files = get_mask_filepaths(input_dir)\n",
    "        num_timepoints = len(mask_files)\n",
    "        logging.info(f\"Found {num_timepoints} timepoints to process.\")\n",
    "        \n",
    "        # --- Step 1: Pre-process to find median volume for noise filtering ---\n",
    "        logging.info(\"Pre-processing to determine volume threshold...\")\n",
    "        all_volumes = []\n",
    "        # Use a subset of frames for efficiency if the dataset is very large\n",
    "        sample_files = mask_files[:min(20, num_timepoints)] \n",
    "        for i, f in enumerate(sample_files):\n",
    "            mask = load_mask(f)\n",
    "            props = extract_properties_from_mask(mask, i) # No volume filter yet\n",
    "            if props:\n",
    "                all_volumes.extend([p['area'] for p in props])\n",
    "        \n",
    "        if not all_volumes:\n",
    "            logging.warning(\"No objects found in sample files. Disabling volume filter.\")\n",
    "            min_volume_threshold = 0\n",
    "        else:\n",
    "            median_volume = np.median(all_volumes)\n",
    "            min_volume_threshold = int(median_volume * min_volume_fraction)\n",
    "            logging.info(f\"Median object volume is {median_volume:.2f}. Using min volume threshold: {min_volume_threshold}\")\n",
    "\n",
    "        # --- Step 2: Extract properties from all masks with noise filtering ---\n",
    "        all_props = []\n",
    "        for t, file_path in enumerate(mask_files):\n",
    "            mask = load_mask(file_path)\n",
    "            props_t = extract_properties_from_mask(mask, t, min_volume_threshold)\n",
    "            all_props.append({p['label']: p for p in props_t})\n",
    "        logging.info(\"Extracted properties for all timepoints.\")\n",
    "\n",
    "        # --- Step 3: Build the linkage graph between objects ---\n",
    "        link_graph = build_link_graph(all_props, mask_files, overlap_threshold)\n",
    "        logging.info(\"Built object linkage graph.\")\n",
    "        \n",
    "        # --- Step 4: Perform robust tracking with gap closing ---\n",
    "        track_map, event_map, lineage = track_objects_robust(\n",
    "            all_props, link_graph, max_gap_frames, max_distance_for_gap\n",
    "        )\n",
    "        logging.info(\"Completed robust object tracking with gap closing.\")\n",
    "        \n",
    "        # --- Step 5: Generate final outputs ---\n",
    "        results = generate_outputs(\n",
    "            all_props, track_map, event_map, lineage, output_csv, tracks_output_csv\n",
    "        )\n",
    "        logging.info(f\"Generated detailed report: {output_csv}\")\n",
    "        logging.info(f\"Generated Napari-compatible tracks file: {tracks_output_csv}\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Pipeline failed: {str(e)}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cd7ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Example Usage (made for scripting rather than Jyp notebook)---\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    if os.path.isdir(data_directory):\n",
    "        try:\n",
    "            results = segmentation_pipeline_robust(\n",
    "                input_dir=data_directory,\n",
    "                output_csv=\"analysis_results.csv\",\n",
    "                tracks_output_csv=\"napari_tracks.csv\",\n",
    "                overlap_threshold=0.25,      # Overlap of 25% of the parent's volume\n",
    "                min_volume_fraction=0.3,     # Ignore objects smaller than 30% of median volume\n",
    "                max_gap_frames=2,            # Allow objects to disappear for up to 2 frames\n",
    "                max_distance_for_gap=50.0    # Max distance (in pixels) to link a reappeared object\n",
    "            )\n",
    "            print(\"\\n--- Pipeline executed successfully! ---\")\n",
    "            print(f\"Detailed results saved to: {results['csv_path']}\")\n",
    "            print(f\"Napari tracks saved to: {results['tracks_csv_path']}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\nAn error occurred during the pipeline execution: {e}\")\n",
    "    else:\n",
    "        print(f\"\\n--- SKIPPING EXECUTION ---\")\n",
    "        print(f\"The example data directory does not exist: '{data_directory}'\")\n",
    "        print(\"Please update the 'data_directory' variable to point to your TIFF files.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lhcellpose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
