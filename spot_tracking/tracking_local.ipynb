{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166281a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import napari\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tifffile import imread\n",
    "from natsort import natsorted\n",
    "import logging\n",
    "import dask.array as da\n",
    "from dask import delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418adbdf",
   "metadata": {},
   "source": [
    "# Display the tracks files in Napari\n",
    "This should be run locally with accessible files like Spot masks and Track csv file (created with script `tracking.ipynb` on server).\n",
    "You can then view the tracks in Napari and possibly also overlay the raw images.\n",
    "Make sure you have proper packages, because the container does not support their running. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "669a303d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Path to the directory containing your individual TIFF mask files.\n",
    "MASK_DIRECTORY = \"/home/mira/ibz_server/mvolosko/image_project/SDC1/1268_fast_imaging_01/spots/spot_segmentation/\"\n",
    "\n",
    "# 2. Path to the tracks CSV file generated by the tracking script.\n",
    "TRACKS_CSV_PATH = \"/home/mira/ibz_server/mvolosko/image_project/SDC1/1268_fast_imaging_01/tracks/napari_tracks_robust.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363b76c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Searching for TIFF files in: /home/mira/ibz_server/mvolosko/image_project/SDC1/1268_fast_imaging_01/spots/spot_segmentation/\n",
      "INFO: Successfully created a 'virtual' stack with shape: (20, 27, 2560, 2560)\n",
      "INFO: Memory usage will be minimal until you start scrolling in Napari.\n",
      "INFO: Loading all tracks from: /home/mira/ibz_server/mvolosko/image_project/SDC1/1268_fast_imaging_01/tracks/napari_tracks_robust.csv\n",
      "INFO: Launching Napari viewer...\n",
      "INFO: No OpenGL_accelerate module loaded: No module named 'OpenGL_accelerate'\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "logging.getLogger('tifffile').setLevel(logging.ERROR)\n",
    "\n",
    "def robust_imread(filename):\n",
    "    \"\"\"\n",
    "    Reads an image and squeezes out singleton dimensions to ensure consistency.\n",
    "    For example, an image with shape (1, Z, Y, X) becomes (Z, Y, X).\n",
    "    \"\"\"\n",
    "    return np.squeeze(imread(filename))\n",
    "\n",
    "def load_masks_as_virtual_stack(directory: str):\n",
    "    \"\"\"\n",
    "    Creates a Dask array, which represents the entire stack WITHOUT loading it all into memory.\n",
    "    This version is robust to inconsistencies in image dimensions.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Searching for TIFF files in: {directory}\")\n",
    "    files = natsorted([os.path.join(directory, f) for f in os.listdir(directory) if f.endswith(('.tif', '.tiff'))])\n",
    "    \n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No TIFF files were found in the directory: {directory}\")\n",
    "\n",
    "    # Get the shape and dtype from the first image using the ROBUST reader.\n",
    "    sample = robust_imread(files[0])\n",
    "    \n",
    "    # Use dask.delayed to wrap our robust reader.\n",
    "    lazy_reader = delayed(robust_imread)\n",
    "    lazy_arrays = [lazy_reader(f) for f in files]\n",
    "\n",
    "    # Create a stack of Dask arrays, ensuring each has the correct shape and dtype\n",
    "    dask_arrays = [da.from_delayed(arr, shape=sample.shape, dtype=sample.dtype) for arr in lazy_arrays]\n",
    "    \n",
    "    # Stack them along the time axis (axis=0)\n",
    "    stack = da.stack(dask_arrays, axis=0)\n",
    "    stack = stack.compute_chunk_sizes()\n",
    "    \n",
    "    logging.info(f\"Successfully created a 'virtual' stack with shape: {stack.shape}\")\n",
    "    logging.info(f\"Memory usage will be minimal until you start scrolling in Napari.\")\n",
    "    return stack\n",
    "\n",
    "\n",
    "def load_all_tracks(csv_path: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Loads all tracking data from a CSV file. No filtering is needed for the virtual stack.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Loading all tracks from: {csv_path}\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "    required_cols = ['track_id', 'time', 'z', 'y', 'x']\n",
    "    return df[required_cols].to_numpy()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not os.path.isdir(MASK_DIRECTORY):\n",
    "        logging.error(f\"Mask directory not found: {MASK_DIRECTORY}\")\n",
    "    elif not os.path.isfile(TRACKS_CSV_PATH):\n",
    "        logging.error(f\"Tracks CSV not found: {TRACKS_CSV_PATH}\")\n",
    "    else:\n",
    "        try:\n",
    "            # 1. Create the VIRTUAL stack of all masks\n",
    "            virtual_stack = load_masks_as_virtual_stack(MASK_DIRECTORY)\n",
    "\n",
    "            # 2. Load ALL tracking data (it's small)\n",
    "            tracks_data = load_all_tracks(TRACKS_CSV_PATH)\n",
    "\n",
    "            # 3. Launch Napari\n",
    "            logging.info(\"Launching Napari viewer...\")\n",
    "            viewer = napari.Viewer(ndisplay=3)\n",
    "            \n",
    "            # Napari natively understands Dask arrays and handles them efficiently\n",
    "            viewer.add_labels(virtual_stack, name='Segmentation (Virtual Stack)')\n",
    "            \n",
    "            properties = {'track_id': tracks_data[:, 0]}\n",
    "            tracks_layer = viewer.add_tracks(\n",
    "                tracks_data,\n",
    "                properties=properties,\n",
    "                name='Object Tracks',\n",
    "                tail_length=30\n",
    "            )\n",
    "            tracks_layer.color_by = 'track_id'\n",
    "            \n",
    "            napari.run()\n",
    "\n",
    "        except (FileNotFoundError, ValueError) as e:\n",
    "            logging.error(f\"Could not start Napari due to an error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddda333",
   "metadata": {},
   "source": [
    "# Code to create animation from tracks in Napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12324e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Creating stop-motion sequence for 20 frames...\n",
      "INFO: Generating animation... this may take a moment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendering frames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/426 [00:00<?, ?it/s]WARNING: IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1618, 937) to (1632, 944) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "100%|██████████| 426/426 [15:15<00:00,  2.15s/it]\n",
      "INFO: Animation saved to '1268_01.mp4'\n"
     ]
    }
   ],
   "source": [
    "from napari_animation import Animation\n",
    "import logging\n",
    "\n",
    "# --- Animation Configuration ---\n",
    "\n",
    "# Set the desired frames per second for the output video\n",
    "FPS = 20\n",
    "\n",
    "# Set how long to pause on each data frame (in video frames).\n",
    "# Since FPS is 20, a pause of 20 equals a 1-second hold.\n",
    "PAUSE_DURATION_FRAMES = 20\n",
    "\n",
    "# Set how many video frames the initial zoom-in should take.\n",
    "ZOOM_DURATION_FRAMES = 25\n",
    "\n",
    "\n",
    "# --- Animation Script ---\n",
    "\n",
    "# 1. Create an Animation object from the existing viewer\n",
    "animation = Animation(viewer)\n",
    "total_data_frames = virtual_stack.shape[0]\n",
    "\n",
    "# --- Define the animation's key states ---\n",
    "\n",
    "# Keyframe 1: The very beginning, unzoomed.\n",
    "viewer.reset_view()\n",
    "viewer.dims.set_current_step(0, 0)\n",
    "animation.capture_keyframe() # This is the first frame of the animation\n",
    "\n",
    "# Keyframe 2: The zoomed-in state.\n",
    "# The animation creates a smooth zoom transition to this state.\n",
    "viewer.camera.zoom *= 3\n",
    "animation.capture_keyframe(steps=ZOOM_DURATION_FRAMES)\n",
    "\n",
    "# 3. Loop through each data frame to create the \"stop-motion\" effect\n",
    "logging.info(f\"Creating stop-motion sequence for {total_data_frames} frames...\")\n",
    "for i in range(total_data_frames):\n",
    "    # Move the viewer to the next data frame\n",
    "    viewer.dims.set_current_step(0, i)\n",
    "\n",
    "    # Capture this view and hold it for the specified pause duration\n",
    "    animation.capture_keyframe(steps=PAUSE_DURATION_FRAMES)\n",
    "\n",
    "# --- Generate the video ---\n",
    "logging.info(\"Generating animation... this may take a moment.\")\n",
    "animation.animate(\n",
    "    \"1268_01.mp4\",\n",
    "    canvas_only=True,\n",
    "    fps=FPS\n",
    ")\n",
    "\n",
    "logging.info(\"Animation saved to '1268_01.mp4'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c4aa5c",
   "metadata": {},
   "source": [
    "# Code for plotting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80da6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "# Make sure to replace csv with the actual name of your file\n",
    "try:\n",
    "    df = pd.read_csv('/home/mira/ibz_server/mvolosko/image_project/SDC1/1268_fast_imaging_01/tracks/analysis_results_robust.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: The csv file  was not found.\")\n",
    "    print(\"Please make sure the file is in the same directory as the script,\")\n",
    "    print(\"or provide the full file path.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# Filter out the rows where time is 0\n",
    "df_filtered = df[df['time'] != 0]\n",
    "events_to_exclude = ['bridged', 'bridged_disappearance', 'disappearance']\n",
    "df_filtered = df_filtered[~df_filtered['event_type'].isin(events_to_exclude)]\n",
    "df_filtered['event_type'] = df_filtered['event_type'].replace('terminal', 'terminated')\n",
    "\n",
    "# Group by time and event_type, and count the occurrences\n",
    "event_counts = df_filtered.groupby(['time', 'event_type']).size().reset_index(name='count')\n",
    "\n",
    "# Pivot the table to have event_types as columns\n",
    "pivot_df = event_counts.pivot(index='time', columns='event_type', values='count').fillna(0)\n",
    "\n",
    "\n",
    "# --- Plotting and Label Conversion ---\n",
    "plt.style.use('seaborn-v0_8-muted')\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "pivot_df.plot(kind='line', ax=ax, marker='', linestyle='-', linewidth=4)\n",
    "\n",
    "# Setting the title and labels\n",
    "ax.set_title('Event Types Over Time', fontsize=16)\n",
    "ax.set_xlabel('Time (min)', fontsize=16)\n",
    "ax.set_ylabel('Number of Events', fontsize=16)\n",
    "ax.legend(title='Event Type')\n",
    "ax.grid(True)\n",
    "\n",
    "# NEW: Convert x-axis from frame number to real time\n",
    "minutes_per_frame = 30.0 / 20.0\n",
    "\n",
    "# Get the tick locations (which are frame numbers)\n",
    "tick_locations = ax.get_xticks()\n",
    "\n",
    "# Create the new labels in MM:SS format\n",
    "new_labels = []\n",
    "for frame in tick_locations:\n",
    "    # Ignore ticks outside the data range (e.g., < 0)\n",
    "    if frame >= 0:\n",
    "        total_minutes = frame * minutes_per_frame\n",
    "        minutes = int(total_minutes)\n",
    "        new_labels.append(f'{minutes:02d}')\n",
    "\n",
    "# Set the new discrete labels on the plot\n",
    "ax.set_xticks(tick_locations) # Ensures ticks are set at integer frame values\n",
    "ax.set_xticklabels(new_labels)\n",
    "\n",
    "\n",
    "# Final adjustments\n",
    "plt.tight_layout() # Adjusts plot to prevent labels from overlapping\n",
    "plt.savefig('event_types_real_time.png')\n",
    "\n",
    "print(\"Plot saved as event_types_real_time.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1623d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Calculate number of tracks per timepoint (replicates = tracks) ---\n",
    "track_counts = pivot_df.apply(lambda row: (row > 0).astype(int), axis=1)\n",
    "\n",
    "# For each timepoint: mean number of tracks and SEM across track replicates\n",
    "track_dynamics = track_counts.sum(axis=1).groupby(level=0).agg(['mean', 'sem'])\n",
    "\n",
    "# --- Plotting ---\n",
    "plt.style.use('seaborn-v0_8-muted')\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "# Mean + SEM (like your size_dynamics)\n",
    "ax.errorbar(\n",
    "    track_dynamics.index,\n",
    "    track_dynamics['mean'],\n",
    "    yerr=track_dynamics['sem'],\n",
    "    capsize=4,\n",
    "    marker='o',\n",
    "    linestyle='-',\n",
    "    linewidth=2\n",
    ")\n",
    "\n",
    "# Titles and labels\n",
    "ax.set_title(\"Tracks per Timepoint\", fontsize=16)\n",
    "ax.set_xlabel(\"Time (mins)\", fontsize=12)\n",
    "ax.set_ylabel(\"Number of Tracks\", fontsize=12)\n",
    "ax.grid(True)\n",
    "\n",
    "# --- Convert x-axis from frames to minutes ---\n",
    "minutes_per_frame = 30.0 / 20.0  # adjust to your acquisition rate\n",
    "\n",
    "tick_locations = ax.get_xticks()\n",
    "new_labels = []\n",
    "for frame in tick_locations:\n",
    "    if frame >= 0:\n",
    "        total_minutes = frame * minutes_per_frame\n",
    "        minutes = int(total_minutes)\n",
    "        new_labels.append(f'{minutes:02d}')\n",
    "\n",
    "ax.set_xticks(tick_locations)\n",
    "ax.set_xticklabels(new_labels)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('tracks_vs_time.png')\n",
    "print(\"Plot saved as tracks_vs_time.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba7eac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- NEW: Calculate Size Dynamics ---\n",
    "# Group by time and calculate the mean and standard error of the mean (sem) for the 'area'\n",
    "size_dynamics = df_filtered.groupby('time')['area'].agg(['mean', 'sem'])\n",
    "\n",
    "\n",
    "# --- Plotting and Label Conversion ---\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "# Plot the mean area with the SEM as error bars (yerr)\n",
    "size_dynamics['mean'].plot(ax=ax, yerr=size_dynamics['sem'], capsize=4, marker='o', linestyle='-')\n",
    "\n",
    "\n",
    "# Setting the title and labels\n",
    "ax.set_title('Size Dynamics: Mean Area vs. Time (±SEM)', fontsize=16)\n",
    "ax.set_xlabel('Time (mins)', fontsize=12)\n",
    "ax.set_ylabel('Mean Area', fontsize=12)\n",
    "ax.grid(True)\n",
    "\n",
    "# Convert x-axis from frame number to real time\n",
    "minutes_per_frame = 30.0 / 20.0\n",
    "\n",
    "# Get the tick locations (which are frame numbers)\n",
    "tick_locations = ax.get_xticks()\n",
    "\n",
    "# Create the new labels in MM:SS format\n",
    "new_labels = []\n",
    "for frame in tick_locations:\n",
    "    # Ignore ticks outside the data range (e.g., < 0)\n",
    "    if frame >= 0:\n",
    "        total_minutes = frame * minutes_per_frame\n",
    "        minutes = int(total_minutes)\n",
    "        new_labels.append(f'{minutes:02d}')\n",
    "\n",
    "# Set the new discrete labels on the plot\n",
    "ax.set_xticks(tick_locations) # Ensures ticks are set at integer frame values\n",
    "ax.set_xticklabels(new_labels)\n",
    "\n",
    "\n",
    "# Final adjustments\n",
    "plt.tight_layout()\n",
    "plt.savefig('mean_area_vs_time.png')\n",
    "\n",
    "print(\"Plot saved as mean_area_vs_time.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7ab6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Load and Prepare Data \n",
    "try:\n",
    "    df = pd.read_csv('/home/mira/ibz_server/mvolosko/image_project/SDC1/1268_fast_imaging_01/tracks/analysis_results_robust.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: The file 'your_file.csv' was not found.\")\n",
    "    print(\"Please make sure the file is in the same directory as the script,\")\n",
    "    print(\"or provide the full file path.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# NEW: Handle duplicates for a given track_id at the same time point\n",
    "df.drop_duplicates(subset=['track_id', 'time'], keep='last', inplace=True)\n",
    "\n",
    "events_to_exclude = ['bridged', 'bridged_disappearance', 'disappearance']\n",
    "df = df[~df['event_type'].isin(events_to_exclude)]\n",
    "df['event_type'] = df['event_type'].replace('terminal', 'terminated')\n",
    "\n",
    "# --- 2. Create the \"Long-Form\" Lifecycle Data ---\n",
    "print(\"Building track lifecycles...\")\n",
    "# Find the start and end time for each track\n",
    "track_lifetimes = df.groupby('track_id')['time'].agg(['min', 'max']).reset_index()\n",
    "\n",
    "lifecycle_data = []\n",
    "# For each track, create a record for every frame it exists\n",
    "for _, row in track_lifetimes.iterrows():\n",
    "    track_id = row['track_id']\n",
    "    for time in range(row['min'], row['max'] + 1):\n",
    "        # Default state is 'persisting'\n",
    "        lifecycle_data.append({'track_id': track_id, 'time': time, 'event_type': 'persisting'})\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "lifecycle_df = pd.DataFrame(lifecycle_data)\n",
    "\n",
    "# Now, update the 'persisting' state with actual events from the original data\n",
    "# We set indices to easily align and update the data\n",
    "lifecycle_df.set_index(['track_id', 'time'], inplace=True)\n",
    "original_events = df.set_index(['track_id', 'time'])\n",
    "lifecycle_df.update(original_events)\n",
    "lifecycle_df.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "# --- 3. Create the Plotting Matrix ---\n",
    "print(\"Creating plotting matrix...\")\n",
    "# Map event names to numbers for plotting\n",
    "event_names = ['persisting', 'appearance', 'split', 'merge', 'terminated']\n",
    "event_ids = {name: i for i, name in enumerate(event_names)}\n",
    "lifecycle_df['event_id'] = lifecycle_df['event_type'].map(event_ids).fillna(-1) # Use -1 for missing\n",
    "\n",
    "# Pivot to create the matrix: rows=tracks, columns=time, values=event_id\n",
    "plot_matrix = lifecycle_df.pivot(index='track_id', columns='time', values='event_id')\n",
    "\n",
    "\n",
    "# --- 4. Generate the Plot ---\n",
    "print(\"Generating plot...\")\n",
    "# Define a custom color for each event type\n",
    "colors = ['#d3d3d3', '#2ca02c', '#ff7f0e', '#d62728', '#1f77b4'] # gray, green, orange, purple, red, blue, brown\n",
    "cmap = mcolors.ListedColormap(colors)\n",
    "bounds = np.arange(len(event_names) + 1) - 0.5\n",
    "norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 25))\n",
    "im = ax.imshow(plot_matrix, aspect='auto', cmap=cmap, norm=norm, interpolation='none')\n",
    "\n",
    "# Create a colorbar legend\n",
    "cbar = fig.colorbar(im, ax=ax, ticks=np.arange(len(event_names)))\n",
    "cbar.set_ticklabels(event_names)\n",
    "cbar.set_label('Event Type', rotation=270, labelpad=15)\n",
    "\n",
    "# Formatting the plot\n",
    "ax.set_title('Track Lifecycles', fontsize=18)\n",
    "ax.set_xlabel('Time (frames)', fontsize=12)\n",
    "ax.set_ylabel('Track ID', fontsize=12)\n",
    "# ax.set_xlim(0.5, 10.5)\n",
    "ax.set_ylim(0, 300)\n",
    "# Save the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig('track_lifecycles.png')\n",
    "\n",
    "print(\"\\nPlot saved as track_lifecycles.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lhcellpose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
